[2024-11-08T08:23:25.205+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:23:25.206+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:23:25.210+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:23:25.210+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:23:25.232+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:23:25.227+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:23:25.234+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:23:25.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.069 seconds
[2024-11-08T08:23:55.571+0000] {processor.py:186} INFO - Started process (PID=137) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:23:55.573+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:23:55.576+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:23:55.576+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:23:55.609+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:23:55.602+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:23:55.611+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:23:55.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.136 seconds
[2024-11-08T08:24:26.382+0000] {processor.py:186} INFO - Started process (PID=202) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:24:26.384+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:24:26.387+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:24:26.386+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:24:26.411+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:24:26.406+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:24:26.412+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:24:26.442+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.067 seconds
[2024-11-08T08:24:57.309+0000] {processor.py:186} INFO - Started process (PID=267) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:24:57.310+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:24:57.314+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:24:57.313+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:24:57.342+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:24:57.335+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:24:57.345+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:24:57.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.096 seconds
[2024-11-08T08:25:27.637+0000] {processor.py:186} INFO - Started process (PID=332) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:25:27.639+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:25:27.643+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:25:27.642+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:25:27.672+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:25:27.667+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:25:27.674+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:25:27.712+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.085 seconds
[2024-11-08T08:25:58.200+0000] {processor.py:186} INFO - Started process (PID=397) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:25:58.202+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:25:58.206+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:25:58.205+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:25:58.237+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:25:58.231+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:25:58.239+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:25:58.269+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.081 seconds
[2024-11-08T08:26:28.575+0000] {processor.py:186} INFO - Started process (PID=462) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:26:28.576+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:26:28.581+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:26:28.580+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:26:28.609+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:26:28.604+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:26:28.611+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:26:28.646+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.082 seconds
[2024-11-08T08:26:59.295+0000] {processor.py:186} INFO - Started process (PID=527) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:26:59.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:26:59.300+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:26:59.299+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:26:59.321+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:26:59.316+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:26:59.323+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:26:59.351+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.065 seconds
[2024-11-08T08:27:29.777+0000] {processor.py:186} INFO - Started process (PID=592) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:27:29.779+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:27:29.783+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:27:29.783+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:27:29.814+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:27:29.807+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:27:29.823+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:27:29.866+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.101 seconds
[2024-11-08T08:27:59.939+0000] {processor.py:186} INFO - Started process (PID=657) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:27:59.940+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:27:59.943+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:27:59.942+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:27:59.962+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:27:59.958+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:27:59.964+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:27:59.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.058 seconds
[2024-11-08T08:28:30.644+0000] {processor.py:186} INFO - Started process (PID=722) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:28:30.645+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:28:30.649+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:28:30.648+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:28:30.684+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:28:30.678+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:28:30.687+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:28:30.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.085 seconds
[2024-11-08T08:29:00.822+0000] {processor.py:186} INFO - Started process (PID=787) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:29:00.824+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:29:00.829+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:29:00.828+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:29:00.861+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:29:00.854+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:29:00.864+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:29:00.919+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.110 seconds
[2024-11-08T08:29:31.106+0000] {processor.py:186} INFO - Started process (PID=852) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:29:31.108+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:29:31.112+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:29:31.112+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:29:31.138+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:29:31.133+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:29:31.140+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:29:31.173+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.081 seconds
[2024-11-08T08:30:01.453+0000] {processor.py:186} INFO - Started process (PID=917) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:30:01.455+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:30:01.459+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:30:01.458+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:30:01.481+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:30:01.476+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:30:01.482+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:30:01.510+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.070 seconds
[2024-11-08T08:30:31.784+0000] {processor.py:186} INFO - Started process (PID=982) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:30:31.786+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:30:31.792+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:30:31.791+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:30:31.819+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:30:31.813+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:30:31.821+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:30:31.856+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.085 seconds
[2024-11-08T08:31:02.645+0000] {processor.py:186} INFO - Started process (PID=1047) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:31:02.647+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:31:02.654+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:31:02.653+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:31:02.680+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:31:02.675+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:31:02.682+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:31:02.715+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.094 seconds
[2024-11-08T08:31:33.395+0000] {processor.py:186} INFO - Started process (PID=1112) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:31:33.397+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:31:33.403+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:31:33.402+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:31:33.429+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:31:33.424+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:31:33.431+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:31:33.464+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.090 seconds
[2024-11-08T08:32:04.292+0000] {processor.py:186} INFO - Started process (PID=1177) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:32:04.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:32:04.297+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:32:04.296+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:32:04.321+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:32:04.316+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:32:04.323+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:32:04.349+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.064 seconds
[2024-11-08T08:32:34.491+0000] {processor.py:186} INFO - Started process (PID=1242) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:32:34.493+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:32:34.497+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:32:34.496+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:32:34.524+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:32:34.518+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:32:34.526+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:32:34.559+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.077 seconds
[2024-11-08T08:33:04.747+0000] {processor.py:186} INFO - Started process (PID=1307) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:33:04.749+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:33:04.753+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:33:04.753+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:33:04.783+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:33:04.777+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:33:04.786+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:33:04.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.099 seconds
[2024-11-08T08:33:35.511+0000] {processor.py:186} INFO - Started process (PID=1372) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:33:35.513+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:33:35.518+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:33:35.517+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:33:35.550+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:33:35.544+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:33:35.552+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:33:35.589+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.089 seconds
[2024-11-08T08:34:06.089+0000] {processor.py:186} INFO - Started process (PID=1436) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:34:06.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:34:06.094+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:34:06.094+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:34:06.118+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:34:06.113+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:34:06.120+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:34:06.149+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.068 seconds
[2024-11-08T08:34:37.448+0000] {processor.py:186} INFO - Started process (PID=1501) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:34:37.450+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:34:37.453+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:34:37.452+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:34:37.487+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:34:37.477+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:34:37.490+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:34:37.543+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.103 seconds
[2024-11-08T08:35:08.787+0000] {processor.py:186} INFO - Started process (PID=1560) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:35:08.789+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:35:08.792+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:35:08.792+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:35:08.816+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:35:08.811+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:35:08.819+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:35:08.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.073 seconds
[2024-11-08T08:35:39.020+0000] {processor.py:186} INFO - Started process (PID=1621) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:35:39.026+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:35:39.045+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:35:39.043+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:35:39.116+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:35:39.111+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:35:39.119+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:35:39.153+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.167 seconds
[2024-11-08T08:36:09.773+0000] {processor.py:186} INFO - Started process (PID=1686) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:36:09.774+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:36:09.778+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:36:09.777+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:36:09.804+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:36:09.799+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:36:09.807+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:36:09.837+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.073 seconds
[2024-11-08T08:36:40.296+0000] {processor.py:186} INFO - Started process (PID=1750) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:36:40.297+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:36:40.301+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:36:40.300+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:36:40.325+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:36:40.321+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:36:40.327+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:36:40.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.077 seconds
[2024-11-08T08:37:11.139+0000] {processor.py:186} INFO - Started process (PID=1803) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:37:11.141+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:37:11.144+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:37:11.144+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:37:11.193+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:37:11.184+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:37:11.198+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:37:11.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.116 seconds
[2024-11-08T08:37:41.575+0000] {processor.py:186} INFO - Started process (PID=1866) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:37:41.577+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:37:41.580+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:37:41.580+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:37:41.608+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:37:41.602+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:37:41.611+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:37:41.642+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.075 seconds
[2024-11-08T08:38:12.199+0000] {processor.py:186} INFO - Started process (PID=1925) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:38:12.200+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:38:12.203+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:38:12.203+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:38:12.233+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:38:12.227+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:38:12.235+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:38:12.260+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.070 seconds
[2024-11-08T08:38:42.363+0000] {processor.py:186} INFO - Started process (PID=1983) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:38:42.365+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:38:42.369+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:38:42.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:38:42.397+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:38:42.392+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:38:42.399+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:38:42.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.082 seconds
[2024-11-08T08:39:12.558+0000] {processor.py:186} INFO - Started process (PID=2045) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:39:12.559+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:39:12.563+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:39:12.563+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:39:12.590+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:39:12.584+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:39:12.592+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:39:12.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.070 seconds
[2024-11-08T08:39:43.023+0000] {processor.py:186} INFO - Started process (PID=2110) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:39:43.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:39:43.028+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:39:43.028+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:39:43.060+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:39:43.054+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:39:43.063+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:39:43.089+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.077 seconds
[2024-11-08T08:40:13.587+0000] {processor.py:186} INFO - Started process (PID=2175) to work on /opt/airflow/dags/etl.py
[2024-11-08T08:40:13.589+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T08:40:13.596+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:40:13.595+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T08:40:13.625+0000] {logging_mixin.py:190} INFO - [2024-11-08T08:40:13.621+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T08:40:13.627+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T08:40:13.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.088 seconds
[2024-11-08T09:33:11.675+0000] {processor.py:186} INFO - Started process (PID=2240) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:33:11.690+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:33:11.698+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:33:11.697+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:33:11.901+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:33:11.882+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:33:11.915+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:33:12.000+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.353 seconds
[2024-11-08T09:33:42.298+0000] {processor.py:186} INFO - Started process (PID=2305) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:33:42.299+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:33:42.303+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:33:42.302+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:33:42.325+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:33:42.320+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:33:42.326+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:33:42.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.073 seconds
[2024-11-08T09:34:12.605+0000] {processor.py:186} INFO - Started process (PID=2370) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:34:12.607+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:34:12.610+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:34:12.609+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:34:12.632+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:34:12.629+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:34:12.634+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:34:12.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.062 seconds
[2024-11-08T09:34:42.839+0000] {processor.py:186} INFO - Started process (PID=2431) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:34:42.840+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:34:42.845+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:34:42.844+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:34:42.875+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:34:42.869+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:34:42.878+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:34:42.914+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.088 seconds
[2024-11-08T09:35:13.426+0000] {processor.py:186} INFO - Started process (PID=2496) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:35:13.428+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:35:13.433+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:35:13.432+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:35:13.461+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:35:13.453+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:35:13.464+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:35:13.513+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.099 seconds
[2024-11-08T09:35:43.756+0000] {processor.py:186} INFO - Started process (PID=2561) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:35:43.758+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:35:43.762+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:35:43.761+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:35:43.797+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:35:43.790+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:35:43.799+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:35:43.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.089 seconds
[2024-11-08T09:36:14.475+0000] {processor.py:186} INFO - Started process (PID=2626) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:36:14.477+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:36:14.480+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:36:14.480+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:36:14.509+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:36:14.502+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:36:14.511+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:36:14.546+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.079 seconds
[2024-11-08T09:36:44.744+0000] {processor.py:186} INFO - Started process (PID=2691) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:36:44.746+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:36:44.751+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:36:44.750+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:36:44.779+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:36:44.773+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:36:44.782+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:36:44.816+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.083 seconds
[2024-11-08T09:37:15.128+0000] {processor.py:186} INFO - Started process (PID=2756) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:37:15.131+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:37:15.142+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:37:15.141+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:37:15.179+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:37:15.166+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:37:15.183+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:37:15.235+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.154 seconds
[2024-11-08T09:39:24.804+0000] {processor.py:186} INFO - Started process (PID=70) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:39:24.806+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:39:24.812+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:39:24.811+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:39:24.843+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:39:24.836+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:39:24.846+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:39:24.893+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.101 seconds
[2024-11-08T09:39:55.705+0000] {processor.py:186} INFO - Started process (PID=135) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:39:55.708+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:39:55.714+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:39:55.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:39:55.753+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:39:55.742+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:39:55.756+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:39:55.796+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.128 seconds
[2024-11-08T09:40:26.070+0000] {processor.py:186} INFO - Started process (PID=200) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:40:26.071+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:40:26.074+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:40:26.074+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:40:26.101+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:40:26.096+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:40:26.103+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:40:26.133+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.073 seconds
[2024-11-08T09:40:57.155+0000] {processor.py:186} INFO - Started process (PID=265) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:40:57.157+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:40:57.162+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:40:57.162+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:40:57.185+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:40:57.180+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:40:57.187+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:40:57.224+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.089 seconds
[2024-11-08T09:41:27.313+0000] {processor.py:186} INFO - Started process (PID=330) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:41:27.314+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:41:27.318+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:41:27.317+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:41:27.354+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:41:27.348+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:41:27.358+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:41:27.396+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.090 seconds
[2024-11-08T09:43:47.707+0000] {processor.py:186} INFO - Started process (PID=71) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:43:47.708+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:43:47.712+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:43:47.711+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:43:47.742+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:43:47.735+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:43:47.744+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:43:47.775+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.078 seconds
[2024-11-08T09:44:18.625+0000] {processor.py:186} INFO - Started process (PID=136) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:44:18.626+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:44:18.631+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:44:18.630+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:44:18.663+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:44:18.657+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:44:18.666+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:44:18.693+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.079 seconds
[2024-11-08T09:44:49.229+0000] {processor.py:186} INFO - Started process (PID=201) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:44:49.233+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:44:49.239+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:44:49.238+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:44:49.281+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:44:49.272+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:44:49.284+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:44:49.331+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.116 seconds
[2024-11-08T09:45:20.025+0000] {processor.py:186} INFO - Started process (PID=266) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:45:20.026+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:45:20.029+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:45:20.029+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:45:20.055+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:45:20.051+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:45:20.057+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:45:20.087+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.070 seconds
[2024-11-08T09:45:50.471+0000] {processor.py:186} INFO - Started process (PID=331) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:45:50.473+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:45:50.477+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:45:50.477+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:45:50.502+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:45:50.497+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:45:50.503+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:45:50.531+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.070 seconds
[2024-11-08T09:46:20.866+0000] {processor.py:186} INFO - Started process (PID=396) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:46:20.870+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:46:20.877+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:46:20.876+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:46:20.908+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:46:20.903+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:46:20.911+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:46:20.944+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.110 seconds
[2024-11-08T09:46:51.772+0000] {processor.py:186} INFO - Started process (PID=461) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:46:51.774+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:46:51.778+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:46:51.777+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:46:51.809+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:46:51.802+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:46:51.811+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:46:51.838+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.078 seconds
[2024-11-08T09:47:22.377+0000] {processor.py:186} INFO - Started process (PID=526) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:47:22.380+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:47:22.386+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:47:22.385+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:47:22.436+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:47:22.427+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:47:22.440+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:47:22.492+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.138 seconds
[2024-11-08T09:47:52.745+0000] {processor.py:186} INFO - Started process (PID=591) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:47:52.746+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:47:52.750+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:47:52.750+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:47:52.779+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:47:52.773+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:47:52.781+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:47:52.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.076 seconds
[2024-11-08T09:48:23.839+0000] {processor.py:186} INFO - Started process (PID=656) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:48:23.840+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:48:23.843+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:48:23.843+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:48:23.872+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:48:23.866+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:48:23.875+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:48:23.905+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.075 seconds
[2024-11-08T09:48:54.531+0000] {processor.py:186} INFO - Started process (PID=721) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:48:54.533+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:48:54.537+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:48:54.536+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:48:54.568+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:48:54.562+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:48:54.570+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:48:54.601+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.080 seconds
[2024-11-08T09:49:25.121+0000] {processor.py:186} INFO - Started process (PID=786) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:49:25.123+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:49:25.128+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:49:25.127+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:49:25.159+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:49:25.152+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:49:25.164+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:49:25.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.102 seconds
[2024-11-08T09:49:55.628+0000] {processor.py:186} INFO - Started process (PID=851) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:49:55.630+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:49:55.634+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:49:55.633+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:49:55.657+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:49:55.652+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:49:55.659+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:49:55.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.073 seconds
[2024-11-08T09:50:25.983+0000] {processor.py:186} INFO - Started process (PID=916) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:50:25.985+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:50:25.988+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:50:25.988+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:50:26.011+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:50:26.007+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:50:26.013+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:50:26.045+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.072 seconds
[2024-11-08T09:50:56.276+0000] {processor.py:186} INFO - Started process (PID=981) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:50:56.281+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:50:56.294+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:50:56.293+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:50:56.390+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:50:56.384+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:50:56.392+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:50:56.421+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.176 seconds
[2024-11-08T09:51:26.618+0000] {processor.py:186} INFO - Started process (PID=1046) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:51:26.622+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:51:26.632+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:51:26.631+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:51:26.682+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:51:26.669+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:51:26.684+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:51:26.714+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.124 seconds
[2024-11-08T09:51:56.873+0000] {processor.py:186} INFO - Started process (PID=1111) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:51:56.877+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:51:56.886+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:51:56.885+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:51:56.953+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:51:56.939+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:51:56.959+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:51:57.023+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.167 seconds
[2024-11-08T09:52:27.877+0000] {processor.py:186} INFO - Started process (PID=1176) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:52:27.879+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:52:27.882+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:52:27.882+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:52:27.905+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:52:27.900+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:52:27.907+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:52:27.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.075 seconds
[2024-11-08T09:52:58.451+0000] {processor.py:186} INFO - Started process (PID=1241) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:52:58.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:52:58.456+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:52:58.456+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:52:58.481+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:52:58.476+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:52:58.484+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:52:58.521+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.081 seconds
[2024-11-08T09:53:28.806+0000] {processor.py:186} INFO - Started process (PID=1301) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:53:28.809+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:53:28.824+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:53:28.816+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:53:28.861+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:53:28.855+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:53:28.864+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:53:28.909+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.115 seconds
[2024-11-08T09:54:00.038+0000] {processor.py:186} INFO - Started process (PID=1355) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:54:00.042+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:54:00.047+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:54:00.046+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:54:00.094+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:54:00.087+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:54:00.097+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:54:00.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.132 seconds
[2024-11-08T09:54:31.360+0000] {processor.py:186} INFO - Started process (PID=1418) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:54:31.362+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:54:31.366+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:54:31.365+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:54:31.387+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:54:31.383+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:54:31.389+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:54:31.429+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.077 seconds
[2024-11-08T09:55:01.833+0000] {processor.py:186} INFO - Started process (PID=1478) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:55:01.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:55:01.840+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:55:01.839+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:55:01.867+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:55:01.861+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:55:01.869+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:55:01.909+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.095 seconds
[2024-11-08T09:55:32.893+0000] {processor.py:186} INFO - Started process (PID=1542) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:55:32.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:55:32.900+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:55:32.900+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:55:32.928+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:55:32.923+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:55:32.931+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:55:32.965+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.089 seconds
[2024-11-08T09:56:03.482+0000] {processor.py:186} INFO - Started process (PID=1607) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:56:03.484+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:56:03.489+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:56:03.488+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:56:03.519+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:56:03.514+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:56:03.521+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:56:03.566+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.096 seconds
[2024-11-08T09:56:34.608+0000] {processor.py:186} INFO - Started process (PID=1672) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:56:34.611+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:56:34.618+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:56:34.617+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:56:34.669+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:56:34.658+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:56:34.672+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:56:34.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.148 seconds
[2024-11-08T09:57:05.403+0000] {processor.py:186} INFO - Started process (PID=1737) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:57:05.404+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:57:05.409+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:57:05.408+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:57:05.435+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:57:05.428+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:57:05.438+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:57:05.489+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.099 seconds
[2024-11-08T09:57:36.791+0000] {processor.py:186} INFO - Started process (PID=1794) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:57:36.793+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:57:36.797+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:57:36.797+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:57:36.825+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:57:36.819+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:57:36.828+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:57:36.862+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.084 seconds
[2024-11-08T09:58:08.217+0000] {processor.py:186} INFO - Started process (PID=1856) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:58:08.219+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:58:08.224+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:58:08.224+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:58:08.257+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:58:08.250+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:58:08.260+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:58:08.368+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.164 seconds
[2024-11-08T09:58:39.697+0000] {processor.py:186} INFO - Started process (PID=1921) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:58:39.699+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:58:39.703+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:58:39.702+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:58:39.728+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:58:39.723+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:58:39.731+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:58:39.768+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.083 seconds
[2024-11-08T09:59:10.566+0000] {processor.py:186} INFO - Started process (PID=1985) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:59:10.567+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:59:10.571+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:59:10.571+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:59:10.601+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:59:10.595+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:59:10.604+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:59:10.637+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.083 seconds
[2024-11-08T09:59:41.780+0000] {processor.py:186} INFO - Started process (PID=2049) to work on /opt/airflow/dags/etl.py
[2024-11-08T09:59:41.785+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T09:59:41.798+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:59:41.795+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T09:59:41.841+0000] {logging_mixin.py:190} INFO - [2024-11-08T09:59:41.836+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T09:59:41.843+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T09:59:41.872+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.127 seconds
[2024-11-08T10:00:12.166+0000] {processor.py:186} INFO - Started process (PID=2114) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:00:12.168+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:00:12.171+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:00:12.171+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:00:12.203+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:00:12.197+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T10:00:12.206+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:00:12.235+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.078 seconds
[2024-11-08T10:00:42.743+0000] {processor.py:186} INFO - Started process (PID=2178) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:00:42.746+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:00:42.752+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:00:42.751+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:00:42.804+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:00:42.792+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T10:00:42.808+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:00:42.859+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.134 seconds
[2024-11-08T10:01:13.074+0000] {processor.py:186} INFO - Started process (PID=2243) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:01:13.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:01:13.086+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:01:13.086+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:01:13.138+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:01:13.129+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T10:01:13.141+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:01:13.201+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.151 seconds
[2024-11-08T10:01:43.303+0000] {processor.py:186} INFO - Started process (PID=2308) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:01:43.305+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:01:43.308+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:01:43.308+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:01:43.340+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:01:43.333+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T10:01:43.342+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:01:43.375+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.081 seconds
[2024-11-08T10:02:13.666+0000] {processor.py:186} INFO - Started process (PID=2373) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:02:13.668+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:02:13.672+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:02:13.672+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:02:13.709+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:02:13.701+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T10:02:13.711+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:02:13.753+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.096 seconds
[2024-11-08T10:02:44.231+0000] {processor.py:186} INFO - Started process (PID=2444) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:02:44.232+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:02:44.236+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:02:44.235+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:02:44.264+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:02:44.257+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T10:02:44.266+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:02:44.295+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.072 seconds
[2024-11-08T10:03:14.716+0000] {processor.py:186} INFO - Started process (PID=2509) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:03:14.718+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:03:14.724+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:03:14.723+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:03:14.760+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:03:14.750+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T10:03:14.763+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:03:14.805+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.101 seconds
[2024-11-08T10:03:45.243+0000] {processor.py:186} INFO - Started process (PID=2574) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:03:45.245+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:03:45.248+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:03:45.248+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:03:45.277+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:03:45.269+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T10:03:45.281+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:03:45.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.099 seconds
[2024-11-08T10:04:15.681+0000] {processor.py:186} INFO - Started process (PID=2639) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:04:15.684+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:04:15.690+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:04:15.689+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:04:15.746+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:04:15.731+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T10:04:15.749+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:04:15.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.146 seconds
[2024-11-08T10:04:46.175+0000] {processor.py:186} INFO - Started process (PID=2704) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:04:46.178+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:04:46.184+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:04:46.184+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:04:46.226+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:04:46.217+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T10:04:46.230+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:04:46.306+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.164 seconds
[2024-11-08T10:05:16.513+0000] {processor.py:186} INFO - Started process (PID=2768) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:05:16.515+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:05:16.521+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:05:16.520+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:05:16.554+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:05:16.546+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T10:05:16.556+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:05:16.603+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.105 seconds
[2024-11-08T10:05:47.369+0000] {processor.py:186} INFO - Started process (PID=2833) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:05:47.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:05:47.374+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:05:47.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:05:47.402+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:05:47.397+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T10:05:47.404+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:05:47.440+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.083 seconds
[2024-11-08T10:06:18.426+0000] {processor.py:186} INFO - Started process (PID=2898) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:06:18.428+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:06:18.432+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:06:18.431+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:06:18.459+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:06:18.454+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T10:06:18.462+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:06:18.490+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.089 seconds
[2024-11-08T10:06:48.848+0000] {processor.py:186} INFO - Started process (PID=2963) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:06:48.849+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:06:48.855+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:06:48.854+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:06:48.893+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:06:48.886+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T10:06:48.895+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:06:48.939+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.102 seconds
[2024-11-08T10:07:19.591+0000] {processor.py:186} INFO - Started process (PID=3028) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:07:19.593+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:07:19.597+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:07:19.597+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:07:19.624+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:07:19.619+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T10:07:19.626+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:07:19.658+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.076 seconds
[2024-11-08T10:07:50.410+0000] {processor.py:186} INFO - Started process (PID=3093) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:07:50.412+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:07:50.415+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:07:50.415+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:07:50.452+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:07:50.444+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T10:07:50.455+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:07:50.487+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.086 seconds
[2024-11-08T10:08:20.926+0000] {processor.py:186} INFO - Started process (PID=3158) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:08:20.928+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:08:20.934+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:08:20.933+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:08:20.981+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:08:20.970+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T10:08:20.985+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:08:21.034+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.120 seconds
[2024-11-08T10:08:51.953+0000] {processor.py:186} INFO - Started process (PID=3222) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:08:51.955+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:08:51.958+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:08:51.958+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:08:51.988+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:08:51.982+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T10:08:51.990+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:08:52.023+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.081 seconds
[2024-11-08T10:09:22.845+0000] {processor.py:186} INFO - Started process (PID=3288) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:09:22.846+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:09:22.850+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:09:22.849+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:09:22.876+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:09:22.870+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T10:09:22.878+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:09:22.903+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.068 seconds
[2024-11-08T10:09:53.038+0000] {processor.py:186} INFO - Started process (PID=3353) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:09:53.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:09:53.044+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:09:53.043+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:09:53.077+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:09:53.070+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T10:09:53.079+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:09:53.120+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.089 seconds
[2024-11-08T10:10:23.800+0000] {processor.py:186} INFO - Started process (PID=3418) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:10:23.802+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:10:23.806+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:10:23.805+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:10:23.843+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:10:23.835+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T10:10:23.846+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:10:23.886+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.095 seconds
[2024-11-08T10:10:54.029+0000] {processor.py:186} INFO - Started process (PID=3483) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:10:54.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:10:54.034+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:10:54.034+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:10:54.058+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:10:54.053+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T10:10:54.060+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:10:54.091+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.070 seconds
[2024-11-08T10:11:24.264+0000] {processor.py:186} INFO - Started process (PID=3547) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:11:24.266+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:11:24.273+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:11:24.272+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:11:24.321+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:11:24.312+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T10:11:24.325+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:11:24.373+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.118 seconds
[2024-11-08T10:11:55.721+0000] {processor.py:186} INFO - Started process (PID=3609) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:11:55.722+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:11:55.726+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:11:55.725+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:11:55.758+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:11:55.752+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T10:11:55.761+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:11:56.000+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.289 seconds
[2024-11-08T10:12:26.820+0000] {processor.py:186} INFO - Started process (PID=3676) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:12:26.822+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:12:26.827+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:12:26.826+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:12:26.854+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:12:26.848+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 5, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2024-11-08T10:12:26.857+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:12:26.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.105 seconds
[2024-11-08T10:25:32.956+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:25:32.958+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:25:32.966+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:25:32.966+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:25:33.204+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:25:33.534+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:25:33.533+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:25:33.564+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:25:33.563+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:25:33.578+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:25:33.578+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:25:33.599+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:25:33.598+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:25:33.612+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:25:33.612+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:25:33.628+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:25:33.627+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:25:33.639+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:25:33.639+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:25:33.641+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:25:33.640+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:25:33.676+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:25:33.676+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_etl_pipeline_with_separate_functions
[2024-11-08T10:25:33.693+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:25:33.693+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:25:33.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.781 seconds
[2024-11-08T10:26:04.181+0000] {processor.py:186} INFO - Started process (PID=137) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:26:04.182+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:26:04.185+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:26:04.185+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:26:04.286+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:26:04.310+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:26:04.310+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:26:04.337+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:26:04.336+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:26:04.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.189 seconds
[2024-11-08T10:26:34.885+0000] {processor.py:186} INFO - Started process (PID=202) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:26:34.886+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:26:34.889+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:26:34.888+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:26:34.996+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:26:35.018+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:26:35.018+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:26:35.046+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:26:35.046+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:26:35.068+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.192 seconds
[2024-11-08T10:27:05.446+0000] {processor.py:186} INFO - Started process (PID=267) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:27:05.447+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:27:05.449+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:27:05.449+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:27:05.555+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:27:05.583+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:27:05.583+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:27:05.608+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:27:05.608+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:27:05.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.197 seconds
[2024-11-08T10:27:35.831+0000] {processor.py:186} INFO - Started process (PID=332) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:27:35.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:27:35.835+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:27:35.834+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:27:35.938+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:27:35.963+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:27:35.963+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:27:35.987+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:27:35.987+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:27:36.011+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.187 seconds
[2024-11-08T10:28:06.211+0000] {processor.py:186} INFO - Started process (PID=397) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:28:06.212+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:28:06.215+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:28:06.214+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:28:06.334+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:28:06.359+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:28:06.358+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:28:06.384+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:28:06.384+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:28:06.409+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.206 seconds
[2024-11-08T10:28:36.899+0000] {processor.py:186} INFO - Started process (PID=462) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:28:36.901+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:28:36.905+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:28:36.904+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:28:37.079+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:28:37.108+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:28:37.108+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:28:37.149+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:28:37.149+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:28:37.187+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.303 seconds
[2024-11-08T10:29:08.073+0000] {processor.py:186} INFO - Started process (PID=527) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:29:08.074+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:29:08.077+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:29:08.076+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:29:08.174+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:29:08.196+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:29:08.196+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:29:08.222+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:29:08.222+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:29:08.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.181 seconds
[2024-11-08T10:29:38.879+0000] {processor.py:186} INFO - Started process (PID=592) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:29:38.880+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:29:38.883+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:29:38.883+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:29:38.988+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:29:39.014+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:29:39.013+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:29:39.040+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:29:39.040+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:29:39.062+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.189 seconds
[2024-11-08T10:30:09.622+0000] {processor.py:186} INFO - Started process (PID=657) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:30:09.623+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:30:09.626+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:30:09.625+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:30:09.793+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:30:09.832+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:30:09.831+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:30:09.875+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:30:09.875+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:30:09.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.300 seconds
[2024-11-08T10:30:40.172+0000] {processor.py:186} INFO - Started process (PID=722) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:30:40.173+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:30:40.176+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:30:40.176+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:30:40.324+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:30:40.346+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:30:40.345+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:30:40.370+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:30:40.370+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:30:40.394+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.232 seconds
[2024-11-08T10:31:10.690+0000] {processor.py:186} INFO - Started process (PID=787) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:31:10.691+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:31:10.694+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:31:10.694+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:31:10.801+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:31:10.824+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:31:10.824+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:31:10.850+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:31:10.850+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:31:10.874+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.190 seconds
[2024-11-08T10:31:41.801+0000] {processor.py:186} INFO - Started process (PID=852) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:31:41.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:31:41.805+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:31:41.805+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:31:41.904+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:31:41.925+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:31:41.924+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:31:41.951+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:31:41.951+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:31:41.973+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.179 seconds
[2024-11-08T10:32:12.859+0000] {processor.py:186} INFO - Started process (PID=917) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:32:12.860+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:32:12.863+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:32:12.863+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:32:12.963+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:32:12.984+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:32:12.984+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:32:13.011+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:32:13.010+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:32:13.033+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.181 seconds
[2024-11-08T10:35:31.289+0000] {processor.py:186} INFO - Started process (PID=70) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:35:31.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:35:31.294+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:35:31.294+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:35:31.457+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:35:31.681+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:35:31.680+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:35:31.695+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:35:31.695+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:35:31.704+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:35:31.704+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:35:31.716+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:35:31.715+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:35:31.725+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:35:31.724+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:35:31.733+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:35:31.733+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:35:31.742+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:35:31.741+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:35:31.743+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:35:31.742+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:35:31.759+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:35:31.759+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_etl_pipeline_with_separate_functions
[2024-11-08T10:35:31.775+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:35:31.774+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:35:31.798+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.522 seconds
[2024-11-08T10:36:02.167+0000] {processor.py:186} INFO - Started process (PID=135) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:36:02.168+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:36:02.171+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:36:02.171+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:36:02.270+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:36:02.294+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:36:02.293+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:36:02.321+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:36:02.320+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:36:02.346+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.186 seconds
[2024-11-08T10:36:32.922+0000] {processor.py:186} INFO - Started process (PID=200) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:36:32.923+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:36:32.926+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:36:32.925+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:36:33.042+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:36:33.062+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:36:33.062+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:36:33.087+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:36:33.087+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:36:33.111+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.199 seconds
[2024-11-08T10:37:03.243+0000] {processor.py:186} INFO - Started process (PID=267) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:37:03.244+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:37:03.247+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:37:03.246+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:37:03.346+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:37:03.368+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:37:03.367+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:37:03.394+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:37:03.394+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:37:03.419+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.184 seconds
[2024-11-08T10:37:33.799+0000] {processor.py:186} INFO - Started process (PID=331) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:37:33.800+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:37:33.804+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:37:33.803+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:37:33.919+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:37:33.939+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:37:33.939+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:37:33.962+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:37:33.962+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:37:33.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.194 seconds
[2024-11-08T10:38:04.386+0000] {processor.py:186} INFO - Started process (PID=396) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:38:04.387+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:38:04.390+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:38:04.390+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:38:04.507+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:38:04.533+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:38:04.533+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:38:04.561+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:38:04.561+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:38:04.587+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.208 seconds
[2024-11-08T10:38:34.792+0000] {processor.py:186} INFO - Started process (PID=461) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:38:34.793+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:38:34.795+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:38:34.795+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:38:34.923+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:38:34.945+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:38:34.945+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:38:34.971+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:38:34.971+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:38:34.998+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.213 seconds
[2024-11-08T10:41:01.463+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:41:01.465+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:41:01.469+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:41:01.468+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:41:01.657+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:41:01.872+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:41:01.871+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:41:01.894+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:41:01.894+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:41:01.913+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:41:01.913+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:41:01.936+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:41:01.936+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:41:01.949+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:41:01.949+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:41:01.965+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:41:01.965+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:41:01.981+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:41:01.980+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:41:01.982+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:41:01.982+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:41:02.012+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:41:02.012+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_etl_pipeline_with_separate_functions
[2024-11-08T10:41:02.038+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:41:02.038+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:41:02.077+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.625 seconds
[2024-11-08T10:41:32.808+0000] {processor.py:186} INFO - Started process (PID=138) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:41:32.809+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:41:32.812+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:41:32.812+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:41:32.907+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:41:32.928+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:41:32.928+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:41:32.952+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:41:32.952+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:41:32.975+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.172 seconds
[2024-11-08T10:42:03.588+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:42:03.589+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:42:03.592+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:42:03.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:42:03.691+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:42:03.713+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:42:03.712+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:42:03.738+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:42:03.738+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:42:03.758+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.176 seconds
[2024-11-08T10:42:34.016+0000] {processor.py:186} INFO - Started process (PID=270) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:42:34.017+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:42:34.020+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:42:34.020+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:42:34.150+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:42:34.172+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:42:34.172+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:42:34.200+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:42:34.200+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:42:34.224+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.216 seconds
[2024-11-08T10:43:04.688+0000] {processor.py:186} INFO - Started process (PID=336) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:43:04.689+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:43:04.691+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:43:04.691+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:43:04.785+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:43:04.806+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:43:04.806+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:43:04.831+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:43:04.831+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:43:04.852+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.171 seconds
[2024-11-08T10:43:35.262+0000] {processor.py:186} INFO - Started process (PID=402) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:43:35.264+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:43:35.267+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:43:35.267+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:43:35.376+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:43:35.398+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:43:35.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:43:35.424+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:43:35.424+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:43:35.446+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.192 seconds
[2024-11-08T10:44:05.966+0000] {processor.py:186} INFO - Started process (PID=468) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:44:05.967+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:44:05.971+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:44:05.971+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:44:06.081+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:44:06.104+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:44:06.104+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:44:06.132+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:44:06.132+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:44:06.154+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.195 seconds
[2024-11-08T10:44:36.321+0000] {processor.py:186} INFO - Started process (PID=534) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:44:36.322+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:44:36.325+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:44:36.325+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:44:36.426+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:44:36.451+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:44:36.451+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:44:36.477+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:44:36.476+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:44:36.498+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.184 seconds
[2024-11-08T10:45:07.307+0000] {processor.py:186} INFO - Started process (PID=600) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:45:07.308+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:45:07.311+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:45:07.311+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:45:07.412+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:45:07.435+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:45:07.434+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:45:07.463+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:45:07.463+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:45:07.484+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.185 seconds
[2024-11-08T10:45:37.661+0000] {processor.py:186} INFO - Started process (PID=666) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:45:37.662+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:45:37.665+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:45:37.665+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:45:37.799+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:45:37.833+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:45:37.833+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:45:37.884+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:45:37.884+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:45:37.915+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.262 seconds
[2024-11-08T10:46:08.657+0000] {processor.py:186} INFO - Started process (PID=732) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:46:08.658+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:46:08.662+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:46:08.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:46:08.758+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:46:08.780+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:46:08.779+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:46:08.807+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:46:08.807+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:46:08.829+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.180 seconds
[2024-11-08T10:46:39.765+0000] {processor.py:186} INFO - Started process (PID=798) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:46:39.766+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:46:39.770+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:46:39.769+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:46:39.874+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:46:39.897+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:46:39.897+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:46:39.937+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:46:39.937+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:46:39.957+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.200 seconds
[2024-11-08T10:47:10.775+0000] {processor.py:186} INFO - Started process (PID=864) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:47:10.776+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:47:10.779+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:47:10.779+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:47:10.911+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:47:10.933+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:47:10.933+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:47:10.966+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:47:10.966+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:47:10.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.223 seconds
[2024-11-08T10:47:41.510+0000] {processor.py:186} INFO - Started process (PID=930) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:47:41.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:47:41.514+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:47:41.513+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:47:41.620+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:47:41.643+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:47:41.642+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:47:41.676+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:47:41.676+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:47:41.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.207 seconds
[2024-11-08T10:48:12.515+0000] {processor.py:186} INFO - Started process (PID=996) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:48:12.516+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:48:12.519+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:48:12.518+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:48:12.629+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:48:12.652+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:48:12.651+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:48:12.678+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:48:12.678+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:48:12.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.194 seconds
[2024-11-08T10:48:43.382+0000] {processor.py:186} INFO - Started process (PID=1062) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:48:43.383+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:48:43.385+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:48:43.385+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:48:43.480+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:48:43.502+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:48:43.502+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:48:43.529+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:48:43.528+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:48:43.550+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.175 seconds
[2024-11-08T10:49:14.187+0000] {processor.py:186} INFO - Started process (PID=1128) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:49:14.188+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:49:14.191+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:49:14.191+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:49:14.292+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:49:14.314+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:49:14.313+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:49:14.340+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:49:14.340+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:49:14.363+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.182 seconds
[2024-11-08T10:49:44.436+0000] {processor.py:186} INFO - Started process (PID=1194) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:49:44.438+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:49:44.440+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:49:44.440+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:49:44.541+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:49:44.563+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:49:44.563+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:49:44.589+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:49:44.589+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:49:44.612+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.183 seconds
[2024-11-08T10:50:14.783+0000] {processor.py:186} INFO - Started process (PID=1260) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:50:14.784+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:50:14.787+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:50:14.787+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:50:14.893+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:50:14.915+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:50:14.915+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:50:14.942+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:50:14.942+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:50:14.965+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.189 seconds
[2024-11-08T10:50:45.959+0000] {processor.py:186} INFO - Started process (PID=1326) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:50:45.960+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:50:45.963+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:50:45.963+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:50:46.070+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:50:46.093+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:50:46.093+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:50:46.118+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:50:46.118+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:50:46.141+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.191 seconds
[2024-11-08T10:51:16.500+0000] {processor.py:186} INFO - Started process (PID=1392) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:51:16.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:51:16.503+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:51:16.503+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:51:16.609+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:51:16.638+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:51:16.638+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:51:16.665+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:51:16.665+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:51:16.687+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.193 seconds
[2024-11-08T10:51:47.079+0000] {processor.py:186} INFO - Started process (PID=1458) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:51:47.081+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:51:47.084+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:51:47.083+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:51:47.195+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:51:47.217+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:51:47.217+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:51:47.244+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:51:47.244+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:51:47.268+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.195 seconds
[2024-11-08T10:52:17.809+0000] {processor.py:186} INFO - Started process (PID=1524) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:52:17.810+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:52:17.813+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:52:17.813+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:52:17.943+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:52:17.968+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:52:17.968+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:52:17.998+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:52:17.998+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:52:18.026+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.224 seconds
[2024-11-08T10:52:48.288+0000] {processor.py:186} INFO - Started process (PID=1590) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:52:48.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:52:48.294+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:52:48.293+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:52:48.472+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:52:48.504+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:52:48.503+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:52:48.549+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:52:48.549+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:52:48.583+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.305 seconds
[2024-11-08T10:53:18.706+0000] {processor.py:186} INFO - Started process (PID=1656) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:53:18.708+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:53:18.712+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:53:18.712+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:53:18.838+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:53:18.858+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:53:18.858+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:53:18.884+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:53:18.884+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:53:18.904+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.210 seconds
[2024-11-08T10:53:48.994+0000] {processor.py:186} INFO - Started process (PID=1722) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:53:48.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:53:48.998+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:53:48.998+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:53:49.123+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:53:49.144+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:53:49.144+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:53:49.171+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:53:49.171+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:53:49.196+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.210 seconds
[2024-11-08T10:54:19.257+0000] {processor.py:186} INFO - Started process (PID=1789) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:54:19.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:54:19.261+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:54:19.261+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:54:19.385+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:54:19.410+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:54:19.409+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:54:19.443+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:54:19.442+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:54:19.467+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.221 seconds
[2024-11-08T10:54:50.175+0000] {processor.py:186} INFO - Started process (PID=1854) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:54:50.177+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:54:50.180+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:54:50.180+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:54:50.308+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:54:50.329+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:54:50.329+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:54:50.354+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:54:50.354+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:54:50.379+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.214 seconds
[2024-11-08T10:55:20.924+0000] {processor.py:186} INFO - Started process (PID=1926) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:55:20.925+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:55:20.928+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:55:20.928+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:55:21.033+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:55:21.056+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:55:21.055+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:55:21.082+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:55:21.082+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:55:21.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.192 seconds
[2024-11-08T10:55:51.297+0000] {processor.py:186} INFO - Started process (PID=1992) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:55:51.299+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:55:51.303+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:55:51.303+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:55:51.459+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:55:51.501+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:55:51.500+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:55:51.535+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:55:51.534+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:55:51.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.283 seconds
[2024-11-08T10:56:21.710+0000] {processor.py:186} INFO - Started process (PID=2043) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:56:21.711+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:56:21.714+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:56:21.714+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:56:21.854+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:56:21.904+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:56:21.903+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:56:21.938+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:56:21.937+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:56:21.961+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.258 seconds
[2024-11-08T10:56:52.638+0000] {processor.py:186} INFO - Started process (PID=2106) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:56:52.639+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:56:52.642+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:56:52.641+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:56:52.741+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:56:52.763+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:56:52.763+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:56:52.790+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:56:52.789+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:56:52.814+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.183 seconds
[2024-11-08T10:57:22.868+0000] {processor.py:186} INFO - Started process (PID=2167) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:57:22.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:57:22.872+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:57:22.871+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:57:22.987+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:57:23.013+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:57:23.013+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:57:23.045+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:57:23.045+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:57:23.070+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.210 seconds
[2024-11-08T10:59:18.630+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:59:18.632+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:59:18.637+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:59:18.636+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:59:18.841+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:59:19.301+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:59:19.299+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:59:19.374+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:59:19.374+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:59:19.434+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:59:19.433+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:59:19.462+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:59:19.462+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:59:19.507+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:59:19.507+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:59:19.542+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:59:19.542+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:59:19.552+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:59:19.552+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T10:59:19.553+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:59:19.553+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:59:19.575+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:59:19.574+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_etl_pipeline_with_separate_functions
[2024-11-08T10:59:19.589+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:59:19.589+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:59:19.612+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.994 seconds
[2024-11-08T10:59:49.995+0000] {processor.py:186} INFO - Started process (PID=138) to work on /opt/airflow/dags/etl.py
[2024-11-08T10:59:49.997+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T10:59:49.999+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:59:49.999+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T10:59:50.111+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T10:59:50.132+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:59:50.132+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T10:59:50.159+0000] {logging_mixin.py:190} INFO - [2024-11-08T10:59:50.159+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T10:59:50.181+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.196 seconds
[2024-11-08T11:00:20.995+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/etl.py
[2024-11-08T11:00:20.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T11:00:20.999+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:00:20.998+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T11:00:21.101+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T11:00:21.125+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:00:21.125+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T11:00:21.155+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:00:21.155+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T11:00:21.177+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.190 seconds
[2024-11-08T11:00:51.588+0000] {processor.py:186} INFO - Started process (PID=270) to work on /opt/airflow/dags/etl.py
[2024-11-08T11:00:51.589+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T11:00:51.592+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:00:51.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T11:00:51.693+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T11:00:51.714+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:00:51.713+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T11:00:51.740+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:00:51.740+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T11:00:51.763+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.181 seconds
[2024-11-08T11:01:21.839+0000] {processor.py:186} INFO - Started process (PID=336) to work on /opt/airflow/dags/etl.py
[2024-11-08T11:01:21.840+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T11:01:21.843+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:01:21.843+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T11:01:21.969+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T11:01:21.994+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:01:21.994+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T11:01:22.026+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:01:22.026+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T11:01:22.051+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.220 seconds
[2024-11-08T11:01:52.324+0000] {processor.py:186} INFO - Started process (PID=402) to work on /opt/airflow/dags/etl.py
[2024-11-08T11:01:52.325+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T11:01:52.328+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:01:52.328+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T11:01:52.426+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T11:01:52.446+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:01:52.446+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T11:01:52.470+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:01:52.470+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T11:01:52.491+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.173 seconds
[2024-11-08T11:02:22.742+0000] {processor.py:186} INFO - Started process (PID=468) to work on /opt/airflow/dags/etl.py
[2024-11-08T11:02:22.743+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T11:02:22.745+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:02:22.745+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T11:02:22.845+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T11:02:22.865+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:02:22.865+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T11:02:22.897+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:02:22.897+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T11:02:22.918+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.182 seconds
[2024-11-08T11:02:53.574+0000] {processor.py:186} INFO - Started process (PID=534) to work on /opt/airflow/dags/etl.py
[2024-11-08T11:02:53.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T11:02:53.578+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:02:53.578+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T11:02:53.688+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T11:02:53.708+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:02:53.708+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T11:02:53.732+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:02:53.732+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T11:02:53.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.190 seconds
[2024-11-08T11:03:23.863+0000] {processor.py:186} INFO - Started process (PID=600) to work on /opt/airflow/dags/etl.py
[2024-11-08T11:03:23.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T11:03:23.868+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:03:23.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T11:03:23.963+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T11:03:23.984+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:03:23.984+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T11:03:24.009+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:03:24.009+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T11:03:24.033+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.178 seconds
[2024-11-08T11:03:54.232+0000] {processor.py:186} INFO - Started process (PID=666) to work on /opt/airflow/dags/etl.py
[2024-11-08T11:03:54.234+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T11:03:54.237+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:03:54.236+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T11:03:54.349+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T11:03:54.370+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:03:54.369+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T11:03:54.394+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:03:54.394+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T11:03:54.415+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.191 seconds
[2024-11-08T11:04:25.208+0000] {processor.py:186} INFO - Started process (PID=732) to work on /opt/airflow/dags/etl.py
[2024-11-08T11:04:25.210+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T11:04:25.213+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:04:25.212+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T11:04:25.326+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T11:04:25.345+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:04:25.345+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T11:04:25.369+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:04:25.369+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T11:04:25.390+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.189 seconds
[2024-11-08T11:04:56.226+0000] {processor.py:186} INFO - Started process (PID=799) to work on /opt/airflow/dags/etl.py
[2024-11-08T11:04:56.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T11:04:56.229+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:04:56.229+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T11:04:56.328+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T11:04:56.352+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:04:56.352+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T11:04:56.387+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:04:56.387+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T11:04:56.406+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.187 seconds
[2024-11-08T11:05:27.148+0000] {processor.py:186} INFO - Started process (PID=865) to work on /opt/airflow/dags/etl.py
[2024-11-08T11:05:27.149+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T11:05:27.153+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:05:27.152+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T11:05:27.262+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T11:05:27.283+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:05:27.283+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T11:05:27.307+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:05:27.307+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T11:05:27.332+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.191 seconds
[2024-11-08T11:05:58.411+0000] {processor.py:186} INFO - Started process (PID=931) to work on /opt/airflow/dags/etl.py
[2024-11-08T11:05:58.412+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T11:05:58.415+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:05:58.414+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T11:05:58.520+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T11:05:58.541+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:05:58.541+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T11:05:58.568+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:05:58.567+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T11:05:58.598+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.194 seconds
[2024-11-08T11:06:29.537+0000] {processor.py:186} INFO - Started process (PID=997) to work on /opt/airflow/dags/etl.py
[2024-11-08T11:06:29.538+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T11:06:29.541+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:06:29.540+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T11:06:29.666+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T11:06:29.691+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:06:29.691+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T11:06:29.721+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:06:29.720+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T11:06:29.743+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.212 seconds
[2024-11-08T11:06:59.805+0000] {processor.py:186} INFO - Started process (PID=1063) to work on /opt/airflow/dags/etl.py
[2024-11-08T11:06:59.806+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T11:06:59.809+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:06:59.809+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T11:06:59.907+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T11:06:59.929+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:06:59.928+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T11:06:59.963+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:06:59.963+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T11:06:59.987+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.189 seconds
[2024-11-08T11:07:30.556+0000] {processor.py:186} INFO - Started process (PID=1129) to work on /opt/airflow/dags/etl.py
[2024-11-08T11:07:30.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T11:07:30.560+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:07:30.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T11:07:30.657+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T11:07:30.678+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:07:30.678+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T11:07:30.703+0000] {logging_mixin.py:190} INFO - [2024-11-08T11:07:30.702+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T11:07:30.725+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.177 seconds
[2024-11-08T13:14:30.363+0000] {processor.py:186} INFO - Started process (PID=1153) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:14:30.373+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:14:30.379+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:14:30.378+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:14:30.845+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:14:30.910+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:14:30.907+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:14:30.998+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:14:30.997+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:14:31.047+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.696 seconds
[2024-11-08T13:15:01.533+0000] {processor.py:186} INFO - Started process (PID=1219) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:15:01.540+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:15:01.547+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:15:01.546+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:15:01.713+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:15:01.740+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:15:01.740+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:15:01.768+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:15:01.767+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:15:01.791+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.269 seconds
[2024-11-08T13:15:32.621+0000] {processor.py:186} INFO - Started process (PID=1285) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:15:32.624+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:15:32.628+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:15:32.628+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:15:32.759+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:15:32.782+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:15:32.782+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:15:32.808+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:15:32.808+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:15:32.841+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.233 seconds
[2024-11-08T13:16:03.892+0000] {processor.py:186} INFO - Started process (PID=1351) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:16:03.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:16:03.903+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:16:03.902+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:16:04.107+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:16:04.140+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:16:04.140+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:16:04.172+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:16:04.172+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:16:04.198+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.324 seconds
[2024-11-08T13:16:34.705+0000] {processor.py:186} INFO - Started process (PID=1417) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:16:34.707+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:16:34.713+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:16:34.712+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:16:34.862+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:16:34.888+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:16:34.888+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:16:34.920+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:16:34.920+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:16:34.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.255 seconds
[2024-11-08T13:17:05.181+0000] {processor.py:186} INFO - Started process (PID=1483) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:17:05.183+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:17:05.189+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:17:05.188+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:17:05.322+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:17:05.347+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:17:05.347+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:17:05.378+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:17:05.378+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:17:05.444+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.273 seconds
[2024-11-08T13:17:36.556+0000] {processor.py:186} INFO - Started process (PID=1549) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:17:36.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:17:36.562+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:17:36.561+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:17:36.700+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:17:36.731+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:17:36.730+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:17:36.765+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:17:36.765+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:17:36.795+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.258 seconds
[2024-11-08T13:18:07.769+0000] {processor.py:186} INFO - Started process (PID=1616) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:18:07.772+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:18:07.779+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:18:07.778+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:18:07.975+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:18:08.002+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:18:08.002+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:18:08.036+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:18:08.036+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:18:08.062+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.313 seconds
[2024-11-08T13:18:39.021+0000] {processor.py:186} INFO - Started process (PID=1682) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:18:39.023+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:18:39.027+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:18:39.026+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:18:39.212+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:18:39.246+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:18:39.246+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:18:39.291+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:18:39.291+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:18:39.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.317 seconds
[2024-11-08T13:19:09.503+0000] {processor.py:186} INFO - Started process (PID=1747) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:19:09.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:19:09.508+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:19:09.507+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:19:09.629+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:19:09.657+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:19:09.656+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:19:09.694+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:19:09.694+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:19:09.717+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.223 seconds
[2024-11-08T13:19:39.893+0000] {processor.py:186} INFO - Started process (PID=1813) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:19:39.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:19:39.900+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:19:39.899+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:19:40.089+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:19:40.133+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:19:40.133+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:19:40.196+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:19:40.196+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:19:40.241+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.360 seconds
[2024-11-08T13:20:10.717+0000] {processor.py:186} INFO - Started process (PID=1879) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:20:10.718+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:20:10.721+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:20:10.721+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:20:10.869+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:20:10.895+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:20:10.894+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:20:10.925+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:20:10.925+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:20:10.952+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.243 seconds
[2024-11-08T13:20:41.972+0000] {processor.py:186} INFO - Started process (PID=1945) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:20:41.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:20:41.978+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:20:41.977+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:20:42.157+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:20:42.196+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:20:42.195+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:20:42.248+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:20:42.248+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:20:42.284+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.332 seconds
[2024-11-08T13:21:13.032+0000] {processor.py:186} INFO - Started process (PID=2011) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:21:13.033+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:21:13.038+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:21:13.037+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:21:13.177+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:21:13.205+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:21:13.205+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:21:13.257+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:21:13.256+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:21:13.302+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.280 seconds
[2024-11-08T13:21:43.970+0000] {processor.py:186} INFO - Started process (PID=2077) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:21:43.971+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:21:43.975+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:21:43.975+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:21:44.123+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:21:44.148+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:21:44.148+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:21:44.178+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:21:44.178+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:21:44.232+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.270 seconds
[2024-11-08T13:22:14.499+0000] {processor.py:186} INFO - Started process (PID=2143) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:22:14.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:22:14.505+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:22:14.505+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:22:14.640+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:22:14.666+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:22:14.666+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:22:14.696+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:22:14.695+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:22:14.724+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.238 seconds
[2024-11-08T13:22:44.973+0000] {processor.py:186} INFO - Started process (PID=2209) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:22:44.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:22:44.978+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:22:44.978+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:22:45.145+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:22:45.171+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:22:45.171+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:22:45.202+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:22:45.202+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:22:45.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.265 seconds
[2024-11-08T13:26:44.658+0000] {processor.py:186} INFO - Started process (PID=71) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:26:44.659+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:26:44.662+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:26:44.662+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:26:44.797+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:26:44.992+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:26:44.991+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T13:26:45.011+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:26:45.010+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T13:26:45.025+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:26:45.024+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T13:26:45.048+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:26:45.048+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T13:26:45.060+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:26:45.059+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T13:26:45.071+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:26:45.071+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T13:26:45.084+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:26:45.083+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T13:26:45.085+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:26:45.084+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:26:45.101+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:26:45.101+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_etl_pipeline_with_separate_functions
[2024-11-08T13:26:45.115+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:26:45.114+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:26:45.145+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.494 seconds
[2024-11-08T13:27:15.543+0000] {processor.py:186} INFO - Started process (PID=138) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:27:15.545+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:27:15.548+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:27:15.548+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:27:15.675+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:27:15.701+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:27:15.701+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:27:15.734+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:27:15.733+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:27:15.760+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.226 seconds
[2024-11-08T13:27:45.885+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:27:45.887+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:27:45.890+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:27:45.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:27:46.038+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:27:46.073+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:27:46.073+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:27:46.124+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:27:46.124+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:27:46.157+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.283 seconds
[2024-11-08T13:28:16.755+0000] {processor.py:186} INFO - Started process (PID=270) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:28:16.757+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:28:16.764+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:28:16.763+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:28:17.080+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:28:17.163+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:28:17.163+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:28:17.296+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:28:17.292+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:28:17.366+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.658 seconds
[2024-11-08T13:28:48.373+0000] {processor.py:186} INFO - Started process (PID=336) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:28:48.375+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:28:48.378+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:28:48.378+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:28:48.521+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:28:48.551+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:28:48.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:28:48.600+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:28:48.600+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:28:48.676+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.313 seconds
[2024-11-08T13:29:19.610+0000] {processor.py:186} INFO - Started process (PID=402) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:29:19.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:29:19.615+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:29:19.615+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:29:19.768+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:29:19.807+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:29:19.807+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:29:19.847+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:29:19.847+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:29:19.875+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.275 seconds
[2024-11-08T13:29:50.285+0000] {processor.py:186} INFO - Started process (PID=468) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:29:50.286+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:29:50.291+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:29:50.290+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:29:50.464+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:29:50.490+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:29:50.490+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:29:50.524+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:29:50.524+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:29:50.551+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.278 seconds
[2024-11-08T13:30:20.916+0000] {processor.py:186} INFO - Started process (PID=534) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:30:20.917+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:30:20.923+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:30:20.921+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:30:21.070+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:30:21.102+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:30:21.102+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:30:21.141+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:30:21.141+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:30:21.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.269 seconds
[2024-11-08T13:30:51.367+0000] {processor.py:186} INFO - Started process (PID=600) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:30:51.368+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:30:51.373+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:30:51.373+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:30:51.559+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:30:51.592+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:30:51.592+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:30:51.654+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:30:51.654+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:30:51.683+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.330 seconds
[2024-11-08T13:31:22.017+0000] {processor.py:186} INFO - Started process (PID=666) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:31:22.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:31:22.024+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:31:22.023+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:31:22.231+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:31:22.273+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:31:22.272+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:31:22.319+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:31:22.318+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:31:22.349+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.343 seconds
[2024-11-08T13:31:53.371+0000] {processor.py:186} INFO - Started process (PID=732) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:31:53.372+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:31:53.376+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:31:53.375+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:31:53.488+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:31:53.512+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:31:53.512+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:31:53.545+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:31:53.545+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:31:53.570+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.210 seconds
[2024-11-08T13:32:24.422+0000] {processor.py:186} INFO - Started process (PID=798) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:32:24.425+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:32:24.432+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:32:24.431+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:32:24.559+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:32:24.585+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:32:24.584+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:32:24.618+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:32:24.618+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:32:24.651+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.242 seconds
[2024-11-08T13:32:54.908+0000] {processor.py:186} INFO - Started process (PID=864) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:32:54.910+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:32:54.915+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:32:54.914+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:32:55.081+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:32:55.120+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:32:55.119+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:32:55.180+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:32:55.179+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:32:55.218+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.319 seconds
[2024-11-08T13:33:25.594+0000] {processor.py:186} INFO - Started process (PID=930) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:33:25.598+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:33:25.605+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:33:25.604+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:33:25.762+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:33:25.791+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:33:25.790+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:33:25.824+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:33:25.824+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:33:25.852+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.273 seconds
[2024-11-08T13:33:56.048+0000] {processor.py:186} INFO - Started process (PID=996) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:33:56.049+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:33:56.053+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:33:56.052+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:33:56.187+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:33:56.218+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:33:56.218+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:33:56.260+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:33:56.259+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:33:56.300+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.262 seconds
[2024-11-08T13:34:26.909+0000] {processor.py:186} INFO - Started process (PID=1062) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:34:26.911+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:34:26.914+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:34:26.914+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:34:27.044+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:34:27.074+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:34:27.073+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:34:27.104+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:34:27.104+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:34:27.130+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.229 seconds
[2024-11-08T13:34:57.655+0000] {processor.py:186} INFO - Started process (PID=1128) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:34:57.656+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:34:57.661+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:34:57.660+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:34:57.791+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:34:57.822+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:34:57.822+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:34:57.859+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:34:57.858+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:34:57.888+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.242 seconds
[2024-11-08T13:35:28.745+0000] {processor.py:186} INFO - Started process (PID=1194) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:35:28.747+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:35:28.750+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:35:28.750+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:35:28.878+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:35:28.904+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:35:28.904+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:35:28.941+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:35:28.941+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:35:28.971+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.235 seconds
[2024-11-08T13:35:59.502+0000] {processor.py:186} INFO - Started process (PID=1260) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:35:59.503+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:35:59.508+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:35:59.507+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:35:59.732+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:35:59.768+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:35:59.768+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:35:59.806+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:35:59.806+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:35:59.836+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.353 seconds
[2024-11-08T13:36:29.951+0000] {processor.py:186} INFO - Started process (PID=1326) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:36:29.952+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:36:29.957+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:36:29.956+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:36:30.086+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:36:30.111+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:36:30.110+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:36:30.142+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:36:30.142+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:36:30.171+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.231 seconds
[2024-11-08T13:37:01.443+0000] {processor.py:186} INFO - Started process (PID=1398) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:37:01.444+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:37:01.448+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:37:01.447+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:37:01.584+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:37:01.613+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:37:01.612+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:37:01.648+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:37:01.648+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:37:01.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.238 seconds
[2024-11-08T13:37:32.169+0000] {processor.py:186} INFO - Started process (PID=1459) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:37:32.171+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:37:32.175+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:37:32.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:37:32.404+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:37:32.441+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:37:32.441+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:37:32.487+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:37:32.487+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:37:32.533+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.375 seconds
[2024-11-08T13:38:03.085+0000] {processor.py:186} INFO - Started process (PID=1518) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:38:03.087+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:38:03.092+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:38:03.091+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:38:03.275+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:38:03.304+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:38:03.304+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:38:03.348+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:38:03.347+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:38:03.404+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.330 seconds
[2024-11-08T13:38:34.883+0000] {processor.py:186} INFO - Started process (PID=1581) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:38:34.886+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:38:34.890+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:38:34.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:38:35.034+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:38:35.060+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:38:35.059+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:38:35.097+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:38:35.097+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:38:35.124+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.252 seconds
[2024-11-08T13:39:06.859+0000] {processor.py:186} INFO - Started process (PID=1647) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:39:06.861+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:39:06.865+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:39:06.865+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:39:06.996+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:39:07.025+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:39:07.025+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:39:07.060+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:39:07.059+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:39:07.092+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.246 seconds
[2024-11-08T13:39:38.493+0000] {processor.py:186} INFO - Started process (PID=1714) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:39:38.495+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:39:38.499+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:39:38.498+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:39:38.626+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:39:38.655+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:39:38.655+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:39:38.699+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:39:38.698+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:39:38.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.253 seconds
[2024-11-08T13:40:09.969+0000] {processor.py:186} INFO - Started process (PID=1780) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:40:09.971+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:40:09.975+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:40:09.974+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:40:10.141+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:40:10.170+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:40:10.169+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:40:10.210+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:40:10.210+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:40:10.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.280 seconds
[2024-11-08T13:40:40.758+0000] {processor.py:186} INFO - Started process (PID=1846) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:40:40.759+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:40:40.763+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:40:40.762+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:40:40.900+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:40:40.925+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:40:40.925+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:40:40.956+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:40:40.955+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:40:40.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.233 seconds
[2024-11-08T13:43:30.716+0000] {processor.py:186} INFO - Started process (PID=70) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:43:30.717+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:43:30.720+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:43:30.720+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:43:30.852+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:43:31.119+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:43:31.118+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T13:43:31.143+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:43:31.142+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T13:43:31.158+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:43:31.157+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T13:43:31.171+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:43:31.170+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T13:43:31.184+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:43:31.183+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T13:43:31.195+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:43:31.194+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T13:43:31.205+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:43:31.204+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T13:43:31.206+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:43:31.206+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:43:31.223+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:43:31.223+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_etl_pipeline_with_separate_functions
[2024-11-08T13:43:31.237+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:43:31.237+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:43:31.259+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.551 seconds
[2024-11-08T13:44:01.449+0000] {processor.py:186} INFO - Started process (PID=136) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:44:01.450+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:44:01.454+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:44:01.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:44:01.583+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:44:01.608+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:44:01.608+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:44:01.638+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:44:01.638+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:44:01.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.223 seconds
[2024-11-08T13:44:32.259+0000] {processor.py:186} INFO - Started process (PID=202) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:44:32.260+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:44:32.264+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:44:32.264+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:44:32.398+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:44:32.422+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:44:32.422+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:44:32.453+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:44:32.453+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:44:32.477+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.226 seconds
[2024-11-08T13:45:03.106+0000] {processor.py:186} INFO - Started process (PID=268) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:45:03.107+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:45:03.111+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:45:03.110+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:45:03.227+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:45:03.250+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:45:03.250+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:45:03.280+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:45:03.279+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:45:03.304+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.207 seconds
[2024-11-08T13:45:33.877+0000] {processor.py:186} INFO - Started process (PID=334) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:45:33.879+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:45:33.884+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:45:33.883+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:45:34.016+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:45:34.046+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:45:34.046+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:45:34.112+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:45:34.111+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:45:34.143+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.277 seconds
[2024-11-08T13:46:04.563+0000] {processor.py:186} INFO - Started process (PID=400) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:46:04.564+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:46:04.569+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:46:04.568+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:46:04.753+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:46:04.798+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:46:04.797+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:46:04.844+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:46:04.844+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:46:04.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.326 seconds
[2024-11-08T13:46:35.475+0000] {processor.py:186} INFO - Started process (PID=466) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:46:35.477+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:46:35.482+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:46:35.481+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:46:35.602+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:46:35.628+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:46:35.627+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:46:35.667+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:46:35.667+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:46:35.694+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.255 seconds
[2024-11-08T13:47:06.310+0000] {processor.py:186} INFO - Started process (PID=532) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:47:06.311+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:47:06.315+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:47:06.315+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:47:06.499+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:47:06.528+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:47:06.527+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:47:06.560+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:47:06.560+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:47:06.584+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.285 seconds
[2024-11-08T13:47:37.349+0000] {processor.py:186} INFO - Started process (PID=598) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:47:37.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:47:37.355+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:47:37.354+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:47:37.520+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:47:37.559+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:47:37.559+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:47:37.602+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:47:37.601+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:47:37.641+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.301 seconds
[2024-11-08T13:48:07.881+0000] {processor.py:186} INFO - Started process (PID=664) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:48:07.883+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:48:07.886+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:48:07.886+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:48:08.039+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:48:08.068+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:48:08.068+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:48:08.099+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:48:08.099+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:48:08.126+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.258 seconds
[2024-11-08T13:48:38.639+0000] {processor.py:186} INFO - Started process (PID=730) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:48:38.640+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:48:38.644+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:48:38.643+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:48:38.766+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:48:38.791+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:48:38.791+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:48:38.822+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:48:38.821+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:48:38.848+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.217 seconds
[2024-11-08T13:49:09.101+0000] {processor.py:186} INFO - Started process (PID=796) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:49:09.102+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:49:09.106+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:49:09.105+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:49:09.229+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:49:09.254+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:49:09.254+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:49:09.284+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:49:09.283+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:49:09.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.215 seconds
[2024-11-08T13:49:39.518+0000] {processor.py:186} INFO - Started process (PID=862) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:49:39.519+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:49:39.523+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:49:39.522+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:49:39.645+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:49:39.671+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:49:39.671+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:49:39.701+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:49:39.701+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:49:39.728+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.219 seconds
[2024-11-08T13:50:10.306+0000] {processor.py:186} INFO - Started process (PID=928) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:50:10.308+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:50:10.311+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:50:10.311+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:50:10.431+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:50:10.456+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:50:10.456+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:50:10.485+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:50:10.485+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:50:10.512+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.214 seconds
[2024-11-08T13:50:40.923+0000] {processor.py:186} INFO - Started process (PID=994) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:50:40.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:50:40.928+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:50:40.927+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:50:41.055+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:50:41.083+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:50:41.083+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:50:41.120+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:50:41.120+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:50:41.146+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.231 seconds
[2024-11-08T13:51:12.150+0000] {processor.py:186} INFO - Started process (PID=1060) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:51:12.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:51:12.155+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:51:12.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:51:12.277+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:51:12.301+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:51:12.301+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:51:12.330+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:51:12.330+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:51:12.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.216 seconds
[2024-11-08T13:51:42.977+0000] {processor.py:186} INFO - Started process (PID=1126) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:51:42.979+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:51:42.984+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:51:42.983+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:51:43.121+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:51:43.147+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:51:43.146+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:51:43.179+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:51:43.178+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:51:43.206+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.241 seconds
[2024-11-08T13:54:51.150+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:54:51.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:54:51.155+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:54:51.154+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:54:51.302+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:54:51.367+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:54:51.366+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:54:51.423+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:54:51.423+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:54:51.456+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.314 seconds
[2024-11-08T13:55:21.587+0000] {processor.py:186} INFO - Started process (PID=143) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:55:21.589+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:55:21.592+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:55:21.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:55:21.714+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:55:21.741+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:55:21.740+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:55:21.771+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:55:21.771+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:55:21.796+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.217 seconds
[2024-11-08T13:55:52.322+0000] {processor.py:186} INFO - Started process (PID=210) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:55:52.323+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:55:52.326+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:55:52.326+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:55:52.446+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:55:52.477+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:55:52.476+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:55:52.506+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:55:52.505+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:55:52.531+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.218 seconds
[2024-11-08T13:56:23.601+0000] {processor.py:186} INFO - Started process (PID=276) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:56:23.603+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:56:23.607+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:56:23.607+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:56:23.760+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:56:23.790+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:56:23.790+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:56:23.826+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:56:23.825+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:56:23.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.259 seconds
[2024-11-08T13:56:53.962+0000] {processor.py:186} INFO - Started process (PID=342) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:56:53.963+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:56:53.967+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:56:53.966+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:56:54.089+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:56:54.113+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:56:54.112+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:56:54.144+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:56:54.143+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:56:54.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.216 seconds
[2024-11-08T13:57:24.931+0000] {processor.py:186} INFO - Started process (PID=408) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:57:24.933+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:57:24.944+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:57:24.942+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:57:25.098+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:57:25.136+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:57:25.135+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:57:25.179+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:57:25.178+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:57:25.233+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.318 seconds
[2024-11-08T13:57:56.177+0000] {processor.py:186} INFO - Started process (PID=474) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:57:56.178+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:57:56.183+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:57:56.182+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:57:56.359+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:57:56.399+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:57:56.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:57:56.465+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:57:56.464+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:57:56.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.333 seconds
[2024-11-08T13:58:27.453+0000] {processor.py:186} INFO - Started process (PID=540) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:58:27.456+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:58:27.465+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:58:27.464+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:58:27.658+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:58:27.693+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:58:27.692+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:58:27.739+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:58:27.738+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:58:27.769+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.352 seconds
[2024-11-08T13:58:58.237+0000] {processor.py:186} INFO - Started process (PID=606) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:58:58.238+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:58:58.242+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:58:58.242+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:58:58.426+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:58:58.454+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:58:58.454+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:58:58.487+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:58:58.487+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:58:58.515+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.287 seconds
[2024-11-08T13:59:29.233+0000] {processor.py:186} INFO - Started process (PID=672) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:59:29.234+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:59:29.239+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:59:29.238+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:59:29.413+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:59:29.446+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:59:29.445+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:59:29.477+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:59:29.477+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:59:29.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.280 seconds
[2024-11-08T13:59:59.753+0000] {processor.py:186} INFO - Started process (PID=738) to work on /opt/airflow/dags/etl.py
[2024-11-08T13:59:59.755+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T13:59:59.759+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:59:59.758+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T13:59:59.879+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T13:59:59.906+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:59:59.906+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T13:59:59.948+0000] {logging_mixin.py:190} INFO - [2024-11-08T13:59:59.948+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T13:59:59.979+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.236 seconds
[2024-11-08T14:00:30.640+0000] {processor.py:186} INFO - Started process (PID=804) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:00:30.642+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:00:30.645+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:00:30.645+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:00:30.781+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:00:30.807+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:00:30.807+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:00:30.839+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:00:30.839+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:00:30.866+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.235 seconds
[2024-11-08T14:03:08.767+0000] {processor.py:186} INFO - Started process (PID=71) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:03:08.769+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:03:08.776+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:03:08.775+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:03:08.954+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:03:09.027+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:03:09.027+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:03:09.072+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:03:09.071+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:03:09.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.345 seconds
[2024-11-08T14:03:39.256+0000] {processor.py:186} INFO - Started process (PID=137) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:03:39.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:03:39.264+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:03:39.264+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:03:39.405+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:03:39.429+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:03:39.429+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:03:39.458+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:03:39.458+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:03:39.486+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.241 seconds
[2024-11-08T14:04:10.400+0000] {processor.py:186} INFO - Started process (PID=203) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:04:10.402+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:04:10.407+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:04:10.406+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:04:10.524+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:04:10.548+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:04:10.548+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:04:10.576+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:04:10.576+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:04:10.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.216 seconds
[2024-11-08T14:04:40.918+0000] {processor.py:186} INFO - Started process (PID=269) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:04:40.920+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:04:40.924+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:04:40.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:04:41.057+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:04:41.086+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:04:41.086+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:04:41.119+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:04:41.119+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:04:41.152+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.244 seconds
[2024-11-08T14:05:11.266+0000] {processor.py:186} INFO - Started process (PID=335) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:05:11.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:05:11.271+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:05:11.270+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:05:11.391+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:05:11.415+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:05:11.415+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:05:11.446+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:05:11.446+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:05:11.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.214 seconds
[2024-11-08T14:05:42.225+0000] {processor.py:186} INFO - Started process (PID=401) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:05:42.229+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:05:42.234+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:05:42.233+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:05:42.454+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:05:42.486+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:05:42.485+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:05:42.524+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:05:42.524+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:05:42.557+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.351 seconds
[2024-11-08T14:06:12.739+0000] {processor.py:186} INFO - Started process (PID=467) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:06:12.740+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:06:12.743+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:06:12.743+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:06:12.874+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:06:12.904+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:06:12.903+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:06:12.935+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:06:12.935+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:06:12.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.231 seconds
[2024-11-08T14:06:43.677+0000] {processor.py:186} INFO - Started process (PID=533) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:06:43.678+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:06:43.681+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:06:43.681+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:06:43.844+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:06:43.872+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:06:43.872+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:06:43.908+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:06:43.908+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:06:43.935+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.266 seconds
[2024-11-08T14:07:14.670+0000] {processor.py:186} INFO - Started process (PID=599) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:07:14.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:07:14.674+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:07:14.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:07:14.801+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:07:14.829+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:07:14.829+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:07:14.858+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:07:14.858+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:07:14.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.222 seconds
[2024-11-08T14:07:45.698+0000] {processor.py:186} INFO - Started process (PID=665) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:07:45.700+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:07:45.707+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:07:45.706+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:07:45.971+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:07:46.010+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:07:46.009+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:07:46.065+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:07:46.064+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:07:46.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.427 seconds
[2024-11-08T14:08:17.035+0000] {processor.py:186} INFO - Started process (PID=731) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:08:17.041+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:08:17.053+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:08:17.051+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:08:17.328+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:08:17.354+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:08:17.354+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:08:17.387+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:08:17.387+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:08:17.415+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.411 seconds
[2024-11-08T14:08:47.672+0000] {processor.py:186} INFO - Started process (PID=797) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:08:47.674+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:08:47.678+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:08:47.678+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:08:47.867+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:08:47.903+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:08:47.903+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:08:47.944+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:08:47.944+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:08:47.976+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.316 seconds
[2024-11-08T14:09:18.260+0000] {processor.py:186} INFO - Started process (PID=863) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:09:18.263+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:09:18.273+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:09:18.272+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:09:18.510+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:09:18.554+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:09:18.553+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:09:18.608+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:09:18.607+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:09:18.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.401 seconds
[2024-11-08T14:09:49.254+0000] {processor.py:186} INFO - Started process (PID=929) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:09:49.256+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:09:49.260+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:09:49.259+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:09:49.400+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:09:49.439+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:09:49.439+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:09:49.484+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:09:49.484+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:09:49.529+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.284 seconds
[2024-11-08T14:10:19.762+0000] {processor.py:186} INFO - Started process (PID=995) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:10:19.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:10:19.767+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:10:19.766+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:10:19.890+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:10:19.916+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:10:19.915+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:10:19.945+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:10:19.945+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:10:19.980+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.225 seconds
[2024-11-08T14:10:50.379+0000] {processor.py:186} INFO - Started process (PID=1061) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:10:50.380+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:10:50.384+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:10:50.383+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:10:50.517+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:10:50.543+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:10:50.543+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:10:50.577+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:10:50.577+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:10:50.612+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.243 seconds
[2024-11-08T14:11:21.104+0000] {processor.py:186} INFO - Started process (PID=1127) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:11:21.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:11:21.126+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:11:21.124+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:11:21.312+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:11:21.339+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:11:21.339+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:11:21.374+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:11:21.374+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:11:21.400+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.339 seconds
[2024-11-08T14:11:52.343+0000] {processor.py:186} INFO - Started process (PID=1193) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:11:52.344+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:11:52.349+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:11:52.348+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:11:52.526+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:11:52.560+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:11:52.560+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:11:52.599+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:11:52.599+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:11:52.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.306 seconds
[2024-11-08T14:12:23.489+0000] {processor.py:186} INFO - Started process (PID=1259) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:12:23.491+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:12:23.497+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:12:23.496+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:12:23.644+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:12:23.669+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:12:23.669+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:12:23.700+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:12:23.699+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:12:23.732+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.257 seconds
[2024-11-08T14:12:54.549+0000] {processor.py:186} INFO - Started process (PID=1325) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:12:54.551+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:12:54.555+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:12:54.555+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:12:54.680+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:12:54.707+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:12:54.707+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:12:54.738+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:12:54.737+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:12:54.768+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.233 seconds
[2024-11-08T14:13:25.342+0000] {processor.py:186} INFO - Started process (PID=1391) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:13:25.345+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:13:25.350+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:13:25.349+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:13:25.564+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:13:25.604+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:13:25.603+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:13:25.667+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:13:25.667+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:13:25.705+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.378 seconds
[2024-11-08T14:13:55.813+0000] {processor.py:186} INFO - Started process (PID=1457) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:13:55.815+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:13:55.818+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:13:55.817+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:13:56.017+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:13:56.060+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:13:56.060+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:13:56.116+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:13:56.116+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:13:56.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.355 seconds
[2024-11-08T14:14:26.244+0000] {processor.py:186} INFO - Started process (PID=1523) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:14:26.246+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:14:26.250+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:14:26.250+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:14:26.428+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:14:26.466+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:14:26.465+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:14:26.518+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:14:26.517+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:14:26.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.335 seconds
[2024-11-08T14:55:28.087+0000] {processor.py:186} INFO - Started process (PID=70) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:55:28.089+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:55:28.094+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:55:28.094+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:55:28.268+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:55:28.306+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:55:28.305+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:55:28.336+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:55:28.336+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:55:28.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.287 seconds
[2024-11-08T14:55:58.801+0000] {processor.py:186} INFO - Started process (PID=136) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:55:58.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:55:58.807+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:55:58.807+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:55:58.941+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:55:58.971+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:55:58.970+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:55:59.001+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:55:59.001+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:55:59.031+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.239 seconds
[2024-11-08T14:56:29.245+0000] {processor.py:186} INFO - Started process (PID=203) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:56:29.250+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:56:29.267+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:56:29.265+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:56:29.668+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:56:29.706+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:56:29.706+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:56:29.749+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:56:29.749+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:56:29.784+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.551 seconds
[2024-11-08T14:56:59.989+0000] {processor.py:186} INFO - Started process (PID=268) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:56:59.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:57:00.002+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:57:00.001+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:57:00.508+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:57:00.581+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:57:00.580+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:57:00.669+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:57:00.669+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:57:00.719+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.794 seconds
[2024-11-08T14:57:31.900+0000] {processor.py:186} INFO - Started process (PID=334) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:57:31.905+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:57:31.919+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:57:31.918+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:57:32.163+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:57:32.189+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:57:32.189+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:57:32.222+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:57:32.222+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:57:32.252+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.385 seconds
[2024-11-08T14:58:02.993+0000] {processor.py:186} INFO - Started process (PID=400) to work on /opt/airflow/dags/etl.py
[2024-11-08T14:58:02.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T14:58:02.999+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:58:02.998+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T14:58:03.332+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T14:58:03.421+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:58:03.420+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T14:58:03.489+0000] {logging_mixin.py:190} INFO - [2024-11-08T14:58:03.489+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T14:58:03.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.554 seconds
[2024-11-08T15:01:04.403+0000] {processor.py:186} INFO - Started process (PID=71) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:01:04.406+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:01:04.415+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:01:04.415+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:01:04.949+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:01:05.051+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:01:05.050+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:01:05.199+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:01:05.198+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:01:05.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.895 seconds
[2024-11-08T15:01:35.634+0000] {processor.py:186} INFO - Started process (PID=137) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:01:35.635+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:01:35.639+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:01:35.639+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:01:35.824+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:01:35.856+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:01:35.856+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:01:35.893+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:01:35.892+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:01:35.925+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.300 seconds
[2024-11-08T15:02:06.040+0000] {processor.py:186} INFO - Started process (PID=203) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:02:06.042+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:02:06.045+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:02:06.045+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:02:06.165+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:02:06.190+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:02:06.190+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:02:06.219+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:02:06.219+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:02:06.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.216 seconds
[2024-11-08T15:02:37.150+0000] {processor.py:186} INFO - Started process (PID=270) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:02:37.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:02:37.158+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:02:37.157+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:02:37.358+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:02:37.396+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:02:37.396+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:02:37.446+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:02:37.446+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:02:37.479+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.371 seconds
[2024-11-08T15:03:08.455+0000] {processor.py:186} INFO - Started process (PID=336) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:03:08.457+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:03:08.460+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:03:08.460+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:03:08.605+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:03:08.634+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:03:08.633+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:03:08.671+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:03:08.670+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:03:08.696+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.254 seconds
[2024-11-08T15:03:38.856+0000] {processor.py:186} INFO - Started process (PID=402) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:03:38.861+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:03:38.865+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:03:38.864+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:03:39.040+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:03:39.089+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:03:39.088+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:03:39.161+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:03:39.160+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:03:39.224+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.379 seconds
[2024-11-08T15:04:09.549+0000] {processor.py:186} INFO - Started process (PID=468) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:04:09.550+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:04:09.554+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:04:09.553+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:04:09.680+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:04:09.705+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:04:09.704+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:04:09.734+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:04:09.733+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:04:09.758+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.217 seconds
[2024-11-08T15:04:40.408+0000] {processor.py:186} INFO - Started process (PID=534) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:04:40.410+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:04:40.417+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:04:40.417+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:04:40.645+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:04:40.671+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:04:40.670+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:04:40.711+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:04:40.711+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:04:40.747+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.355 seconds
[2024-11-08T15:05:11.256+0000] {processor.py:186} INFO - Started process (PID=600) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:05:11.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:05:11.265+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:05:11.265+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:05:11.429+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:05:11.455+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:05:11.455+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:05:11.486+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:05:11.486+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:05:11.529+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.289 seconds
[2024-11-08T15:05:42.169+0000] {processor.py:186} INFO - Started process (PID=666) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:05:42.171+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:05:42.175+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:05:42.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:05:42.300+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:05:42.328+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:05:42.328+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:05:42.359+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:05:42.359+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:05:42.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.234 seconds
[2024-11-08T15:06:12.897+0000] {processor.py:186} INFO - Started process (PID=731) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:06:12.898+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:06:12.902+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:06:12.901+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:06:13.051+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:06:13.079+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:06:13.079+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:06:13.114+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:06:13.114+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:06:13.141+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.252 seconds
[2024-11-08T15:06:43.434+0000] {processor.py:186} INFO - Started process (PID=797) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:06:43.437+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:06:43.444+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:06:43.443+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:06:43.668+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:06:43.711+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:06:43.710+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:06:43.756+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:06:43.755+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:06:43.792+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.378 seconds
[2024-11-08T15:07:14.886+0000] {processor.py:186} INFO - Started process (PID=863) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:07:14.889+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:07:14.894+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:07:14.893+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:07:15.066+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:07:15.093+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:07:15.093+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:07:15.139+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:07:15.139+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:07:15.165+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.291 seconds
[2024-11-08T15:07:45.718+0000] {processor.py:186} INFO - Started process (PID=929) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:07:45.721+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:07:45.729+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:07:45.729+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:07:45.930+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:07:45.964+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:07:45.963+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:07:46.006+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:07:46.005+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:07:46.034+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.330 seconds
[2024-11-08T15:08:16.988+0000] {processor.py:186} INFO - Started process (PID=994) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:08:16.990+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:08:16.996+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:08:16.995+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:08:17.208+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:08:17.238+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:08:17.238+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:08:17.294+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:08:17.294+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:08:17.342+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.362 seconds
[2024-11-08T15:08:47.703+0000] {processor.py:186} INFO - Started process (PID=1060) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:08:47.705+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:08:47.709+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:08:47.709+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:08:47.863+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:08:47.893+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:08:47.893+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:08:47.933+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:08:47.932+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:08:47.964+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.271 seconds
[2024-11-08T15:09:18.157+0000] {processor.py:186} INFO - Started process (PID=1126) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:09:18.158+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:09:18.162+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:09:18.162+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:09:18.307+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:09:18.332+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:09:18.332+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:09:18.366+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:09:18.366+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:09:18.398+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.251 seconds
[2024-11-08T15:09:48.834+0000] {processor.py:186} INFO - Started process (PID=1193) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:09:48.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:09:48.838+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:09:48.838+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:09:48.969+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:09:48.996+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:09:48.995+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:09:49.032+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:09:49.032+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:09:49.062+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.236 seconds
[2024-11-08T15:12:39.194+0000] {processor.py:186} INFO - Started process (PID=71) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:12:39.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:12:39.198+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:12:39.198+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:12:39.339+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:12:39.374+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:12:39.374+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:12:39.414+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:12:39.414+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:12:39.449+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.264 seconds
[2024-11-08T15:13:10.082+0000] {processor.py:186} INFO - Started process (PID=137) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:13:10.084+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:13:10.088+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:13:10.087+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:13:10.221+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:13:10.247+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:13:10.246+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:13:10.277+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:13:10.277+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:13:10.301+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.231 seconds
[2024-11-08T15:13:41.037+0000] {processor.py:186} INFO - Started process (PID=203) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:13:41.038+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:13:41.042+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:13:41.041+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:13:41.220+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:13:41.253+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:13:41.252+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:13:41.299+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:13:41.299+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:13:41.327+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.301 seconds
[2024-11-08T15:14:12.042+0000] {processor.py:186} INFO - Started process (PID=269) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:14:12.044+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:14:12.049+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:14:12.048+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:14:12.250+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:14:12.284+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:14:12.283+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:14:12.330+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:14:12.330+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:14:12.360+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.330 seconds
[2024-11-08T15:14:42.520+0000] {processor.py:186} INFO - Started process (PID=335) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:14:42.521+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:14:42.525+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:14:42.525+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:14:42.663+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:14:42.693+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:14:42.693+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:14:42.734+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:14:42.734+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:14:42.766+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.255 seconds
[2024-11-08T15:15:12.951+0000] {processor.py:186} INFO - Started process (PID=401) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:15:12.953+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:15:12.957+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:15:12.957+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:15:13.100+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:15:13.130+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:15:13.130+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:15:13.166+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:15:13.166+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:15:13.198+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.258 seconds
[2024-11-08T15:19:02.502+0000] {processor.py:186} INFO - Started process (PID=74) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:19:02.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:19:02.507+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:19:02.506+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:19:02.641+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:19:02.813+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:19:02.812+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T15:19:02.827+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:19:02.827+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T15:19:02.837+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:19:02.837+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T15:19:02.849+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:19:02.849+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T15:19:02.859+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:19:02.858+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T15:19:02.869+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:19:02.869+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T15:19:02.879+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:19:02.879+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T15:19:02.880+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:19:02.880+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:19:02.902+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:19:02.902+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_etl_pipeline_with_separate_functions
[2024-11-08T15:19:02.915+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:19:02.915+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:19:02.953+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.459 seconds
[2024-11-08T15:19:34.007+0000] {processor.py:186} INFO - Started process (PID=140) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:19:34.008+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:19:34.012+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:19:34.012+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:19:34.178+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:19:34.241+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:19:34.240+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:19:34.304+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:19:34.304+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:19:34.352+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.353 seconds
[2024-11-08T15:20:04.634+0000] {processor.py:186} INFO - Started process (PID=206) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:20:04.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:20:04.640+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:20:04.640+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:20:04.983+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:20:05.044+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:20:05.043+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:20:05.099+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:20:05.099+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:20:05.140+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.518 seconds
[2024-11-08T15:20:35.602+0000] {processor.py:186} INFO - Started process (PID=272) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:20:35.604+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:20:35.615+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:20:35.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:20:35.898+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:20:35.963+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:20:35.962+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:20:36.065+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:20:36.065+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:20:36.137+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.556 seconds
[2024-11-08T15:21:06.604+0000] {processor.py:186} INFO - Started process (PID=338) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:21:06.607+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:21:06.615+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:21:06.614+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:21:06.844+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:21:06.919+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:21:06.918+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:21:06.984+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:21:06.983+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:21:07.069+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.534 seconds
[2024-11-08T15:21:38.218+0000] {processor.py:186} INFO - Started process (PID=406) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:21:38.223+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:21:38.237+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:21:38.235+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:26:18.263+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:26:18.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:26:18.270+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:26:18.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:26:18.502+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:26:18.729+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:26:18.728+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T15:26:18.751+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:26:18.750+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T15:26:18.767+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:26:18.766+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T15:26:18.788+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:26:18.787+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T15:26:18.807+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:26:18.806+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T15:26:18.828+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:26:18.827+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T15:26:18.845+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:26:18.845+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T15:26:18.847+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:26:18.846+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:26:18.871+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:26:18.870+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_etl_pipeline_with_separate_functions
[2024-11-08T15:26:18.891+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:26:18.891+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:26:18.925+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.674 seconds
[2024-11-08T15:27:01.034+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:27:01.037+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:27:01.042+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:27:01.041+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:27:01.379+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:27:01.426+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:27:01.425+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:27:01.473+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:27:01.472+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:27:01.506+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.484 seconds
[2024-11-08T15:27:32.086+0000] {processor.py:186} INFO - Started process (PID=140) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:27:32.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:27:32.093+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:27:32.092+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:27:32.391+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:27:32.435+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:27:32.435+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:27:32.508+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:27:32.507+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:27:32.564+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.498 seconds
[2024-11-08T15:28:02.760+0000] {processor.py:186} INFO - Started process (PID=207) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:28:02.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:28:02.769+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:28:02.768+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:28:03.100+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:28:03.160+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:28:03.159+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:28:03.198+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:28:03.198+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:28:03.255+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.511 seconds
[2024-11-08T15:28:33.371+0000] {processor.py:186} INFO - Started process (PID=274) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:28:33.373+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:28:33.377+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:28:33.377+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:28:33.563+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:28:33.616+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:28:33.616+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:28:33.671+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:28:33.670+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:28:33.715+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.356 seconds
[2024-11-08T15:29:04.462+0000] {processor.py:186} INFO - Started process (PID=341) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:29:04.464+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:29:04.468+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:29:04.467+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:29:04.685+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:29:04.716+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:29:04.716+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:29:04.761+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:29:04.761+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:29:04.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.349 seconds
[2024-11-08T15:29:35.439+0000] {processor.py:186} INFO - Started process (PID=409) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:29:35.441+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:29:35.449+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:29:35.448+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:29:35.791+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:29:35.844+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:29:35.843+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:29:35.906+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:29:35.906+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:29:35.959+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.537 seconds
[2024-11-08T15:30:06.580+0000] {processor.py:186} INFO - Started process (PID=476) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:30:06.587+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:30:06.603+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:30:06.601+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:30:06.888+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:30:06.921+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:30:06.921+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:30:06.969+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:30:06.968+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:30:07.008+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.447 seconds
[2024-11-08T15:30:37.669+0000] {processor.py:186} INFO - Started process (PID=543) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:30:37.670+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:30:37.675+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:30:37.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:30:37.869+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:30:37.915+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:30:37.914+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:30:37.982+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:30:37.981+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:30:38.036+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.379 seconds
[2024-11-08T15:31:08.650+0000] {processor.py:186} INFO - Started process (PID=610) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:31:08.652+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:31:08.658+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:31:08.657+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:31:09.004+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:31:09.078+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:31:09.077+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:31:09.117+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:31:09.116+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:31:09.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.519 seconds
[2024-11-08T15:31:39.777+0000] {processor.py:186} INFO - Started process (PID=678) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:31:39.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:31:39.804+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:31:39.803+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:31:40.198+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:31:40.285+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:31:40.283+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:31:40.419+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:31:40.419+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:31:40.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.755 seconds
[2024-11-08T15:32:11.048+0000] {processor.py:186} INFO - Started process (PID=746) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:32:11.051+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:32:11.057+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:32:11.056+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:32:11.373+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:32:11.436+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:32:11.435+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:32:11.488+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:32:11.488+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:32:11.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.496 seconds
[2024-11-08T15:32:42.144+0000] {processor.py:186} INFO - Started process (PID=813) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:32:42.168+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:32:42.198+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:32:42.197+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:32:42.410+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:32:42.451+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:32:42.451+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:32:42.530+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:32:42.529+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:32:42.592+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.479 seconds
[2024-11-08T15:33:12.854+0000] {processor.py:186} INFO - Started process (PID=880) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:33:12.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:33:12.863+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:33:12.862+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:33:13.097+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:33:13.134+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:33:13.133+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:33:13.180+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:33:13.180+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:33:13.216+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.377 seconds
[2024-11-08T15:33:43.612+0000] {processor.py:186} INFO - Started process (PID=947) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:33:43.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:33:43.624+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:33:43.623+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:33:44.094+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:33:44.134+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:33:44.134+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:33:44.191+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:33:44.190+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:33:44.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.641 seconds
[2024-11-08T15:34:15.858+0000] {processor.py:186} INFO - Started process (PID=1014) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:34:15.860+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:34:15.866+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:34:15.865+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:34:16.170+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:34:16.226+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:34:16.225+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:34:16.301+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:34:16.300+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:34:16.347+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.503 seconds
[2024-11-08T15:34:48.604+0000] {processor.py:186} INFO - Started process (PID=1078) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:34:48.608+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:34:48.620+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:34:48.619+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:34:48.868+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:34:48.917+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:34:48.915+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:34:49.073+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:34:49.072+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:34:49.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.617 seconds
[2024-11-08T15:35:19.466+0000] {processor.py:186} INFO - Started process (PID=1138) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:35:19.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:35:19.474+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:35:19.474+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:35:19.866+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:35:19.901+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:35:19.900+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:35:19.945+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:35:19.945+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:35:19.979+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.529 seconds
[2024-11-08T15:35:50.662+0000] {processor.py:186} INFO - Started process (PID=1203) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:35:50.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:35:50.672+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:35:50.671+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:35:50.980+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:35:51.048+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:35:51.047+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:35:51.141+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:35:51.140+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:35:51.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.556 seconds
[2024-11-08T15:36:23.084+0000] {processor.py:186} INFO - Started process (PID=1270) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:36:23.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:36:23.100+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:36:23.097+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:36:23.555+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:36:23.609+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:36:23.608+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:36:23.654+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:36:23.653+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:36:23.689+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.637 seconds
[2024-11-08T15:36:54.288+0000] {processor.py:186} INFO - Started process (PID=1337) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:36:54.292+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:36:54.299+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:36:54.297+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:36:54.687+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:36:54.736+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:36:54.735+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:36:54.783+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:36:54.782+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:36:54.817+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.557 seconds
[2024-11-08T15:37:25.730+0000] {processor.py:186} INFO - Started process (PID=1401) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:37:25.733+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:37:25.743+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:37:25.740+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:37:26.012+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:37:26.066+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:37:26.065+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:37:26.135+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:37:26.134+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:37:26.184+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.473 seconds
[2024-11-08T15:37:57.023+0000] {processor.py:186} INFO - Started process (PID=1468) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:37:57.026+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:37:57.032+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:37:57.031+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:37:57.264+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:37:57.298+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:37:57.297+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:37:57.341+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:37:57.340+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:37:57.378+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.378 seconds
[2024-11-08T15:38:27.747+0000] {processor.py:186} INFO - Started process (PID=1532) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:38:27.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:38:27.761+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:38:27.760+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:38:27.977+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:38:28.013+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:38:28.013+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:38:28.051+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:38:28.050+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:38:28.084+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.364 seconds
[2024-11-08T15:38:59.042+0000] {processor.py:186} INFO - Started process (PID=1597) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:38:59.043+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:38:59.048+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:38:59.047+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:38:59.244+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:38:59.280+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:38:59.280+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:38:59.322+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:38:59.322+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:38:59.353+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.325 seconds
[2024-11-08T15:39:30.571+0000] {processor.py:186} INFO - Started process (PID=1663) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:39:30.574+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:39:30.579+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:39:30.578+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:39:30.842+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:39:30.887+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:39:30.887+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:39:30.949+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:39:30.949+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:39:30.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.440 seconds
[2024-11-08T15:40:01.639+0000] {processor.py:186} INFO - Started process (PID=1729) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:40:01.641+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:40:01.645+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:40:01.644+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:40:01.801+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:40:01.834+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:40:01.833+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:40:01.874+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:40:01.874+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:40:01.909+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.281 seconds
[2024-11-08T15:40:32.220+0000] {processor.py:186} INFO - Started process (PID=1794) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:40:32.221+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:40:32.224+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:40:32.224+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:40:32.322+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:40:32.343+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:40:32.343+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:40:32.367+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:40:32.367+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:40:32.391+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.177 seconds
[2024-11-08T15:41:02.668+0000] {processor.py:186} INFO - Started process (PID=1867) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:41:02.669+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:41:02.672+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:41:02.671+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:41:02.772+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:41:02.795+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:41:02.795+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:41:02.821+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:41:02.821+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:41:02.843+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.182 seconds
[2024-11-08T15:41:33.132+0000] {processor.py:186} INFO - Started process (PID=1934) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:41:33.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:41:33.139+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:41:33.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:41:33.262+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:41:33.287+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:41:33.287+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:41:33.314+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:41:33.314+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:41:33.337+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.217 seconds
[2024-11-08T15:42:03.441+0000] {processor.py:186} INFO - Started process (PID=2001) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:42:03.442+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:42:03.445+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:42:03.444+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:42:03.543+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:42:03.564+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:42:03.564+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:42:03.591+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:42:03.590+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:42:03.613+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.179 seconds
[2024-11-08T15:42:33.734+0000] {processor.py:186} INFO - Started process (PID=2067) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:42:33.735+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:42:33.738+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:42:33.738+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:42:33.866+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:42:33.888+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:42:33.888+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:42:33.917+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:42:33.917+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:42:33.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.216 seconds
[2024-11-08T15:43:04.726+0000] {processor.py:186} INFO - Started process (PID=2134) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:43:04.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:43:04.732+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:43:04.731+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:43:04.864+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:43:04.893+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:43:04.892+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:43:04.925+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:43:04.925+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:43:04.955+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.238 seconds
[2024-11-08T15:43:35.746+0000] {processor.py:186} INFO - Started process (PID=2201) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:43:35.748+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:43:35.753+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:43:35.752+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:43:35.920+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:43:35.951+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:43:35.950+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:43:35.996+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:43:35.996+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:43:36.032+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.298 seconds
[2024-11-08T15:44:06.656+0000] {processor.py:186} INFO - Started process (PID=2268) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:44:06.657+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:44:06.662+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:44:06.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:44:06.831+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:44:06.865+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:44:06.864+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:44:06.911+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:44:06.910+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:44:06.942+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.294 seconds
[2024-11-08T15:44:37.810+0000] {processor.py:186} INFO - Started process (PID=2335) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:44:37.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:44:37.815+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:44:37.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:44:37.938+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:44:37.966+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:44:37.966+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:44:37.997+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:44:37.997+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:44:38.032+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.230 seconds
[2024-11-08T15:45:08.274+0000] {processor.py:186} INFO - Started process (PID=2402) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:45:08.275+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:45:08.279+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:45:08.278+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:45:08.378+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:45:08.403+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:45:08.402+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:45:08.650+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:45:08.649+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:45:08.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.404 seconds
[2024-11-08T15:45:38.929+0000] {processor.py:186} INFO - Started process (PID=2469) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:45:38.930+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:45:38.933+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:45:38.933+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:45:39.053+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:45:39.076+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:45:39.075+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:45:39.296+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:45:39.296+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:45:39.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.400 seconds
[2024-11-08T15:46:09.431+0000] {processor.py:186} INFO - Started process (PID=2536) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:46:09.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:46:09.436+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:46:09.435+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:46:09.552+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:46:09.574+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:46:09.574+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:46:09.603+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:46:09.602+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:46:09.625+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.201 seconds
[2024-11-08T15:46:40.130+0000] {processor.py:186} INFO - Started process (PID=2603) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:46:40.132+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:46:40.135+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:46:40.134+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:46:40.257+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:46:40.279+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:46:40.278+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:46:40.304+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:46:40.304+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:46:40.325+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.206 seconds
[2024-11-08T15:47:10.518+0000] {processor.py:186} INFO - Started process (PID=2670) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:47:10.520+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:47:10.523+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:47:10.522+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:47:10.624+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:47:10.843+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:47:10.842+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:47:10.870+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:47:10.869+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:47:10.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.387 seconds
[2024-11-08T15:47:41.868+0000] {processor.py:186} INFO - Started process (PID=2737) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:47:41.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:47:41.872+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:47:41.872+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:47:41.973+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:47:41.996+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:47:41.995+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:47:42.219+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:47:42.219+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:47:42.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.377 seconds
[2024-11-08T15:48:13.228+0000] {processor.py:186} INFO - Started process (PID=2804) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:48:13.229+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:48:13.232+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:48:13.232+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:48:13.335+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:48:13.357+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:48:13.357+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:48:13.569+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:48:13.569+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:48:13.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.371 seconds
[2024-11-08T15:48:44.656+0000] {processor.py:186} INFO - Started process (PID=2871) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:48:44.657+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:48:44.659+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:48:44.659+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:48:44.762+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:48:44.782+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:48:44.782+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:48:44.980+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:48:44.980+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:48:45.004+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.354 seconds
[2024-11-08T15:49:15.269+0000] {processor.py:186} INFO - Started process (PID=2938) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:49:15.271+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:49:15.273+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:49:15.273+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:49:15.543+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:49:15.562+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:49:15.562+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:49:15.586+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:49:15.586+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:49:15.607+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.345 seconds
[2024-11-08T15:49:45.782+0000] {processor.py:186} INFO - Started process (PID=3005) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:49:45.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:49:45.785+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:49:45.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:49:46.085+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:49:46.111+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:49:46.111+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:49:46.143+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:49:46.143+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:49:46.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.401 seconds
[2024-11-08T15:50:16.341+0000] {processor.py:186} INFO - Started process (PID=3072) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:50:16.343+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:50:16.347+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:50:16.346+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:50:16.484+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:50:16.725+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:50:16.724+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:50:16.756+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:50:16.756+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:50:16.773+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.442 seconds
[2024-11-08T15:50:47.286+0000] {processor.py:186} INFO - Started process (PID=3139) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:50:47.288+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:50:47.290+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:50:47.290+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:50:47.385+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:50:47.579+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:50:47.579+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:50:47.603+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:50:47.602+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:50:47.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.343 seconds
[2024-11-08T15:51:18.192+0000] {processor.py:186} INFO - Started process (PID=3206) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:51:18.194+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:51:18.196+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:51:18.196+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:51:18.495+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:51:18.522+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:51:18.522+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:51:18.550+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:51:18.550+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:51:18.571+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.385 seconds
[2024-11-08T15:51:49.439+0000] {processor.py:186} INFO - Started process (PID=3273) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:51:49.440+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:51:49.443+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:51:49.443+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:51:49.710+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:51:49.729+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:51:49.728+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:51:49.752+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:51:49.752+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:51:49.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.341 seconds
[2024-11-08T15:52:20.658+0000] {processor.py:186} INFO - Started process (PID=3340) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:52:20.659+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:52:20.662+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:52:20.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:52:20.928+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:52:20.948+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:52:20.947+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:52:20.972+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:52:20.972+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:52:20.996+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.345 seconds
[2024-11-08T15:52:51.637+0000] {processor.py:186} INFO - Started process (PID=3407) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:52:51.639+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:52:51.644+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:52:51.643+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:52:51.955+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:52:51.974+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:52:51.974+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:52:51.995+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:52:51.995+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:52:52.020+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.397 seconds
[2024-11-08T15:53:22.228+0000] {processor.py:186} INFO - Started process (PID=3474) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:53:22.229+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:53:22.231+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:53:22.231+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:53:22.501+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:53:22.527+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:53:22.527+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:53:22.553+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:53:22.553+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:53:22.574+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.353 seconds
[2024-11-08T15:53:52.668+0000] {processor.py:186} INFO - Started process (PID=3541) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:53:52.669+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:53:52.673+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:53:52.672+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:53:52.962+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:53:52.981+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:53:52.980+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:53:53.003+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:53:53.002+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:53:53.028+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.368 seconds
[2024-11-08T15:54:24.047+0000] {processor.py:186} INFO - Started process (PID=3608) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:54:24.049+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:54:24.056+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:54:24.055+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:54:24.441+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:54:24.459+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:54:24.459+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:54:24.484+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:54:24.483+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:54:24.505+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.469 seconds
[2024-11-08T15:54:54.929+0000] {processor.py:186} INFO - Started process (PID=3675) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:54:54.930+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:54:54.932+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:54:54.932+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:54:55.196+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:54:55.215+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:54:55.215+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:54:55.238+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:54:55.237+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:54:55.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.334 seconds
[2024-11-08T15:55:25.842+0000] {processor.py:186} INFO - Started process (PID=3742) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:55:25.843+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:55:25.847+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:55:25.847+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:55:26.150+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:55:26.167+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:55:26.167+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:55:26.190+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:55:26.190+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:55:26.212+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.380 seconds
[2024-11-08T15:55:56.432+0000] {processor.py:186} INFO - Started process (PID=3809) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:55:56.433+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:55:56.438+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:55:56.437+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:55:56.607+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:55:56.642+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:55:56.641+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:55:56.697+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:55:56.697+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:55:56.737+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.316 seconds
[2024-11-08T15:56:27.038+0000] {processor.py:186} INFO - Started process (PID=3876) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:56:27.041+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:56:27.048+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:56:27.048+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:56:27.217+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:56:27.247+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:56:27.246+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:56:27.285+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:56:27.284+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:56:27.310+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.286 seconds
[2024-11-08T15:56:57.427+0000] {processor.py:186} INFO - Started process (PID=3943) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:56:57.428+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:56:57.432+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:56:57.432+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:56:57.540+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:56:57.562+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:56:57.561+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:56:57.588+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:56:57.587+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:56:57.608+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.190 seconds
[2024-11-08T15:57:27.680+0000] {processor.py:186} INFO - Started process (PID=4010) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:57:27.682+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:57:27.684+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:57:27.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:57:27.800+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:57:27.822+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:57:27.822+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:57:27.849+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:57:27.848+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:57:27.871+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.199 seconds
[2024-11-08T15:57:58.407+0000] {processor.py:186} INFO - Started process (PID=4077) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:57:58.409+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:57:58.413+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:57:58.412+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:57:58.547+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:57:58.575+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:57:58.575+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:57:58.609+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:57:58.609+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:57:58.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.230 seconds
[2024-11-08T15:58:28.935+0000] {processor.py:186} INFO - Started process (PID=4144) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:58:28.936+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:58:28.940+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:58:28.939+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:58:29.043+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:58:29.067+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:58:29.066+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:58:29.092+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:58:29.092+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:58:29.113+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.186 seconds
[2024-11-08T15:58:59.348+0000] {processor.py:186} INFO - Started process (PID=4211) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:58:59.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:58:59.353+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:58:59.352+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:58:59.455+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:58:59.476+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:58:59.475+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:58:59.506+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:58:59.506+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:58:59.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.190 seconds
[2024-11-08T15:59:30.239+0000] {processor.py:186} INFO - Started process (PID=4278) to work on /opt/airflow/dags/etl.py
[2024-11-08T15:59:30.240+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T15:59:30.243+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:59:30.242+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T15:59:30.337+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T15:59:30.358+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:59:30.358+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T15:59:30.382+0000] {logging_mixin.py:190} INFO - [2024-11-08T15:59:30.382+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T15:59:30.404+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.172 seconds
[2024-11-08T16:00:00.896+0000] {processor.py:186} INFO - Started process (PID=4345) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:00:00.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:00:00.900+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:00:00.900+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:00:00.995+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:00:01.016+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:00:01.016+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:00:01.048+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:00:01.048+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:00:01.070+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.180 seconds
[2024-11-08T16:00:31.216+0000] {processor.py:186} INFO - Started process (PID=4412) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:00:31.217+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:00:31.221+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:00:31.220+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:00:31.319+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:00:31.341+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:00:31.341+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:00:31.365+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:00:31.365+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:00:31.385+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.177 seconds
[2024-11-08T16:01:01.597+0000] {processor.py:186} INFO - Started process (PID=4479) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:01:01.598+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:01:01.601+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:01:01.600+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:01:01.728+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:01:01.755+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:01:01.755+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:01:01.793+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:01:01.793+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:01:01.824+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.237 seconds
[2024-11-08T16:01:32.041+0000] {processor.py:186} INFO - Started process (PID=4546) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:01:32.043+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:01:32.046+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:01:32.046+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:01:32.202+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:01:32.224+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:01:32.224+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:01:32.248+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:01:32.248+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:01:32.268+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.236 seconds
[2024-11-08T16:02:03.085+0000] {processor.py:186} INFO - Started process (PID=4613) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:02:03.086+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:02:03.088+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:02:03.088+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:02:03.189+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:02:03.214+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:02:03.214+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:02:03.244+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:02:03.243+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:02:03.266+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.187 seconds
[2024-11-08T16:02:33.752+0000] {processor.py:186} INFO - Started process (PID=4680) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:02:33.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:02:33.757+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:02:33.756+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:02:33.872+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:02:33.898+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:02:33.897+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:02:33.929+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:02:33.928+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:02:33.952+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.213 seconds
[2024-11-08T16:03:04.067+0000] {processor.py:186} INFO - Started process (PID=4747) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:03:04.068+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:03:04.070+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:03:04.070+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:03:04.184+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:03:04.204+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:03:04.204+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:03:04.230+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:03:04.229+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:03:04.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.201 seconds
[2024-11-08T16:03:34.352+0000] {processor.py:186} INFO - Started process (PID=4815) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:03:34.353+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:03:34.356+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:03:34.356+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:03:34.450+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:03:34.472+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:03:34.472+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:03:34.498+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:03:34.498+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:03:34.525+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.180 seconds
[2024-11-08T16:04:05.507+0000] {processor.py:186} INFO - Started process (PID=4888) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:04:05.509+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:04:05.512+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:04:05.512+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:04:05.611+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:04:05.635+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:04:05.635+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:04:05.660+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:04:05.660+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:04:05.681+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.183 seconds
[2024-11-08T16:04:36.043+0000] {processor.py:186} INFO - Started process (PID=4955) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:04:36.044+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:04:36.047+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:04:36.047+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:04:36.169+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:04:36.198+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:04:36.198+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:04:36.235+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:04:36.234+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:04:36.264+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.229 seconds
[2024-11-08T16:05:06.705+0000] {processor.py:186} INFO - Started process (PID=5022) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:05:06.707+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:05:06.711+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:05:06.711+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:05:06.886+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:05:06.913+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:05:06.912+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:05:06.954+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:05:06.954+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:05:06.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.287 seconds
[2024-11-08T16:05:37.095+0000] {processor.py:186} INFO - Started process (PID=5089) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:05:37.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:05:37.099+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:05:37.099+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:05:37.241+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:05:37.267+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:05:37.266+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:05:37.305+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:05:37.305+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:05:37.332+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.246 seconds
[2024-11-08T16:06:07.834+0000] {processor.py:186} INFO - Started process (PID=5156) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:06:07.836+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:06:07.840+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:06:07.840+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:06:07.969+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:06:07.993+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:06:07.992+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:06:08.027+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:06:08.027+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:06:08.051+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.228 seconds
[2024-11-08T16:06:38.647+0000] {processor.py:186} INFO - Started process (PID=5223) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:06:38.648+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:06:38.651+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:06:38.650+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:06:38.747+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:06:38.768+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:06:38.768+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:06:38.793+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:06:38.793+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:06:38.818+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.177 seconds
[2024-11-08T16:07:09.754+0000] {processor.py:186} INFO - Started process (PID=5290) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:07:09.755+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:07:09.759+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:07:09.758+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:07:09.883+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:07:09.903+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:07:09.903+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:07:09.928+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:07:09.927+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:07:09.975+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.231 seconds
[2024-11-08T16:07:40.690+0000] {processor.py:186} INFO - Started process (PID=5357) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:07:40.691+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:07:40.694+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:07:40.694+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:07:40.791+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:07:40.813+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:07:40.812+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:07:40.841+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:07:40.841+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:07:40.872+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.189 seconds
[2024-11-08T16:08:11.586+0000] {processor.py:186} INFO - Started process (PID=5424) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:08:11.587+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:08:11.590+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:08:11.590+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:08:11.702+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:08:11.732+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:08:11.731+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:08:11.767+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:08:11.767+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:08:11.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.221 seconds
[2024-11-08T16:08:42.554+0000] {processor.py:186} INFO - Started process (PID=5491) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:08:42.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:08:42.563+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:08:42.562+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:08:42.677+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:08:42.700+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:08:42.699+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:08:42.727+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:08:42.727+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:08:42.750+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.203 seconds
[2024-11-08T16:09:13.414+0000] {processor.py:186} INFO - Started process (PID=5558) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:09:13.415+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:09:13.418+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:09:13.418+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:09:13.532+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:09:13.558+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:09:13.557+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:09:13.584+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:09:13.583+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:09:13.614+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.208 seconds
[2024-11-08T16:09:45.422+0000] {processor.py:186} INFO - Started process (PID=5625) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:09:45.424+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:09:45.429+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:09:45.428+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:09:45.645+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:09:45.680+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:09:45.680+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:09:45.722+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:09:45.722+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:09:45.769+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.357 seconds
[2024-11-08T16:10:16.110+0000] {processor.py:186} INFO - Started process (PID=5692) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:10:16.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:10:16.114+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:10:16.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:10:16.214+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:10:16.236+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:10:16.236+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:10:16.261+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:10:16.260+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:10:16.291+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.187 seconds
[2024-11-08T16:10:47.031+0000] {processor.py:186} INFO - Started process (PID=5757) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:10:47.033+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:10:47.036+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:10:47.036+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:10:47.162+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:10:47.190+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:10:47.190+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:10:47.226+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:10:47.226+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:10:47.260+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.236 seconds
[2024-11-08T16:11:17.476+0000] {processor.py:186} INFO - Started process (PID=5824) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:11:17.477+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:11:17.481+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:11:17.480+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:11:17.614+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:11:17.646+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:11:17.646+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:11:17.678+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:11:17.678+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:11:17.702+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.235 seconds
[2024-11-08T16:11:47.865+0000] {processor.py:186} INFO - Started process (PID=5891) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:11:47.867+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:11:47.870+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:11:47.869+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:11:47.984+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:11:48.006+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:11:48.005+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:11:48.033+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:11:48.033+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:11:48.053+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.197 seconds
[2024-11-08T16:12:18.155+0000] {processor.py:186} INFO - Started process (PID=5957) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:12:18.157+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:12:18.160+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:12:18.159+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:12:18.260+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:12:18.284+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:12:18.284+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:12:18.313+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:12:18.313+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:12:18.343+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.194 seconds
[2024-11-08T16:12:49.029+0000] {processor.py:186} INFO - Started process (PID=6024) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:12:49.030+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:12:49.033+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:12:49.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:12:49.130+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:12:49.152+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:12:49.152+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:12:49.178+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:12:49.178+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:12:49.208+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.185 seconds
[2024-11-08T16:13:19.496+0000] {processor.py:186} INFO - Started process (PID=6091) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:13:19.497+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:13:19.500+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:13:19.499+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:13:19.599+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:13:19.623+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:13:19.622+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:13:19.648+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:13:19.648+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:13:19.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.183 seconds
[2024-11-08T16:13:49.866+0000] {processor.py:186} INFO - Started process (PID=6158) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:13:49.867+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:13:49.870+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:13:49.870+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:13:49.964+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:13:49.987+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:13:49.986+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:13:50.017+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:13:50.016+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:13:50.041+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.182 seconds
[2024-11-08T16:14:20.455+0000] {processor.py:186} INFO - Started process (PID=6225) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:14:20.465+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:14:20.468+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:14:20.468+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:14:20.604+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:14:20.625+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:14:20.625+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:14:20.651+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:14:20.651+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:14:20.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.231 seconds
[2024-11-08T16:14:50.869+0000] {processor.py:186} INFO - Started process (PID=6293) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:14:50.870+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:14:50.873+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:14:50.873+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:14:50.977+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:14:50.999+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:14:50.998+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:14:51.040+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:14:51.040+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:14:51.064+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.201 seconds
[2024-11-08T16:15:21.266+0000] {processor.py:186} INFO - Started process (PID=6361) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:15:21.267+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:15:21.270+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:15:21.270+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:15:21.368+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:15:21.390+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:15:21.390+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:15:21.416+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:15:21.416+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:15:21.441+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.181 seconds
[2024-11-08T16:15:51.530+0000] {processor.py:186} INFO - Started process (PID=6426) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:15:51.531+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:15:51.534+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:15:51.533+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:15:51.641+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:15:51.664+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:15:51.664+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:15:51.691+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:15:51.691+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:15:51.715+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.192 seconds
[2024-11-08T16:16:22.406+0000] {processor.py:186} INFO - Started process (PID=6493) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:16:22.408+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:16:22.415+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:16:22.413+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:16:22.625+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:16:22.669+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:16:22.668+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:16:22.730+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:16:22.730+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:16:22.778+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.383 seconds
[2024-11-08T16:16:52.847+0000] {processor.py:186} INFO - Started process (PID=6561) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:16:52.848+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:16:52.852+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:16:52.851+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:16:52.993+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:16:53.019+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:16:53.019+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:16:53.051+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:16:53.051+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:16:53.085+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.247 seconds
[2024-11-08T16:17:23.481+0000] {processor.py:186} INFO - Started process (PID=6628) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:17:23.482+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:17:23.484+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:17:23.484+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:17:23.583+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:17:23.603+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:17:23.603+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:17:23.628+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:17:23.628+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:17:23.653+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.179 seconds
[2024-11-08T16:17:54.162+0000] {processor.py:186} INFO - Started process (PID=6694) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:17:54.163+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:17:54.166+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:17:54.165+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:17:54.279+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:17:54.302+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:17:54.302+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:17:54.328+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:17:54.328+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:17:54.349+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.195 seconds
[2024-11-08T16:18:25.225+0000] {processor.py:186} INFO - Started process (PID=6761) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:18:25.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:18:25.229+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:18:25.228+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:18:25.329+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:18:25.349+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:18:25.349+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:18:25.375+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:18:25.375+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:18:25.398+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.181 seconds
[2024-11-08T16:18:55.735+0000] {processor.py:186} INFO - Started process (PID=6828) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:18:55.736+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:18:55.740+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:18:55.739+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:18:55.851+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:18:55.872+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:18:55.872+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:18:55.899+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:18:55.899+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:18:55.921+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.194 seconds
[2024-11-08T16:19:26.091+0000] {processor.py:186} INFO - Started process (PID=6895) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:19:26.092+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:19:26.096+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:19:26.095+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:19:26.207+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:19:26.228+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:19:26.228+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:19:26.254+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:19:26.253+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:19:26.280+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.198 seconds
[2024-11-08T16:19:56.771+0000] {processor.py:186} INFO - Started process (PID=6962) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:19:56.772+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:19:56.775+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:19:56.774+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:19:56.872+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:19:56.893+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:19:56.893+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:19:56.922+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:19:56.921+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:19:56.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.181 seconds
[2024-11-08T16:20:27.024+0000] {processor.py:186} INFO - Started process (PID=7029) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:20:27.025+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:20:27.028+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:20:27.027+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:20:27.125+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:20:27.150+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:20:27.150+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:20:27.177+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:20:27.177+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:20:27.202+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.185 seconds
[2024-11-08T16:20:57.287+0000] {processor.py:186} INFO - Started process (PID=7096) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:20:57.288+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:20:57.291+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:20:57.291+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:20:57.387+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:20:57.408+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:20:57.407+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:20:57.434+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:20:57.433+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:20:57.454+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.173 seconds
[2024-11-08T16:21:27.944+0000] {processor.py:186} INFO - Started process (PID=7162) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:21:27.945+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:21:27.949+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:21:27.948+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:21:28.103+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:21:28.134+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:21:28.134+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:21:28.180+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:21:28.179+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:21:28.241+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.307 seconds
[2024-11-08T16:21:58.354+0000] {processor.py:186} INFO - Started process (PID=7229) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:21:58.355+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:21:58.357+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:21:58.357+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:21:58.502+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:21:58.532+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:21:58.532+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:21:58.571+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:21:58.571+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:21:58.601+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.255 seconds
[2024-11-08T16:22:28.875+0000] {processor.py:186} INFO - Started process (PID=7296) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:22:28.876+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:22:28.879+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:22:28.879+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:22:28.978+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:22:28.999+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:22:28.998+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:22:29.026+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:22:29.025+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:22:29.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.182 seconds
[2024-11-08T16:22:59.215+0000] {processor.py:186} INFO - Started process (PID=7364) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:22:59.217+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:22:59.221+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:22:59.220+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:22:59.353+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:22:59.379+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:22:59.379+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:22:59.414+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:22:59.414+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:22:59.437+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.230 seconds
[2024-11-08T16:23:29.815+0000] {processor.py:186} INFO - Started process (PID=7430) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:23:29.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:23:29.819+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:23:29.819+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:23:29.917+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:23:29.939+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:23:29.939+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:23:29.964+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:23:29.964+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:23:29.988+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.179 seconds
[2024-11-08T16:24:00.097+0000] {processor.py:186} INFO - Started process (PID=7497) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:24:00.098+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:24:00.101+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:24:00.100+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:24:00.204+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:24:00.224+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:24:00.224+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:24:00.251+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:24:00.251+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:24:00.273+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.183 seconds
[2024-11-08T16:24:30.325+0000] {processor.py:186} INFO - Started process (PID=7564) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:24:30.326+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:24:30.328+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:24:30.328+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:24:30.440+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:24:30.462+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:24:30.461+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:24:30.498+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:24:30.498+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:24:30.520+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.203 seconds
[2024-11-08T16:25:00.626+0000] {processor.py:186} INFO - Started process (PID=7632) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:25:00.627+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:25:00.630+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:25:00.630+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:25:00.727+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:25:00.749+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:25:00.749+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:25:00.775+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:25:00.775+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:25:00.810+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.191 seconds
[2024-11-08T16:25:30.885+0000] {processor.py:186} INFO - Started process (PID=7699) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:25:30.886+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:25:30.889+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:25:30.889+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:25:30.992+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:25:31.016+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:25:31.016+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:25:31.042+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:25:31.042+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:25:31.067+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.189 seconds
[2024-11-08T16:26:01.111+0000] {processor.py:186} INFO - Started process (PID=7767) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:26:01.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:26:01.115+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:26:01.115+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:26:01.213+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:26:01.234+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:26:01.234+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:26:01.262+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:26:01.262+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:26:01.287+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.183 seconds
[2024-11-08T16:26:31.499+0000] {processor.py:186} INFO - Started process (PID=7834) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:26:31.500+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:26:31.504+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:26:31.504+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:26:31.609+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:26:31.629+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:26:31.629+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:26:31.656+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:26:31.655+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:26:31.679+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.189 seconds
[2024-11-08T16:27:01.912+0000] {processor.py:186} INFO - Started process (PID=7899) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:27:01.913+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:27:01.915+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:27:01.915+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:27:02.009+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:27:02.030+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:27:02.030+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:27:02.056+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:27:02.056+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:27:02.082+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.177 seconds
[2024-11-08T16:27:32.230+0000] {processor.py:186} INFO - Started process (PID=7966) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:27:32.231+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:27:32.234+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:27:32.233+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:27:32.327+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:27:32.348+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:27:32.348+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:27:32.373+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:27:32.373+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:27:32.395+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.172 seconds
[2024-11-08T16:28:03.018+0000] {processor.py:186} INFO - Started process (PID=8033) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:28:03.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:28:03.023+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:28:03.022+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:28:03.167+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:28:03.193+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:28:03.193+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:28:03.232+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:28:03.231+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:28:03.260+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.253 seconds
[2024-11-08T16:28:33.407+0000] {processor.py:186} INFO - Started process (PID=8100) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:28:33.409+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:28:33.413+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:28:33.412+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:28:33.553+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:28:33.590+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:28:33.590+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:28:33.627+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:28:33.626+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:28:33.666+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.269 seconds
[2024-11-08T16:29:04.484+0000] {processor.py:186} INFO - Started process (PID=8167) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:29:04.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:29:04.488+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:29:04.488+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:29:04.592+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:29:04.615+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:29:04.614+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:29:04.641+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:29:04.641+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:29:04.662+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.184 seconds
[2024-11-08T16:29:34.863+0000] {processor.py:186} INFO - Started process (PID=8232) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:29:34.864+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:29:34.867+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:29:34.866+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:29:34.981+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:29:35.001+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:29:35.001+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:29:35.031+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:29:35.030+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:29:35.054+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.198 seconds
[2024-11-08T16:30:05.372+0000] {processor.py:186} INFO - Started process (PID=8299) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:30:05.373+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:30:05.376+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:30:05.376+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:30:05.492+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:30:05.514+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:30:05.514+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:30:05.539+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:30:05.539+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:30:05.561+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.197 seconds
[2024-11-08T16:30:36.005+0000] {processor.py:186} INFO - Started process (PID=8366) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:30:36.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:30:36.009+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:30:36.008+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:30:36.105+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:30:36.126+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:30:36.126+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:30:36.152+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:30:36.151+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:30:36.172+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.174 seconds
[2024-11-08T16:31:07.060+0000] {processor.py:186} INFO - Started process (PID=8433) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:31:07.061+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:31:07.064+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:31:07.063+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:31:07.164+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:31:07.193+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:31:07.193+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:31:07.231+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:31:07.231+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:31:07.257+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.204 seconds
[2024-11-08T16:31:37.840+0000] {processor.py:186} INFO - Started process (PID=8506) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:31:37.841+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:31:37.844+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:31:37.843+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:31:37.941+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:31:37.962+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:31:37.962+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:31:37.988+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:31:37.988+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:31:38.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.177 seconds
[2024-11-08T16:32:08.100+0000] {processor.py:186} INFO - Started process (PID=8573) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:32:08.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:32:08.104+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:32:08.104+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:32:08.213+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:32:08.236+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:32:08.235+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:32:08.265+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:32:08.265+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:32:08.298+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.206 seconds
[2024-11-08T16:32:39.068+0000] {processor.py:186} INFO - Started process (PID=8640) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:32:39.069+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:32:39.072+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:32:39.072+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:32:39.165+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:32:39.186+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:32:39.186+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:32:39.211+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:32:39.210+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:32:39.232+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.172 seconds
[2024-11-08T16:33:09.404+0000] {processor.py:186} INFO - Started process (PID=8707) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:33:09.406+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:33:09.409+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:33:09.408+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:33:09.503+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:33:09.526+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:33:09.526+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:33:09.551+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:33:09.551+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:33:09.573+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.176 seconds
[2024-11-08T16:33:39.837+0000] {processor.py:186} INFO - Started process (PID=8774) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:33:39.839+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:33:39.841+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:33:39.841+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:33:39.936+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:33:39.959+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:33:39.959+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:33:39.988+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:33:39.988+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:33:40.012+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.184 seconds
[2024-11-08T16:34:10.601+0000] {processor.py:186} INFO - Started process (PID=8842) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:34:10.602+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:34:10.605+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:34:10.604+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:34:10.708+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:34:10.729+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:34:10.728+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:34:10.753+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:34:10.753+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:34:10.776+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.181 seconds
[2024-11-08T16:34:40.961+0000] {processor.py:186} INFO - Started process (PID=8909) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:34:40.962+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:34:40.965+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:34:40.964+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:34:41.076+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:34:41.098+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:34:41.098+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:34:41.123+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:34:41.122+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:34:41.143+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.189 seconds
[2024-11-08T16:35:11.984+0000] {processor.py:186} INFO - Started process (PID=8976) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:35:11.985+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:35:11.988+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:35:11.987+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:35:12.098+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:35:12.119+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:35:12.119+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:35:12.150+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:35:12.150+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:35:12.172+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.194 seconds
[2024-11-08T16:35:42.609+0000] {processor.py:186} INFO - Started process (PID=9043) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:35:42.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:35:42.613+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:35:42.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:35:42.710+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:35:42.731+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:35:42.731+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:35:42.756+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:35:42.756+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:35:42.776+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.176 seconds
[2024-11-08T16:36:13.356+0000] {processor.py:186} INFO - Started process (PID=9110) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:36:13.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:36:13.360+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:36:13.360+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:36:13.495+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:36:13.525+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:36:13.524+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:36:13.560+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:36:13.560+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:36:13.586+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.237 seconds
[2024-11-08T16:36:43.906+0000] {processor.py:186} INFO - Started process (PID=9177) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:36:43.907+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:36:43.910+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:36:43.909+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:36:44.014+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:36:44.042+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:36:44.042+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:36:44.069+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:36:44.069+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:36:44.091+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.193 seconds
[2024-11-08T16:37:14.168+0000] {processor.py:186} INFO - Started process (PID=9244) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:37:14.169+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:37:14.172+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:37:14.172+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:37:14.273+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:37:14.292+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:37:14.292+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:37:14.319+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:37:14.319+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:37:14.340+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.179 seconds
[2024-11-08T16:37:44.974+0000] {processor.py:186} INFO - Started process (PID=9310) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:37:44.975+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:37:44.978+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:37:44.978+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:37:45.071+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:37:45.092+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:37:45.091+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:37:45.117+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:37:45.117+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:37:45.138+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.171 seconds
[2024-11-08T16:38:16.052+0000] {processor.py:186} INFO - Started process (PID=9377) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:38:16.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:38:16.056+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:38:16.055+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:38:16.172+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:38:16.195+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:38:16.195+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:38:16.228+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:38:16.228+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:38:16.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.204 seconds
[2024-11-08T16:38:46.944+0000] {processor.py:186} INFO - Started process (PID=9444) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:38:46.945+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:38:46.948+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:38:46.947+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:38:47.047+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:38:47.068+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:38:47.067+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:38:47.094+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:38:47.094+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:38:47.277+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.340 seconds
[2024-11-08T16:39:17.564+0000] {processor.py:186} INFO - Started process (PID=9511) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:39:17.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:39:17.567+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:39:17.567+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:39:17.661+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:39:17.685+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:39:17.685+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:39:17.715+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:39:17.714+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:39:17.902+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.345 seconds
[2024-11-08T16:39:48.152+0000] {processor.py:186} INFO - Started process (PID=9578) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:39:48.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:39:48.155+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:39:48.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:39:48.248+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:39:48.269+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:39:48.269+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:39:48.293+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:39:48.293+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:39:48.313+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.169 seconds
[2024-11-08T16:40:18.700+0000] {processor.py:186} INFO - Started process (PID=9645) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:40:18.701+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:40:18.705+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:40:18.704+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:40:18.841+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:40:18.869+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:40:18.869+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:40:19.101+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:40:19.101+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:40:19.129+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.440 seconds
[2024-11-08T16:40:49.413+0000] {processor.py:186} INFO - Started process (PID=9713) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:40:49.414+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:40:49.417+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:40:49.417+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:40:49.540+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:40:49.562+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:40:49.562+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:40:49.750+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:40:49.750+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:40:49.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.371 seconds
[2024-11-08T16:41:20.163+0000] {processor.py:186} INFO - Started process (PID=9779) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:41:20.164+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:41:20.168+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:41:20.168+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:41:20.338+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:41:20.385+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:41:20.385+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:41:20.445+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:41:20.445+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:41:20.856+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.713 seconds
[2024-11-08T16:41:51.031+0000] {processor.py:186} INFO - Started process (PID=9846) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:41:51.033+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:41:51.036+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:41:51.035+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:41:51.140+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:41:51.161+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:41:51.161+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:41:51.188+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:41:51.188+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:41:51.215+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.190 seconds
[2024-11-08T16:42:21.369+0000] {processor.py:186} INFO - Started process (PID=9914) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:42:21.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:42:21.374+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:42:21.373+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:42:21.625+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:42:21.645+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:42:21.645+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:42:21.668+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:42:21.667+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:42:21.687+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.325 seconds
[2024-11-08T16:42:51.950+0000] {processor.py:186} INFO - Started process (PID=9982) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:42:51.952+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:42:51.955+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:42:51.954+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:42:52.075+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:42:52.253+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:42:52.253+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:42:52.276+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:42:52.276+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:42:52.299+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.356 seconds
[2024-11-08T16:43:22.671+0000] {processor.py:186} INFO - Started process (PID=10049) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:43:22.673+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:43:22.676+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:43:22.675+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:43:22.787+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:43:22.814+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:43:22.813+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:43:23.027+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:43:23.026+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:43:23.058+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.394 seconds
[2024-11-08T16:43:53.391+0000] {processor.py:186} INFO - Started process (PID=10116) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:43:53.392+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:43:53.394+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:43:53.394+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:43:53.513+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:43:53.541+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:43:53.541+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:43:53.812+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:43:53.812+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:43:53.860+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.477 seconds
[2024-11-08T16:44:24.668+0000] {processor.py:186} INFO - Started process (PID=10183) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:44:24.669+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:44:24.672+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:44:24.672+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:44:24.932+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:44:24.951+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:44:24.950+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:44:24.973+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:44:24.973+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:44:24.995+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.334 seconds
[2024-11-08T16:44:55.091+0000] {processor.py:186} INFO - Started process (PID=10250) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:44:55.092+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:44:55.095+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:44:55.095+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:44:55.369+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:44:55.392+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:44:55.391+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:44:55.421+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:44:55.420+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:44:55.450+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.365 seconds
[2024-11-08T16:45:25.863+0000] {processor.py:186} INFO - Started process (PID=10317) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:45:25.864+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:45:25.870+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:45:25.870+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:45:26.070+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:45:26.379+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:45:26.379+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:45:26.436+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:45:26.435+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:45:26.488+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.641 seconds
[2024-11-08T16:45:56.822+0000] {processor.py:186} INFO - Started process (PID=10384) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:45:56.824+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:45:56.829+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:45:56.828+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:45:57.193+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:45:57.220+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:45:57.220+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:45:57.253+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:45:57.252+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:45:57.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.467 seconds
[2024-11-08T16:46:28.112+0000] {processor.py:186} INFO - Started process (PID=10451) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:46:28.113+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:46:28.118+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:46:28.117+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:46:28.494+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:46:28.525+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:46:28.525+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:46:28.564+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:46:28.563+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:46:28.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.488 seconds
[2024-11-08T16:46:58.773+0000] {processor.py:186} INFO - Started process (PID=10518) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:46:58.775+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:46:58.779+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:46:58.779+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:46:59.324+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:46:59.357+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:46:59.357+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:46:59.403+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:46:59.403+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:46:59.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.674 seconds
[2024-11-08T16:47:30.252+0000] {processor.py:186} INFO - Started process (PID=10585) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:47:30.253+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:47:30.259+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:47:30.258+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:47:30.668+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:47:30.694+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:47:30.694+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:47:30.723+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:47:30.723+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:47:30.748+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.511 seconds
[2024-11-08T16:48:01.285+0000] {processor.py:186} INFO - Started process (PID=10652) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:48:01.287+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:48:01.291+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:48:01.290+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:48:01.654+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:48:01.680+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:48:01.680+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:48:01.713+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:48:01.713+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:48:01.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.474 seconds
[2024-11-08T16:48:32.778+0000] {processor.py:186} INFO - Started process (PID=10719) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:48:32.779+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:48:32.783+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:48:32.783+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:48:33.113+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:48:33.140+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:48:33.140+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:48:33.171+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:48:33.171+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:48:33.198+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.429 seconds
[2024-11-08T16:49:03.437+0000] {processor.py:186} INFO - Started process (PID=10779) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:49:03.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:49:03.442+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:49:03.441+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:49:03.776+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:49:03.801+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:49:03.800+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:49:03.831+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:49:03.831+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:49:03.854+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.425 seconds
[2024-11-08T16:49:35.818+0000] {processor.py:186} INFO - Started process (PID=10846) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:49:35.821+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:49:35.836+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:49:35.835+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:49:36.282+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:49:36.305+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:49:36.305+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:49:36.337+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:49:36.336+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:49:36.365+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.563 seconds
[2024-11-08T16:50:07.370+0000] {processor.py:186} INFO - Started process (PID=10913) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:50:07.373+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:50:07.379+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:50:07.378+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:50:07.942+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:50:07.967+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:50:07.967+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:50:08.000+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:50:08.000+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:50:08.035+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.679 seconds
[2024-11-08T16:50:38.185+0000] {processor.py:186} INFO - Started process (PID=10981) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:50:38.187+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:50:38.192+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:50:38.192+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:50:38.338+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:50:38.366+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:50:38.365+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:50:38.400+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:50:38.400+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:50:38.429+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.257 seconds
[2024-11-08T16:51:09.106+0000] {processor.py:186} INFO - Started process (PID=11047) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:51:09.107+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:51:09.111+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:51:09.110+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:51:09.263+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:51:09.300+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:51:09.300+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:51:09.350+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:51:09.350+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:51:09.390+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.293 seconds
[2024-11-08T16:51:40.091+0000] {processor.py:186} INFO - Started process (PID=11120) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:51:40.094+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:51:40.097+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:51:40.097+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:51:40.239+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:51:40.275+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:51:40.274+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:51:40.314+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:51:40.314+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:51:40.339+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.258 seconds
[2024-11-08T16:52:10.829+0000] {processor.py:186} INFO - Started process (PID=11187) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:52:10.831+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:52:10.836+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:52:10.836+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:52:11.041+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:52:11.070+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:52:11.069+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:52:11.102+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:52:11.102+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:52:11.130+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.312 seconds
[2024-11-08T16:52:41.684+0000] {processor.py:186} INFO - Started process (PID=11253) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:52:41.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:52:41.696+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:52:41.695+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:52:41.884+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:52:41.915+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:52:41.914+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:52:41.951+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:52:41.951+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:52:41.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.332 seconds
[2024-11-08T16:53:12.944+0000] {processor.py:186} INFO - Started process (PID=11320) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:53:12.946+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:53:12.951+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:53:12.951+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:53:13.084+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:53:13.113+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:53:13.113+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:53:13.146+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:53:13.146+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:53:13.172+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.244 seconds
[2024-11-08T16:53:43.578+0000] {processor.py:186} INFO - Started process (PID=11387) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:53:43.580+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:53:43.585+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:53:43.585+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:53:43.744+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:53:43.775+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:53:43.775+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:53:43.814+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:53:43.814+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:53:43.844+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.278 seconds
[2024-11-08T16:54:14.989+0000] {processor.py:186} INFO - Started process (PID=11454) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:54:14.991+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:54:14.995+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:54:14.995+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:54:15.174+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:54:15.220+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:54:15.220+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:54:15.302+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:54:15.301+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:54:15.339+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.362 seconds
[2024-11-08T16:54:45.940+0000] {processor.py:186} INFO - Started process (PID=11519) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:54:45.941+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:54:45.946+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:54:45.945+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:54:46.088+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:54:46.124+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:54:46.124+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:54:46.162+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:54:46.161+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:54:46.188+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.257 seconds
[2024-11-08T16:55:16.722+0000] {processor.py:186} INFO - Started process (PID=11583) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:55:16.724+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:55:16.728+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:55:16.728+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:55:16.866+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:55:16.895+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:55:16.894+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:55:16.927+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:55:16.926+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:55:16.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.240 seconds
[2024-11-08T16:55:47.228+0000] {processor.py:186} INFO - Started process (PID=11645) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:55:47.229+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:55:47.233+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:55:47.232+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:55:47.384+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:55:47.414+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:55:47.414+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:55:47.452+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:55:47.452+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:55:47.489+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.270 seconds
[2024-11-08T16:56:17.679+0000] {processor.py:186} INFO - Started process (PID=11708) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:56:17.681+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:56:17.684+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:56:17.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:56:17.816+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:56:17.841+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:56:17.841+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:56:17.870+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:56:17.870+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:56:17.896+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.229 seconds
[2024-11-08T16:56:48.324+0000] {processor.py:186} INFO - Started process (PID=11775) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:56:48.326+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:56:48.329+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:56:48.329+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:56:48.449+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:56:48.475+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:56:48.475+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:56:48.506+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:56:48.505+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:56:48.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.214 seconds
[2024-11-08T16:57:18.726+0000] {processor.py:186} INFO - Started process (PID=11842) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:57:18.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:57:18.732+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:57:18.731+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:57:18.875+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:57:18.910+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:57:18.910+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:57:18.944+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:57:18.944+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:57:18.969+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.257 seconds
[2024-11-08T16:57:49.849+0000] {processor.py:186} INFO - Started process (PID=11909) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:57:49.851+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:57:49.854+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:57:49.854+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:57:49.973+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:57:49.997+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:57:49.997+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:57:50.028+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:57:50.028+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:57:50.053+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.212 seconds
[2024-11-08T16:58:20.191+0000] {processor.py:186} INFO - Started process (PID=11976) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:58:20.192+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:58:20.195+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:58:20.194+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:58:20.290+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:58:20.312+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:58:20.312+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:58:20.337+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:58:20.337+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:58:20.361+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.177 seconds
[2024-11-08T16:58:50.852+0000] {processor.py:186} INFO - Started process (PID=12043) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:58:50.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:58:50.856+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:58:50.855+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:58:50.947+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:58:50.968+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:58:50.967+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:58:50.996+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:58:50.995+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:58:51.024+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.179 seconds
[2024-11-08T16:59:21.120+0000] {processor.py:186} INFO - Started process (PID=12110) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:59:21.121+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:59:21.123+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:59:21.123+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:59:21.219+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:59:21.241+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:59:21.241+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:59:21.265+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:59:21.265+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:59:21.286+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.173 seconds
[2024-11-08T16:59:51.392+0000] {processor.py:186} INFO - Started process (PID=12177) to work on /opt/airflow/dags/etl.py
[2024-11-08T16:59:51.393+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T16:59:51.396+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:59:51.396+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T16:59:51.491+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T16:59:51.517+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:59:51.516+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T16:59:51.561+0000] {logging_mixin.py:190} INFO - [2024-11-08T16:59:51.561+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T16:59:51.604+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.219 seconds
[2024-11-08T17:00:22.168+0000] {processor.py:186} INFO - Started process (PID=12244) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:00:22.170+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:00:22.175+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:00:22.175+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:00:22.283+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:00:22.306+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:00:22.306+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:00:22.335+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:00:22.335+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:00:22.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.196 seconds
[2024-11-08T17:00:52.490+0000] {processor.py:186} INFO - Started process (PID=12311) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:00:52.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:00:52.495+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:00:52.495+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:00:52.618+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:00:52.642+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:00:52.641+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:00:52.674+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:00:52.673+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:00:52.696+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.215 seconds
[2024-11-08T17:01:22.919+0000] {processor.py:186} INFO - Started process (PID=12378) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:01:22.920+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:01:22.923+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:01:22.923+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:01:23.024+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:01:23.044+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:01:23.044+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:01:23.068+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:01:23.068+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:01:23.090+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.179 seconds
[2024-11-08T17:01:53.711+0000] {processor.py:186} INFO - Started process (PID=12445) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:01:53.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:01:53.714+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:01:53.714+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:01:53.809+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:01:53.830+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:01:53.830+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:01:53.855+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:01:53.854+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:01:53.876+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.172 seconds
[2024-11-08T17:02:23.951+0000] {processor.py:186} INFO - Started process (PID=12512) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:02:23.953+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:02:23.956+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:02:23.956+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:02:24.050+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:02:24.071+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:02:24.071+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:02:24.095+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:02:24.095+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:02:24.115+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.173 seconds
[2024-11-08T17:02:54.847+0000] {processor.py:186} INFO - Started process (PID=12579) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:02:54.848+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:02:54.851+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:02:54.850+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:02:54.945+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:02:54.967+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:02:54.966+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:02:54.991+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:02:54.991+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:02:55.011+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.173 seconds
[2024-11-08T17:03:25.345+0000] {processor.py:186} INFO - Started process (PID=12646) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:03:25.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:03:25.349+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:03:25.349+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:03:25.450+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:03:25.471+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:03:25.471+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:03:25.497+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:03:25.496+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:03:25.519+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.182 seconds
[2024-11-08T17:03:55.625+0000] {processor.py:186} INFO - Started process (PID=12713) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:03:55.626+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:03:55.629+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:03:55.628+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:03:55.728+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:03:55.749+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:03:55.749+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:03:55.774+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:03:55.774+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:03:55.795+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.177 seconds
[2024-11-08T17:04:25.950+0000] {processor.py:186} INFO - Started process (PID=12780) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:04:25.951+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:04:25.954+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:04:25.954+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:04:26.049+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:04:26.070+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:04:26.070+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:04:26.095+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:04:26.095+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:04:26.116+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.173 seconds
[2024-11-08T17:04:56.216+0000] {processor.py:186} INFO - Started process (PID=12847) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:04:56.217+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:04:56.220+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:04:56.220+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:04:56.314+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:04:56.335+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:04:56.335+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:04:56.360+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:04:56.359+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:04:56.381+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.171 seconds
[2024-11-08T17:05:26.900+0000] {processor.py:186} INFO - Started process (PID=12914) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:05:26.901+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:05:26.905+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:05:26.904+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:05:26.996+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:05:27.016+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:05:27.016+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:05:27.041+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:05:27.041+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:05:27.061+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.169 seconds
[2024-11-08T17:05:57.187+0000] {processor.py:186} INFO - Started process (PID=12981) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:05:57.188+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:05:57.191+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:05:57.190+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:05:57.301+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:05:57.323+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:05:57.323+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:05:57.350+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:05:57.349+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:05:57.372+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.192 seconds
[2024-11-08T17:06:28.151+0000] {processor.py:186} INFO - Started process (PID=13048) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:06:28.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:06:28.154+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:06:28.154+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:06:28.246+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:06:28.266+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:06:28.266+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:06:28.292+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:06:28.292+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:06:28.313+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.170 seconds
[2024-11-08T17:06:58.992+0000] {processor.py:186} INFO - Started process (PID=13115) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:06:58.993+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:06:58.997+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:06:58.996+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:06:59.156+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:06:59.191+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:06:59.191+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:06:59.227+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:06:59.227+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:06:59.248+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.266 seconds
[2024-11-08T17:07:29.919+0000] {processor.py:186} INFO - Started process (PID=13183) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:07:29.920+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:07:29.923+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:07:29.923+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:07:30.024+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:07:30.054+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:07:30.054+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:07:30.081+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:07:30.081+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:07:30.108+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.195 seconds
[2024-11-08T17:08:00.621+0000] {processor.py:186} INFO - Started process (PID=13250) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:08:00.623+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:08:00.626+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:08:00.625+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:08:00.731+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:08:00.757+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:08:00.757+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:08:00.796+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:08:00.795+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:08:00.824+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.210 seconds
[2024-11-08T17:08:31.220+0000] {processor.py:186} INFO - Started process (PID=13317) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:08:31.221+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:08:31.224+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:08:31.224+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:08:31.322+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:08:31.344+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:08:31.344+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:08:31.370+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:08:31.370+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:08:31.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.185 seconds
[2024-11-08T17:09:01.801+0000] {processor.py:186} INFO - Started process (PID=13384) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:09:01.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:09:01.807+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:09:01.806+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:09:01.919+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:09:01.940+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:09:01.940+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:09:01.965+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:09:01.964+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:09:01.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.200 seconds
[2024-11-08T17:09:33.215+0000] {processor.py:186} INFO - Started process (PID=13448) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:09:33.216+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:09:33.218+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:09:33.218+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:09:33.319+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:09:33.341+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:09:33.341+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:09:33.366+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:09:33.366+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:09:33.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.179 seconds
[2024-11-08T17:10:03.801+0000] {processor.py:186} INFO - Started process (PID=13514) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:10:03.802+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:10:03.805+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:10:03.805+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:10:03.899+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:10:03.923+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:10:03.922+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:10:03.950+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:10:03.950+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:10:03.973+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.179 seconds
[2024-11-08T17:10:35.639+0000] {processor.py:186} INFO - Started process (PID=13581) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:10:35.640+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:10:35.643+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:10:35.642+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:10:35.744+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:10:35.768+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:10:35.767+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:10:35.794+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:10:35.793+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:10:35.814+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.182 seconds
[2024-11-08T17:11:06.285+0000] {processor.py:186} INFO - Started process (PID=13648) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:11:06.286+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:11:06.289+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:11:06.289+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:11:06.395+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:11:06.417+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:11:06.417+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:11:06.444+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:11:06.444+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:11:06.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.187 seconds
[2024-11-08T17:11:38.123+0000] {processor.py:186} INFO - Started process (PID=13716) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:11:38.124+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:11:38.126+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:11:38.126+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:11:38.225+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:11:38.248+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:11:38.248+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:11:38.273+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:11:38.273+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:11:38.297+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.181 seconds
[2024-11-08T17:12:09.306+0000] {processor.py:186} INFO - Started process (PID=13783) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:12:09.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:12:09.309+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:12:09.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:12:09.410+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:12:09.432+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:12:09.432+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:12:09.462+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:12:09.461+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:12:09.487+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.188 seconds
[2024-11-08T17:12:40.403+0000] {processor.py:186} INFO - Started process (PID=13848) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:12:40.404+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:12:40.407+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:12:40.407+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:12:40.511+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:12:40.531+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:12:40.531+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:12:40.555+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:12:40.555+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:12:40.579+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.183 seconds
[2024-11-08T17:13:11.386+0000] {processor.py:186} INFO - Started process (PID=13912) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:13:11.387+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:13:11.390+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:13:11.389+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:13:11.485+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:13:11.508+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:13:11.507+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:13:11.534+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:13:11.534+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:13:11.554+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.175 seconds
[2024-11-08T17:13:41.747+0000] {processor.py:186} INFO - Started process (PID=13973) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:13:41.749+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:13:41.752+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:13:41.751+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:13:41.887+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:13:41.913+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:13:41.913+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:13:41.940+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:13:41.940+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:13:41.962+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.228 seconds
[2024-11-08T17:14:12.486+0000] {processor.py:186} INFO - Started process (PID=14046) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:14:12.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:14:12.490+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:14:12.490+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:14:12.596+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:14:12.622+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:14:12.621+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:14:12.649+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:14:12.649+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:14:12.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.192 seconds
[2024-11-08T17:14:43.286+0000] {processor.py:186} INFO - Started process (PID=14113) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:14:43.287+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:14:43.290+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:14:43.289+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:14:43.386+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:14:43.407+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:14:43.407+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:14:43.433+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:14:43.432+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:14:43.457+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.178 seconds
[2024-11-08T17:15:13.775+0000] {processor.py:186} INFO - Started process (PID=14180) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:15:13.776+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:15:13.778+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:15:13.778+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:15:13.877+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:15:13.898+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:15:13.898+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:15:13.923+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:15:13.923+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:15:13.950+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.184 seconds
[2024-11-08T17:15:44.118+0000] {processor.py:186} INFO - Started process (PID=14247) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:15:44.119+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:15:44.122+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:15:44.121+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:15:44.225+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:15:44.250+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:15:44.250+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:15:44.281+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:15:44.280+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:15:44.305+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.194 seconds
[2024-11-08T17:16:14.834+0000] {processor.py:186} INFO - Started process (PID=14315) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:16:14.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:16:14.838+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:16:14.838+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:16:14.933+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:16:14.955+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:16:14.954+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:16:14.981+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:16:14.980+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:16:15.002+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.177 seconds
[2024-11-08T17:16:45.171+0000] {processor.py:186} INFO - Started process (PID=14382) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:16:45.173+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:16:45.175+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:16:45.175+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:16:45.270+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:16:45.291+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:16:45.291+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:16:45.316+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:16:45.316+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:16:45.338+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.173 seconds
[2024-11-08T17:17:15.831+0000] {processor.py:186} INFO - Started process (PID=14449) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:17:15.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:17:15.835+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:17:15.834+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:17:15.929+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:17:15.950+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:17:15.950+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:17:15.977+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:17:15.977+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:17:15.998+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.174 seconds
[2024-11-08T17:17:46.248+0000] {processor.py:186} INFO - Started process (PID=14516) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:17:46.249+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:17:46.252+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:17:46.252+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:17:46.350+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:17:46.370+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:17:46.370+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:17:46.396+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:17:46.395+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:17:46.416+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.174 seconds
[2024-11-08T17:18:16.567+0000] {processor.py:186} INFO - Started process (PID=14583) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:18:16.568+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:18:16.571+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:18:16.570+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:18:16.675+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:18:16.696+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:18:16.696+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:18:16.725+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:18:16.725+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:18:16.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.185 seconds
[2024-11-08T17:18:47.236+0000] {processor.py:186} INFO - Started process (PID=14650) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:18:47.237+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:18:47.240+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:18:47.239+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:18:47.346+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:18:47.366+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:18:47.366+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:18:47.391+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:18:47.391+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:18:47.412+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.183 seconds
[2024-11-08T17:19:17.691+0000] {processor.py:186} INFO - Started process (PID=14717) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:19:17.692+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:19:17.695+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:19:17.694+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:19:17.803+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:19:17.829+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:19:17.829+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:19:17.856+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:19:17.856+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:19:17.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.201 seconds
[2024-11-08T17:19:48.120+0000] {processor.py:186} INFO - Started process (PID=14784) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:19:48.121+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:19:48.125+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:19:48.124+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:19:48.232+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:19:48.254+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:19:48.254+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:19:48.282+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:19:48.282+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:19:48.311+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.201 seconds
[2024-11-08T17:20:18.816+0000] {processor.py:186} INFO - Started process (PID=14851) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:20:18.817+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:20:18.819+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:20:18.819+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:20:18.917+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:20:18.938+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:20:18.938+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:20:18.964+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:20:18.964+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:20:18.987+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.178 seconds
[2024-11-08T17:20:49.385+0000] {processor.py:186} INFO - Started process (PID=14916) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:20:49.386+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:20:49.389+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:20:49.389+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:20:49.481+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:20:49.501+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:20:49.501+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:20:49.525+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:20:49.525+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:20:49.554+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.175 seconds
[2024-11-08T17:21:20.568+0000] {processor.py:186} INFO - Started process (PID=14983) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:21:20.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:21:20.572+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:21:20.571+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:21:20.673+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:21:20.695+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:21:20.694+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:21:20.720+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:21:20.719+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:21:20.742+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.181 seconds
[2024-11-08T17:21:51.651+0000] {processor.py:186} INFO - Started process (PID=15050) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:21:51.652+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:21:51.654+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:21:51.654+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:21:51.758+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:21:51.779+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:21:51.779+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:21:51.805+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:21:51.804+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:21:51.827+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.184 seconds
[2024-11-08T17:22:22.563+0000] {processor.py:186} INFO - Started process (PID=15117) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:22:22.564+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:22:22.566+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:22:22.566+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:22:22.661+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:22:22.682+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:22:22.682+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:22:22.708+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:22:22.707+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:22:22.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.177 seconds
[2024-11-08T17:22:53.617+0000] {processor.py:186} INFO - Started process (PID=15185) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:22:53.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:22:53.621+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:22:53.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:22:53.718+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:22:53.738+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:22:53.737+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:22:53.763+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:22:53.762+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:22:53.784+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.174 seconds
[2024-11-08T17:23:24.450+0000] {processor.py:186} INFO - Started process (PID=15252) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:23:24.451+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:23:24.454+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:23:24.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:23:24.545+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:23:24.565+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:23:24.565+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:23:24.589+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:23:24.588+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:23:24.612+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.171 seconds
[2024-11-08T17:23:55.005+0000] {processor.py:186} INFO - Started process (PID=15319) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:23:55.007+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:23:55.011+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:23:55.010+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:23:55.122+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:23:55.143+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:23:55.143+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:23:55.167+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:23:55.167+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:23:55.190+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.195 seconds
[2024-11-08T17:24:25.699+0000] {processor.py:186} INFO - Started process (PID=15386) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:24:25.700+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:24:25.702+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:24:25.702+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:24:25.800+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:24:25.821+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:24:25.821+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:24:25.846+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:24:25.846+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:24:25.881+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.189 seconds
[2024-11-08T17:24:56.852+0000] {processor.py:186} INFO - Started process (PID=15453) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:24:56.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:24:56.856+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:24:56.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:24:56.952+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:24:56.972+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:24:56.972+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:24:56.998+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:24:56.997+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:24:57.024+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.179 seconds
[2024-11-08T17:25:27.394+0000] {processor.py:186} INFO - Started process (PID=15520) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:25:27.395+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:25:27.398+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:25:27.398+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:25:27.508+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:25:27.531+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:25:27.530+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:25:27.557+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:25:27.557+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:25:27.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.195 seconds
[2024-11-08T17:25:57.986+0000] {processor.py:186} INFO - Started process (PID=15587) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:25:57.987+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:25:57.989+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:25:57.989+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:25:58.096+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:25:58.119+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:25:58.118+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:25:58.144+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:25:58.143+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:25:58.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.191 seconds
[2024-11-08T17:26:28.959+0000] {processor.py:186} INFO - Started process (PID=15654) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:26:28.960+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:26:28.963+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:26:28.963+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:26:29.058+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:26:29.079+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:26:29.079+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:26:29.108+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:26:29.107+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:26:29.134+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.181 seconds
[2024-11-08T17:26:59.346+0000] {processor.py:186} INFO - Started process (PID=15721) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:26:59.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:26:59.350+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:26:59.350+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:26:59.442+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:26:59.464+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:26:59.464+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:26:59.488+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:26:59.488+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:26:59.510+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.171 seconds
[2024-11-08T17:27:30.415+0000] {processor.py:186} INFO - Started process (PID=15788) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:27:30.416+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:27:30.419+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:27:30.418+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:27:30.519+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:27:30.539+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:27:30.539+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:27:30.565+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:27:30.564+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:27:30.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.183 seconds
[2024-11-08T17:28:01.116+0000] {processor.py:186} INFO - Started process (PID=15856) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:28:01.117+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:28:01.120+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:28:01.119+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:28:01.211+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:28:01.231+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:28:01.231+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:28:01.257+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:28:01.256+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:28:01.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.183 seconds
[2024-11-08T17:28:31.793+0000] {processor.py:186} INFO - Started process (PID=15923) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:28:31.794+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:28:31.797+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:28:31.796+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:28:31.895+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:28:31.917+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:28:31.916+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:28:31.941+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:28:31.941+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:28:31.962+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.175 seconds
[2024-11-08T17:29:02.803+0000] {processor.py:186} INFO - Started process (PID=15990) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:29:02.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:29:02.807+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:29:02.807+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:29:02.901+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:29:02.926+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:29:02.925+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:29:02.955+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:29:02.955+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:29:02.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.186 seconds
[2024-11-08T17:29:33.484+0000] {processor.py:186} INFO - Started process (PID=16057) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:29:33.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:29:33.488+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:29:33.488+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:29:33.584+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:29:33.606+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:29:33.606+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:29:33.633+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:29:33.633+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:29:33.664+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.187 seconds
[2024-11-08T17:30:04.531+0000] {processor.py:186} INFO - Started process (PID=16124) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:30:04.532+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:30:04.535+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:30:04.535+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:30:04.638+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:30:04.661+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:30:04.661+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:30:04.686+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:30:04.686+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:30:04.713+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.191 seconds
[2024-11-08T17:30:35.613+0000] {processor.py:186} INFO - Started process (PID=16191) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:30:35.614+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:30:35.616+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:30:35.616+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:30:35.730+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:30:35.749+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:30:35.749+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:30:35.773+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:30:35.773+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:30:35.796+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.189 seconds
[2024-11-08T17:31:06.593+0000] {processor.py:186} INFO - Started process (PID=16258) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:31:06.595+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:31:06.597+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:31:06.597+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:31:06.692+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:31:06.713+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:31:06.713+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:31:06.737+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:31:06.737+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:31:06.768+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.181 seconds
[2024-11-08T17:31:37.049+0000] {processor.py:186} INFO - Started process (PID=16325) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:31:37.050+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:31:37.053+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:31:37.052+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:31:37.145+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:31:37.165+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:31:37.165+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:31:37.190+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:31:37.190+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:31:37.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.188 seconds
[2024-11-08T17:32:07.590+0000] {processor.py:186} INFO - Started process (PID=16392) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:32:07.592+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:32:07.595+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:32:07.594+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:32:07.720+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:32:07.740+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:32:07.740+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:32:07.765+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:32:07.765+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:32:07.785+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.204 seconds
[2024-11-08T17:32:37.931+0000] {processor.py:186} INFO - Started process (PID=16459) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:32:37.932+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:32:37.935+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:32:37.934+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:32:38.032+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:32:38.053+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:32:38.053+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:32:38.077+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:32:38.077+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:32:38.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.175 seconds
[2024-11-08T17:33:08.315+0000] {processor.py:186} INFO - Started process (PID=16526) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:33:08.316+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:33:08.319+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:33:08.319+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:33:08.416+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:33:08.439+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:33:08.439+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:33:08.464+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:33:08.464+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:33:08.485+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.177 seconds
[2024-11-08T17:33:38.663+0000] {processor.py:186} INFO - Started process (PID=16580) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:33:38.664+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:33:38.667+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:33:38.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:33:38.763+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:33:38.785+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:33:38.785+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:33:38.817+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:33:38.816+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:33:38.841+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.184 seconds
[2024-11-08T17:34:09.215+0000] {processor.py:186} INFO - Started process (PID=16632) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:34:09.217+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:34:09.219+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:34:09.219+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:34:09.343+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:34:09.365+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:34:09.365+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:34:09.392+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:34:09.391+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:34:09.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.207 seconds
[2024-11-08T17:34:40.621+0000] {processor.py:186} INFO - Started process (PID=16698) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:34:40.622+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:34:40.625+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:34:40.625+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:34:40.723+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:34:40.745+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:34:40.744+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:34:40.770+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:34:40.769+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:34:40.793+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.179 seconds
[2024-11-08T17:35:11.424+0000] {processor.py:186} INFO - Started process (PID=16765) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:35:11.425+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:35:11.429+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:35:11.429+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:35:11.536+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:35:11.559+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:35:11.559+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:35:11.584+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:35:11.583+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:35:11.604+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.191 seconds
[2024-11-08T17:35:43.109+0000] {processor.py:186} INFO - Started process (PID=16832) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:35:43.110+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:35:43.113+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:35:43.112+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:35:43.208+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:35:43.229+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:35:43.229+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:35:43.420+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:35:43.419+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:35:43.439+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.337 seconds
[2024-11-08T17:36:14.841+0000] {processor.py:186} INFO - Started process (PID=16905) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:36:14.842+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:36:14.845+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:36:14.844+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:36:14.943+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:36:14.967+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:36:14.967+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:36:14.994+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:36:14.994+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:36:15.193+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.359 seconds
[2024-11-08T17:36:45.793+0000] {processor.py:186} INFO - Started process (PID=16972) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:36:45.794+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:36:45.797+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:36:45.797+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:36:45.893+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:36:45.915+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:36:45.914+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:36:45.943+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:36:45.943+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:36:45.969+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.182 seconds
[2024-11-08T17:37:16.245+0000] {processor.py:186} INFO - Started process (PID=17032) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:37:16.246+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:37:16.249+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:37:16.248+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:37:16.349+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:37:16.529+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:37:16.529+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:37:16.550+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:37:16.550+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:37:16.572+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.334 seconds
[2024-11-08T17:37:47.385+0000] {processor.py:186} INFO - Started process (PID=17099) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:37:47.386+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:37:47.389+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:37:47.389+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:37:47.483+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:37:47.507+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:37:47.507+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:37:47.690+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:37:47.690+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:37:47.717+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.339 seconds
[2024-11-08T17:38:18.634+0000] {processor.py:186} INFO - Started process (PID=17166) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:38:18.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:38:18.639+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:38:18.638+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:38:18.732+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:38:18.753+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:38:18.753+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:38:18.928+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:38:18.928+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:38:18.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.319 seconds
[2024-11-08T17:38:50.003+0000] {processor.py:186} INFO - Started process (PID=17234) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:38:50.004+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:38:50.007+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:38:50.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:38:50.106+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:38:50.126+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:38:50.125+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:38:50.301+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:38:50.301+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:38:50.321+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.325 seconds
[2024-11-08T17:39:20.903+0000] {processor.py:186} INFO - Started process (PID=17302) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:39:20.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:39:20.907+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:39:20.906+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:39:21.170+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:39:21.187+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:39:21.186+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:39:21.208+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:39:21.208+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:39:21.227+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.331 seconds
[2024-11-08T17:39:51.594+0000] {processor.py:186} INFO - Started process (PID=17366) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:39:51.595+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:39:51.598+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:39:51.597+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:39:51.859+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:39:51.879+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:39:51.879+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:39:51.904+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:39:51.904+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:39:51.927+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.340 seconds
[2024-11-08T17:40:22.009+0000] {processor.py:186} INFO - Started process (PID=17435) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:40:22.010+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:40:22.012+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:40:22.012+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:40:22.105+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:40:22.282+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:40:22.282+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:40:22.306+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:40:22.305+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:40:22.324+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.322 seconds
[2024-11-08T17:40:52.762+0000] {processor.py:186} INFO - Started process (PID=17502) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:40:52.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:40:52.766+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:40:52.766+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:40:53.018+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:40:53.038+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:40:53.038+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:40:53.060+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:40:53.059+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:40:53.082+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.326 seconds
[2024-11-08T17:41:23.411+0000] {processor.py:186} INFO - Started process (PID=17568) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:41:23.412+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:41:23.415+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:41:23.415+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:41:23.664+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:41:23.682+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:41:23.682+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:41:23.705+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:41:23.705+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:41:23.725+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.320 seconds
[2024-11-08T17:41:54.086+0000] {processor.py:186} INFO - Started process (PID=17634) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:41:54.087+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:41:54.090+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:41:54.089+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:41:54.387+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:41:54.407+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:41:54.406+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:41:54.430+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:41:54.430+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:41:54.457+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.379 seconds
[2024-11-08T17:42:24.592+0000] {processor.py:186} INFO - Started process (PID=17701) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:42:24.593+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:42:24.595+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:42:24.595+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:42:24.909+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:42:24.928+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:42:24.928+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:42:24.951+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:42:24.951+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:42:24.974+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.389 seconds
[2024-11-08T17:42:55.407+0000] {processor.py:186} INFO - Started process (PID=17768) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:42:55.408+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:42:55.412+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:42:55.411+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:42:55.680+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:42:55.703+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:42:55.702+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:42:55.727+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:42:55.727+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:42:55.752+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.354 seconds
[2024-11-08T17:43:26.475+0000] {processor.py:186} INFO - Started process (PID=17835) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:43:26.477+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:43:26.479+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:43:26.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:43:26.747+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:43:26.766+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:43:26.766+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:43:26.788+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:43:26.787+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:43:26.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.342 seconds
[2024-11-08T17:43:57.245+0000] {processor.py:186} INFO - Started process (PID=17902) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:43:57.246+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:43:57.249+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:43:57.248+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:43:57.531+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:43:57.550+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:43:57.550+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:43:57.572+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:43:57.572+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:43:57.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.356 seconds
[2024-11-08T17:44:28.163+0000] {processor.py:186} INFO - Started process (PID=17970) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:44:28.164+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:44:28.167+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:44:28.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:44:28.486+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:44:28.508+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:44:28.507+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:44:28.542+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:44:28.541+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:44:28.571+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.416 seconds
[2024-11-08T17:44:58.830+0000] {processor.py:186} INFO - Started process (PID=18037) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:44:58.831+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:44:58.833+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:44:58.833+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:44:59.111+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:44:59.131+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:44:59.130+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:44:59.164+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:44:59.164+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:44:59.192+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.369 seconds
[2024-11-08T17:45:29.308+0000] {processor.py:186} INFO - Started process (PID=18104) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:45:29.309+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:45:29.311+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:45:29.311+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:45:29.566+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:45:29.582+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:45:29.582+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:45:29.608+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:45:29.608+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:45:29.627+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.327 seconds
[2024-11-08T17:46:00.573+0000] {processor.py:186} INFO - Started process (PID=18171) to work on /opt/airflow/dags/etl.py
[2024-11-08T17:46:00.574+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T17:46:00.577+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:46:00.577+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T17:46:00.693+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T17:46:00.715+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:46:00.715+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T17:46:00.743+0000] {logging_mixin.py:190} INFO - [2024-11-08T17:46:00.743+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T17:46:00.767+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.200 seconds
[2024-11-08T19:21:44.221+0000] {processor.py:186} INFO - Started process (PID=18237) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:21:44.222+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:21:44.227+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:21:44.226+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:21:44.633+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:21:44.685+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:21:44.685+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:21:44.783+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:21:44.783+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:21:44.847+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.645 seconds
[2024-11-08T19:22:15.054+0000] {processor.py:186} INFO - Started process (PID=18304) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:22:15.055+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:22:15.058+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:22:15.057+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:22:15.169+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:22:15.189+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:22:15.189+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:22:15.214+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:22:15.214+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:22:15.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.192 seconds
[2024-11-08T19:22:46.026+0000] {processor.py:186} INFO - Started process (PID=18371) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:22:46.027+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:22:46.029+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:22:46.029+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:22:46.144+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:22:46.166+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:22:46.166+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:22:46.191+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:22:46.191+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:22:46.213+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.194 seconds
[2024-11-08T19:23:16.372+0000] {processor.py:186} INFO - Started process (PID=18438) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:23:16.374+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:23:16.376+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:23:16.376+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:23:16.488+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:23:16.510+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:23:16.510+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:23:16.540+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:23:16.540+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:23:16.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.200 seconds
[2024-11-08T19:23:47.111+0000] {processor.py:186} INFO - Started process (PID=18505) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:23:47.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:23:47.115+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:23:47.115+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:23:47.233+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:23:47.254+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:23:47.254+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:23:47.281+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:23:47.281+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:23:47.303+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.198 seconds
[2024-11-08T19:24:17.585+0000] {processor.py:186} INFO - Started process (PID=18572) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:24:17.586+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:24:17.589+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:24:17.588+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:24:17.695+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:24:17.718+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:24:17.718+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:24:17.743+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:24:17.742+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:24:17.767+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.189 seconds
[2024-11-08T19:24:48.436+0000] {processor.py:186} INFO - Started process (PID=18639) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:24:48.437+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:24:48.440+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:24:48.440+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:24:48.557+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:24:48.586+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:24:48.586+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:24:48.613+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:24:48.613+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:24:48.634+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.204 seconds
[2024-11-08T19:25:19.392+0000] {processor.py:186} INFO - Started process (PID=18707) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:25:19.393+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:25:19.396+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:25:19.395+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:25:19.503+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:25:19.523+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:25:19.523+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:25:19.549+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:25:19.549+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:25:19.573+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.188 seconds
[2024-11-08T19:25:50.247+0000] {processor.py:186} INFO - Started process (PID=18774) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:25:50.248+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:25:50.251+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:25:50.250+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:25:50.359+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:25:50.379+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:25:50.379+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:25:50.405+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:25:50.405+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:25:50.430+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.190 seconds
[2024-11-08T19:26:20.925+0000] {processor.py:186} INFO - Started process (PID=18841) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:26:20.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:26:20.929+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:26:20.928+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:26:21.035+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:26:21.055+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:26:21.055+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:26:21.081+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:26:21.081+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:26:21.106+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.188 seconds
[2024-11-08T19:26:51.381+0000] {processor.py:186} INFO - Started process (PID=18908) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:26:51.383+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:26:51.387+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:26:51.386+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:26:51.521+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:26:51.550+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:26:51.550+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:26:51.584+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:26:51.584+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:26:51.614+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.246 seconds
[2024-11-08T19:27:21.877+0000] {processor.py:186} INFO - Started process (PID=18975) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:27:21.878+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:27:21.882+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:27:21.882+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:27:22.054+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:27:22.081+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:27:22.080+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:27:22.117+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:27:22.117+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:27:22.146+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.278 seconds
[2024-11-08T19:27:52.489+0000] {processor.py:186} INFO - Started process (PID=19042) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:27:52.490+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:27:52.493+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:27:52.493+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:27:52.622+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:27:52.650+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:27:52.649+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:27:52.682+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:27:52.682+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:27:52.723+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.243 seconds
[2024-11-08T19:28:23.293+0000] {processor.py:186} INFO - Started process (PID=19109) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:28:23.295+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:28:23.298+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:28:23.297+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:28:23.444+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:28:23.471+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:28:23.470+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:28:23.504+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:28:23.504+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:28:23.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.245 seconds
[2024-11-08T19:28:54.432+0000] {processor.py:186} INFO - Started process (PID=19176) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:28:54.433+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:28:54.437+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:28:54.437+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:28:54.565+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:28:54.590+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:28:54.589+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:28:54.624+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:28:54.624+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:28:54.650+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.229 seconds
[2024-11-08T19:29:25.554+0000] {processor.py:186} INFO - Started process (PID=19243) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:29:25.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:29:25.559+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:29:25.558+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:29:25.701+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:29:25.734+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:29:25.734+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:29:25.781+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:29:25.781+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:29:25.817+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.272 seconds
[2024-11-08T19:29:56.134+0000] {processor.py:186} INFO - Started process (PID=19310) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:29:56.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:29:56.139+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:29:56.138+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:29:56.283+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:29:56.311+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:29:56.311+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:29:56.344+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:29:56.344+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:29:56.371+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.246 seconds
[2024-11-08T19:30:27.103+0000] {processor.py:186} INFO - Started process (PID=19378) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:30:27.104+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:30:27.108+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:30:27.107+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:30:27.233+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:30:27.258+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:30:27.257+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:30:27.290+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:30:27.289+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:30:27.315+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.220 seconds
[2024-11-08T19:30:57.571+0000] {processor.py:186} INFO - Started process (PID=19445) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:30:57.572+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:30:57.577+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:30:57.576+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:30:57.706+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:30:57.735+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:30:57.734+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:30:57.768+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:30:57.767+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:30:57.795+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.234 seconds
[2024-11-08T19:31:28.595+0000] {processor.py:186} INFO - Started process (PID=19518) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:31:28.596+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:31:28.600+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:31:28.600+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:31:28.723+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:31:28.748+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:31:28.748+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:31:28.779+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:31:28.779+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:31:28.806+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.220 seconds
[2024-11-08T19:31:59.048+0000] {processor.py:186} INFO - Started process (PID=19585) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:31:59.050+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:31:59.054+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:31:59.053+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:31:59.186+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:31:59.213+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:31:59.213+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:31:59.248+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:31:59.248+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:31:59.277+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.238 seconds
[2024-11-08T19:32:30.064+0000] {processor.py:186} INFO - Started process (PID=19652) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:32:30.066+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:32:30.069+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:32:30.069+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:32:30.186+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:32:30.217+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:32:30.216+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:32:30.257+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:32:30.256+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:32:30.290+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.235 seconds
[2024-11-08T19:33:01.257+0000] {processor.py:186} INFO - Started process (PID=19719) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:33:01.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:33:01.263+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:33:01.263+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:33:01.409+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:33:01.436+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:33:01.436+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:33:01.470+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:33:01.470+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:33:01.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.254 seconds
[2024-11-08T19:33:32.193+0000] {processor.py:186} INFO - Started process (PID=19786) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:33:32.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:33:32.198+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:33:32.198+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:33:32.323+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:33:32.350+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:33:32.349+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:33:32.383+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:33:32.382+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:33:32.412+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.227 seconds
[2024-11-08T19:34:02.952+0000] {processor.py:186} INFO - Started process (PID=19853) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:34:02.954+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:34:02.957+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:34:02.957+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:34:03.079+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:34:03.105+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:34:03.105+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:34:03.136+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:34:03.136+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:34:03.168+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.227 seconds
[2024-11-08T19:34:33.508+0000] {processor.py:186} INFO - Started process (PID=19920) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:34:33.510+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:34:33.515+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:34:33.514+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:34:33.661+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:34:33.692+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:34:33.692+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:34:33.731+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:34:33.730+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:34:33.763+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.264 seconds
[2024-11-08T19:35:03.893+0000] {processor.py:186} INFO - Started process (PID=19987) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:35:03.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:35:03.900+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:35:03.899+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:35:04.060+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:35:04.102+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:35:04.102+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:35:04.146+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:35:04.145+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:35:04.182+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.301 seconds
[2024-11-08T19:35:34.530+0000] {processor.py:186} INFO - Started process (PID=20054) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:35:34.532+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:35:34.535+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:35:34.535+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:35:34.674+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:35:34.708+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:35:34.708+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:35:34.743+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:35:34.743+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:35:34.773+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.251 seconds
[2024-11-08T19:36:05.123+0000] {processor.py:186} INFO - Started process (PID=20121) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:36:05.127+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:36:05.138+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:36:05.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:36:05.330+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:36:05.356+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:36:05.356+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:36:05.389+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:36:05.389+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:36:05.418+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.321 seconds
[2024-11-08T19:56:10.139+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:56:10.144+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:56:10.153+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:56:10.152+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:56:10.367+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:56:10.403+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:56:10.403+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:56:10.437+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:56:10.437+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:56:10.503+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.386 seconds
[2024-11-08T19:56:40.727+0000] {processor.py:186} INFO - Started process (PID=140) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:56:40.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:56:40.732+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:56:40.732+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:56:40.932+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:56:40.958+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:56:40.958+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:56:40.989+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:56:40.989+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:56:41.018+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.304 seconds
[2024-11-08T19:57:11.230+0000] {processor.py:186} INFO - Started process (PID=208) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:57:11.232+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:57:11.234+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:57:11.234+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:57:11.362+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:57:11.397+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:57:11.397+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:57:11.434+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:57:11.434+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:57:11.468+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.246 seconds
[2024-11-08T19:57:41.961+0000] {processor.py:186} INFO - Started process (PID=274) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:57:41.962+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:57:41.965+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:57:41.965+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:57:42.089+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:57:42.112+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:57:42.112+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:57:42.140+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:57:42.139+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:57:42.167+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.213 seconds
[2024-11-08T19:58:12.484+0000] {processor.py:186} INFO - Started process (PID=341) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:58:12.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:58:12.489+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:58:12.488+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:58:12.606+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:58:12.632+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:58:12.631+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:58:12.661+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:58:12.661+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:58:12.688+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.212 seconds
[2024-11-08T19:58:43.334+0000] {processor.py:186} INFO - Started process (PID=408) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:58:43.336+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:58:43.339+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:58:43.339+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:58:43.487+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:58:43.539+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:58:43.539+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:58:43.597+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:58:43.597+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:58:43.652+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.327 seconds
[2024-11-08T19:59:13.965+0000] {processor.py:186} INFO - Started process (PID=475) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:59:13.966+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:59:13.970+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:59:13.969+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:59:14.106+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:59:14.130+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:59:14.130+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:59:14.160+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:59:14.160+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:59:14.190+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.234 seconds
[2024-11-08T19:59:44.434+0000] {processor.py:186} INFO - Started process (PID=542) to work on /opt/airflow/dags/etl.py
[2024-11-08T19:59:44.436+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T19:59:44.439+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:59:44.438+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T19:59:44.733+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T19:59:44.775+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:59:44.775+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T19:59:44.825+0000] {logging_mixin.py:190} INFO - [2024-11-08T19:59:44.824+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T19:59:44.862+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.440 seconds
[2024-11-08T20:00:15.407+0000] {processor.py:186} INFO - Started process (PID=609) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:00:15.408+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:00:15.412+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:00:15.412+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:00:15.553+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:00:15.581+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:00:15.580+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:00:15.614+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:00:15.614+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:00:15.643+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.247 seconds
[2024-11-08T20:00:45.903+0000] {processor.py:186} INFO - Started process (PID=676) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:00:45.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:00:45.907+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:00:45.907+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:00:46.035+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:00:46.062+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:00:46.062+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:00:46.095+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:00:46.094+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:00:46.127+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.231 seconds
[2024-11-08T20:01:16.427+0000] {processor.py:186} INFO - Started process (PID=744) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:01:16.428+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:01:16.433+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:01:16.432+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:01:16.613+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:01:16.644+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:01:16.643+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:01:16.684+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:01:16.683+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:01:16.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.304 seconds
[2024-11-08T20:01:46.912+0000] {processor.py:186} INFO - Started process (PID=812) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:01:46.913+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:01:46.917+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:01:46.917+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:01:47.096+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:01:47.130+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:01:47.130+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:01:47.166+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:01:47.165+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:01:47.201+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.299 seconds
[2024-11-08T20:02:17.648+0000] {processor.py:186} INFO - Started process (PID=878) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:02:17.649+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:02:17.653+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:02:17.653+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:02:17.803+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:02:17.843+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:02:17.843+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:02:17.879+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:02:17.879+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:02:17.910+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.274 seconds
[2024-11-08T20:02:48.686+0000] {processor.py:186} INFO - Started process (PID=945) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:02:48.689+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:02:48.695+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:02:48.694+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:02:48.993+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:02:49.052+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:02:49.052+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:02:49.104+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:02:49.104+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:02:49.150+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.479 seconds
[2024-11-08T20:03:19.416+0000] {processor.py:186} INFO - Started process (PID=1012) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:03:19.418+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:03:19.422+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:03:19.422+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:03:19.732+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:03:19.810+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:03:19.809+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:03:19.902+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:03:19.901+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:03:19.967+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.562 seconds
[2024-11-08T20:05:07.897+0000] {processor.py:186} INFO - Started process (PID=71) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:05:07.898+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:05:07.901+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:05:07.901+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:05:08.029+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:05:08.061+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:05:08.061+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:05:08.091+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:05:08.091+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:05:08.115+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.227 seconds
[2024-11-08T20:05:38.978+0000] {processor.py:186} INFO - Started process (PID=138) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:05:38.979+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:05:38.983+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:05:38.983+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:05:39.134+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:05:39.166+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:05:39.166+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:05:39.203+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:05:39.202+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:05:39.238+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.268 seconds
[2024-11-08T20:06:09.842+0000] {processor.py:186} INFO - Started process (PID=205) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:06:09.843+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:06:09.847+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:06:09.847+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:06:09.989+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:06:10.021+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:06:10.020+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:06:10.054+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:06:10.053+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:06:10.085+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.251 seconds
[2024-11-08T20:06:40.469+0000] {processor.py:186} INFO - Started process (PID=272) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:06:40.470+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:06:40.475+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:06:40.474+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:06:40.611+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:06:40.639+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:06:40.639+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:06:40.678+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:06:40.677+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:06:40.712+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.255 seconds
[2024-11-08T20:07:11.314+0000] {processor.py:186} INFO - Started process (PID=338) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:07:11.316+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:07:11.320+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:07:11.319+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:07:11.493+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:07:11.525+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:07:11.524+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:07:11.571+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:07:11.570+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:07:11.607+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.306 seconds
[2024-11-08T20:07:42.301+0000] {processor.py:186} INFO - Started process (PID=406) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:07:42.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:07:42.312+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:07:42.310+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:07:42.575+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:07:42.630+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:07:42.629+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:07:42.681+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:07:42.681+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:07:42.719+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.437 seconds
[2024-11-08T20:08:12.993+0000] {processor.py:186} INFO - Started process (PID=474) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:08:12.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:08:13.002+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:08:13.001+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:08:13.174+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:08:13.201+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:08:13.201+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:08:13.238+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:08:13.238+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:08:13.270+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.298 seconds
[2024-11-08T20:08:43.458+0000] {processor.py:186} INFO - Started process (PID=540) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:08:43.459+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:08:43.463+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:08:43.462+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:08:43.621+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:08:43.649+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:08:43.649+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:08:43.689+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:08:43.689+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:08:43.715+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.267 seconds
[2024-11-08T20:09:14.208+0000] {processor.py:186} INFO - Started process (PID=607) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:09:14.210+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:09:14.216+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:09:14.215+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:09:14.348+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:09:14.373+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:09:14.373+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:09:14.406+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:09:14.405+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:09:14.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.235 seconds
[2024-11-08T20:09:45.322+0000] {processor.py:186} INFO - Started process (PID=674) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:09:45.323+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:09:45.327+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:09:45.326+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:09:45.458+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:09:45.487+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:09:45.487+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:09:45.525+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:09:45.525+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:09:45.561+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.248 seconds
[2024-11-08T20:10:16.217+0000] {processor.py:186} INFO - Started process (PID=741) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:10:16.218+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:10:16.223+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:10:16.222+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:10:16.414+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:10:16.450+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:10:16.450+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:10:16.480+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:10:16.480+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:10:16.506+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.299 seconds
[2024-11-08T20:10:47.255+0000] {processor.py:186} INFO - Started process (PID=808) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:10:47.256+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:10:47.259+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:10:47.259+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:10:47.392+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:10:47.423+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:10:47.422+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:10:47.475+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:10:47.475+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:10:47.501+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.254 seconds
[2024-11-08T20:11:18.390+0000] {processor.py:186} INFO - Started process (PID=875) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:11:18.392+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:11:18.396+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:11:18.396+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:11:18.548+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:11:18.578+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:11:18.578+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:11:18.617+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:11:18.617+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:11:18.655+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.277 seconds
[2024-11-08T20:11:48.942+0000] {processor.py:186} INFO - Started process (PID=942) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:11:48.943+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:11:48.947+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:11:48.946+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:11:49.074+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:11:49.101+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:11:49.101+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:11:49.131+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:11:49.131+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:11:49.159+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.226 seconds
[2024-11-08T20:12:19.492+0000] {processor.py:186} INFO - Started process (PID=1009) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:12:19.497+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:12:19.507+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:12:19.506+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:12:19.768+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:12:19.796+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:12:19.796+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:12:19.829+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:12:19.829+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:12:19.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.391 seconds
[2024-11-08T20:12:50.578+0000] {processor.py:186} INFO - Started process (PID=1076) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:12:50.580+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:12:50.584+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:12:50.583+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:12:50.727+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:12:50.757+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:12:50.757+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:12:50.787+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:12:50.787+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:12:50.822+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.254 seconds
[2024-11-08T20:13:21.650+0000] {processor.py:186} INFO - Started process (PID=1143) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:13:21.652+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:13:21.656+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:13:21.655+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:13:21.800+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:13:21.827+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:13:21.826+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:13:21.857+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:13:21.857+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:13:21.882+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.243 seconds
[2024-11-08T20:13:52.119+0000] {processor.py:186} INFO - Started process (PID=1210) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:13:52.121+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:13:52.125+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:13:52.124+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:13:52.428+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:13:52.503+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:13:52.503+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:13:52.634+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:13:52.634+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:13:52.704+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.599 seconds
[2024-11-08T20:14:22.974+0000] {processor.py:186} INFO - Started process (PID=1278) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:14:22.975+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:14:22.980+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:14:22.980+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:14:23.242+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:14:23.291+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:14:23.291+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:14:23.358+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:14:23.358+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:14:23.438+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.480 seconds
[2024-11-08T20:14:54.387+0000] {processor.py:186} INFO - Started process (PID=1351) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:14:54.388+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:14:54.391+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:14:54.391+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:14:54.660+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:14:54.696+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:14:54.696+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:14:54.748+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:14:54.747+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:14:54.782+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.404 seconds
[2024-11-08T20:15:25.545+0000] {processor.py:186} INFO - Started process (PID=1418) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:15:25.551+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:15:25.557+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:15:25.556+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:15:25.928+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:15:25.990+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:15:25.989+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:15:26.065+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:15:26.064+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:15:26.120+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.602 seconds
[2024-11-08T20:15:56.249+0000] {processor.py:186} INFO - Started process (PID=1485) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:15:56.250+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:15:56.253+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:15:56.253+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:15:56.411+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:15:56.435+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:15:56.435+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:15:56.465+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:15:56.464+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:15:56.492+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.251 seconds
[2024-11-08T20:16:26.718+0000] {processor.py:186} INFO - Started process (PID=1552) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:16:26.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:16:26.725+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:16:26.724+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:16:26.905+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:16:26.939+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:16:26.938+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:16:26.993+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:16:26.992+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:16:27.027+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.322 seconds
[2024-11-08T20:16:57.342+0000] {processor.py:186} INFO - Started process (PID=1619) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:16:57.344+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:16:57.348+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:16:57.347+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:16:57.477+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:16:57.505+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:16:57.505+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:16:57.537+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:16:57.537+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:16:57.566+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.239 seconds
[2024-11-08T20:17:28.252+0000] {processor.py:186} INFO - Started process (PID=1674) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:17:28.255+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:17:28.260+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:17:28.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:17:28.558+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:17:28.610+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:17:28.610+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:17:28.668+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:17:28.668+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:17:28.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.492 seconds
[2024-11-08T20:17:59.319+0000] {processor.py:186} INFO - Started process (PID=1739) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:17:59.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:17:59.324+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:17:59.324+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:17:59.456+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:17:59.482+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:17:59.481+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:17:59.513+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:17:59.513+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:17:59.540+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.230 seconds
[2024-11-08T20:18:30.264+0000] {processor.py:186} INFO - Started process (PID=1796) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:18:30.267+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:18:30.271+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:18:30.270+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:18:30.494+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:18:30.541+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:18:30.541+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:18:30.585+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:18:30.585+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:18:30.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.394 seconds
[2024-11-08T20:19:00.982+0000] {processor.py:186} INFO - Started process (PID=1864) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:19:00.984+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:19:00.987+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:19:00.987+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:19:01.124+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:19:01.149+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:19:01.149+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:19:01.184+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:19:01.183+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:19:01.210+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.237 seconds
[2024-11-08T20:19:31.450+0000] {processor.py:186} INFO - Started process (PID=1928) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:19:31.452+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:19:31.458+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:19:31.458+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:19:31.580+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:19:31.607+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:19:31.606+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:19:31.639+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:19:31.639+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:19:31.670+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.233 seconds
[2024-11-08T20:20:03.345+0000] {processor.py:186} INFO - Started process (PID=1990) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:20:03.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:20:03.352+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:20:03.351+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:20:03.625+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:20:03.669+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:20:03.669+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:20:03.704+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:20:03.704+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:20:03.735+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.405 seconds
[2024-11-08T20:20:34.421+0000] {processor.py:186} INFO - Started process (PID=2052) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:20:34.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:20:34.425+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:20:34.425+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:20:34.560+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:20:34.586+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:20:34.586+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:20:34.619+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:20:34.618+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:20:34.650+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.238 seconds
[2024-11-08T20:21:05.254+0000] {processor.py:186} INFO - Started process (PID=2115) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:21:05.256+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:21:05.259+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:21:05.258+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:21:05.422+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:21:05.460+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:21:05.460+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:21:05.502+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:21:05.502+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:21:05.534+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.288 seconds
[2024-11-08T20:21:36.007+0000] {processor.py:186} INFO - Started process (PID=2182) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:21:36.009+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:21:36.020+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:21:36.019+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:21:36.193+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:21:36.219+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:21:36.218+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:21:36.472+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:21:36.471+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:21:36.502+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.508 seconds
[2024-11-08T20:22:06.818+0000] {processor.py:186} INFO - Started process (PID=2248) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:22:06.819+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:22:06.822+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:22:06.822+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:22:06.968+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:22:06.994+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:22:06.993+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:22:07.225+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:22:07.224+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:22:07.264+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.454 seconds
[2024-11-08T20:22:38.186+0000] {processor.py:186} INFO - Started process (PID=2315) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:22:38.188+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:22:38.192+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:22:38.191+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:22:38.321+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:22:38.345+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:22:38.345+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:22:38.379+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:22:38.379+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:22:38.630+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.457 seconds
[2024-11-08T20:23:08.723+0000] {processor.py:186} INFO - Started process (PID=2383) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:23:08.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:23:08.729+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:23:08.729+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:23:08.948+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:23:08.984+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:23:08.983+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:23:09.047+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:23:09.047+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:23:09.113+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.401 seconds
[2024-11-08T20:23:39.601+0000] {processor.py:186} INFO - Started process (PID=2450) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:23:39.603+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:23:39.606+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:23:39.606+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:23:39.788+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:23:40.118+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:23:40.117+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:23:40.149+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:23:40.149+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:23:40.177+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.588 seconds
[2024-11-08T20:24:10.764+0000] {processor.py:186} INFO - Started process (PID=2519) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:24:10.766+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:24:10.770+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:24:10.770+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:24:10.916+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:24:10.950+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:24:10.949+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:24:11.232+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:24:11.232+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:24:11.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.511 seconds
[2024-11-08T20:24:41.494+0000] {processor.py:186} INFO - Started process (PID=2587) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:24:41.495+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:24:41.499+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:24:41.499+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:24:41.644+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:24:41.671+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:24:41.671+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:24:41.900+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:24:41.899+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:24:41.930+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.446 seconds
[2024-11-08T20:25:12.186+0000] {processor.py:186} INFO - Started process (PID=2655) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:25:12.188+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:25:12.192+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:25:12.192+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:25:12.341+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:25:12.369+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:25:12.368+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:25:12.627+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:25:12.627+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:25:12.671+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.495 seconds
[2024-11-08T20:25:43.024+0000] {processor.py:186} INFO - Started process (PID=2723) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:25:43.026+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:25:43.032+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:25:43.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:25:43.599+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:25:43.634+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:25:43.634+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:25:43.678+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:25:43.678+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:25:43.719+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.712 seconds
[2024-11-08T20:26:14.424+0000] {processor.py:186} INFO - Started process (PID=2791) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:26:14.425+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:26:14.428+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:26:14.428+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:26:14.785+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:26:14.811+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:26:14.811+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:26:14.844+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:26:14.844+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:26:14.878+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.464 seconds
[2024-11-08T20:26:45.113+0000] {processor.py:186} INFO - Started process (PID=2857) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:26:45.114+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:26:45.117+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:26:45.117+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:26:45.447+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:26:45.482+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:26:45.481+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:26:45.525+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:26:45.525+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:26:45.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.459 seconds
[2024-11-08T20:27:15.969+0000] {processor.py:186} INFO - Started process (PID=2924) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:27:15.970+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:27:15.976+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:27:15.975+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:27:16.380+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:27:16.414+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:27:16.413+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:27:16.449+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:27:16.448+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:27:16.477+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.518 seconds
[2024-11-08T20:27:47.048+0000] {processor.py:186} INFO - Started process (PID=2991) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:27:47.050+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:27:47.055+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:27:47.054+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:27:47.509+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:27:47.545+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:27:47.544+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:27:47.585+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:27:47.585+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:27:47.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.595 seconds
[2024-11-08T20:28:17.812+0000] {processor.py:186} INFO - Started process (PID=3058) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:28:17.815+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:28:17.819+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:28:17.818+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:28:18.162+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:28:18.191+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:28:18.190+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:28:18.227+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:28:18.226+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:28:18.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.463 seconds
[2024-11-08T20:28:48.505+0000] {processor.py:186} INFO - Started process (PID=3124) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:28:48.507+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:28:48.510+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:28:48.510+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:28:48.882+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:28:48.907+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:28:48.907+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:28:48.936+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:28:48.936+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:28:48.970+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.475 seconds
[2024-11-08T20:29:19.170+0000] {processor.py:186} INFO - Started process (PID=3191) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:29:19.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:29:19.181+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:29:19.181+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:29:19.654+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:29:19.681+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:29:19.681+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:29:19.709+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:29:19.709+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:29:19.737+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.594 seconds
[2024-11-08T20:29:50.699+0000] {processor.py:186} INFO - Started process (PID=3259) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:29:50.701+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:29:50.705+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:29:50.704+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:29:51.037+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:29:51.064+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:29:51.064+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:29:51.096+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:29:51.095+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:29:51.129+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.440 seconds
[2024-11-08T20:30:21.271+0000] {processor.py:186} INFO - Started process (PID=3325) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:30:21.273+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:30:21.276+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:30:21.276+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:30:21.681+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:30:21.712+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:30:21.712+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:30:21.755+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:30:21.755+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:30:21.795+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.533 seconds
[2024-11-08T20:34:24.126+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:34:24.128+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:34:24.132+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:34:24.131+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:34:24.359+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:34:24.416+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:34:24.416+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:34:24.463+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:34:24.463+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:34:24.506+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.390 seconds
[2024-11-08T20:34:54.899+0000] {processor.py:186} INFO - Started process (PID=139) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:34:54.900+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:34:54.904+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:34:54.904+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:34:55.056+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:34:55.081+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:34:55.081+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:34:55.111+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:34:55.111+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:34:55.137+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.248 seconds
[2024-11-08T20:35:25.534+0000] {processor.py:186} INFO - Started process (PID=206) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:35:25.536+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:35:25.538+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:35:25.537+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:35:25.689+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:35:25.725+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:35:25.725+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:35:25.776+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:35:25.776+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:35:25.829+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.303 seconds
[2024-11-08T20:35:56.078+0000] {processor.py:186} INFO - Started process (PID=273) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:35:56.079+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:35:56.081+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:35:56.081+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:35:56.218+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:35:56.246+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:35:56.246+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:35:56.286+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:35:56.285+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:35:56.314+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.245 seconds
[2024-11-08T20:36:26.959+0000] {processor.py:186} INFO - Started process (PID=340) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:36:26.961+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:36:26.963+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:36:26.962+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:36:27.164+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:36:27.189+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:36:27.189+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:36:27.235+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:36:27.235+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:36:27.271+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.320 seconds
[2024-11-08T20:36:57.344+0000] {processor.py:186} INFO - Started process (PID=407) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:36:57.346+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:36:57.348+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:36:57.348+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:36:57.541+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:36:57.566+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:36:57.566+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:36:57.600+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:36:57.600+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:36:57.631+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.300 seconds
[2024-11-08T20:37:27.798+0000] {processor.py:186} INFO - Started process (PID=474) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:37:27.800+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:37:27.802+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:37:27.802+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:37:27.962+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:37:27.992+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:37:27.992+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:37:28.038+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:37:28.037+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:37:28.075+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.287 seconds
[2024-11-08T20:37:58.268+0000] {processor.py:186} INFO - Started process (PID=541) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:37:58.270+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:37:58.272+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:37:58.271+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:37:58.404+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:37:58.429+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:37:58.429+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:37:58.461+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:37:58.461+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:37:58.491+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.230 seconds
[2024-11-08T20:38:28.703+0000] {processor.py:186} INFO - Started process (PID=608) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:38:28.705+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:38:28.707+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:38:28.706+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:38:28.837+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:38:28.866+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:38:28.865+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:38:28.898+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:38:28.898+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:38:28.927+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.232 seconds
[2024-11-08T20:38:59.581+0000] {processor.py:186} INFO - Started process (PID=675) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:38:59.583+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:38:59.586+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:38:59.585+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:38:59.779+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:38:59.816+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:38:59.816+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:38:59.867+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:38:59.866+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:38:59.902+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.330 seconds
[2024-11-08T20:39:30.485+0000] {processor.py:186} INFO - Started process (PID=742) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:39:30.486+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:39:30.488+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:39:30.488+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:39:30.631+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:39:30.659+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:39:30.659+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:39:30.696+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:39:30.696+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:39:30.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.251 seconds
[2024-11-08T20:40:00.991+0000] {processor.py:186} INFO - Started process (PID=810) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:40:00.992+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:40:00.994+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:40:00.994+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:40:01.128+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:40:01.156+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:40:01.156+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:40:01.192+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:40:01.191+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:40:01.222+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.241 seconds
[2024-11-08T20:40:31.610+0000] {processor.py:186} INFO - Started process (PID=878) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:40:31.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:40:31.615+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:40:31.615+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:40:31.773+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:40:31.802+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:40:31.801+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:40:31.841+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:40:31.840+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:40:31.874+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.277 seconds
[2024-11-08T20:41:02.099+0000] {processor.py:186} INFO - Started process (PID=945) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:41:02.100+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:41:02.102+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:41:02.102+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:41:02.234+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:41:02.260+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:41:02.259+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:41:02.292+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:41:02.292+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:41:02.316+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.229 seconds
[2024-11-08T20:41:33.147+0000] {processor.py:186} INFO - Started process (PID=1011) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:41:33.148+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:41:33.150+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:41:33.150+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:41:33.285+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:41:33.315+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:41:33.315+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:41:33.354+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:41:33.354+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:41:33.385+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.246 seconds
[2024-11-08T20:42:03.889+0000] {processor.py:186} INFO - Started process (PID=1079) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:42:03.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:42:03.901+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:42:03.900+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:42:04.146+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:42:04.183+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:42:04.183+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:42:04.236+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:42:04.235+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:42:04.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.406 seconds
[2024-11-08T20:42:34.867+0000] {processor.py:186} INFO - Started process (PID=1146) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:42:34.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:42:34.870+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:42:34.870+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:42:35.010+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:42:35.037+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:42:35.036+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:42:35.071+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:42:35.070+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:42:35.104+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.246 seconds
[2024-11-08T20:43:06.019+0000] {processor.py:186} INFO - Started process (PID=1213) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:43:06.021+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:43:06.023+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:43:06.022+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:43:06.167+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:43:06.191+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:43:06.191+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:43:06.228+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:43:06.228+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:43:06.258+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.249 seconds
[2024-11-08T20:43:36.876+0000] {processor.py:186} INFO - Started process (PID=1280) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:43:36.880+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:43:36.885+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:43:36.884+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:43:37.143+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:43:37.178+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:43:37.178+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:43:37.232+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:43:37.232+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:43:37.272+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.415 seconds
[2024-11-08T20:44:08.318+0000] {processor.py:186} INFO - Started process (PID=1348) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:44:08.320+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:44:08.322+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:44:08.322+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:44:08.460+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:44:08.487+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:44:08.487+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:44:08.521+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:44:08.520+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:44:08.549+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.244 seconds
[2024-11-08T20:47:17.842+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:47:17.843+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:47:17.848+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:47:17.847+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:47:18.074+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:47:18.413+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:47:18.412+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T20:47:18.530+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:47:18.529+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T20:47:18.545+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:47:18.544+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T20:47:18.561+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:47:18.561+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T20:47:18.574+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:47:18.574+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T20:47:18.588+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:47:18.588+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T20:47:18.604+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:47:18.603+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T20:47:18.605+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:47:18.605+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:47:18.639+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:47:18.638+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_etl_pipeline_with_separate_functions
[2024-11-08T20:47:18.664+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:47:18.664+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:47:18.698+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.897 seconds
[2024-11-08T20:48:05.008+0000] {processor.py:186} INFO - Started process (PID=68) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:48:05.010+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:48:05.013+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:48:05.012+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:48:05.164+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:48:05.201+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:48:05.201+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:48:05.233+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:48:05.232+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:48:05.262+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.264 seconds
[2024-11-08T20:48:35.463+0000] {processor.py:186} INFO - Started process (PID=136) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:48:35.464+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:48:35.468+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:48:35.467+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:48:35.599+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:48:35.629+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:48:35.629+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:48:35.692+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:48:35.691+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:48:35.730+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.277 seconds
[2024-11-08T20:49:06.190+0000] {processor.py:186} INFO - Started process (PID=202) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:49:06.191+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:49:06.194+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:49:06.194+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:49:06.326+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:49:06.352+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:49:06.351+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:49:06.383+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:49:06.382+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:49:06.411+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.229 seconds
[2024-11-08T20:49:37.170+0000] {processor.py:186} INFO - Started process (PID=269) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:49:37.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:49:37.176+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:49:37.175+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:49:37.314+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:49:37.344+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:49:37.344+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:49:37.378+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:49:37.377+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:49:37.411+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.250 seconds
[2024-11-08T20:50:08.004+0000] {processor.py:186} INFO - Started process (PID=336) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:50:08.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:50:08.010+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:50:08.010+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:50:08.155+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:50:08.181+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:50:08.181+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:50:08.226+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:50:08.226+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:50:08.273+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.279 seconds
[2024-11-08T20:50:39.094+0000] {processor.py:186} INFO - Started process (PID=403) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:50:39.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:50:39.100+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:50:39.099+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:50:39.290+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:50:39.341+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:50:39.340+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:50:39.405+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:50:39.405+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:50:39.449+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.367 seconds
[2024-11-08T20:51:09.869+0000] {processor.py:186} INFO - Started process (PID=470) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:51:09.871+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:51:09.877+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:51:09.876+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:51:10.170+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:51:10.231+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:51:10.230+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:51:10.326+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:51:10.325+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:51:10.372+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.519 seconds
[2024-11-08T20:51:40.498+0000] {processor.py:186} INFO - Started process (PID=537) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:51:40.500+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:51:40.503+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:51:40.502+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:51:40.646+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:51:40.673+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:51:40.673+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:51:40.707+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:51:40.707+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:51:40.738+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.248 seconds
[2024-11-08T20:52:10.920+0000] {processor.py:186} INFO - Started process (PID=605) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:52:10.921+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:52:10.925+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:52:10.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:52:11.070+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:52:11.098+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:52:11.097+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:52:11.128+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:52:11.127+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:52:11.157+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.246 seconds
[2024-11-08T20:52:41.377+0000] {processor.py:186} INFO - Started process (PID=672) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:52:41.379+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:52:41.384+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:52:41.383+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:52:41.599+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:52:41.632+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:52:41.632+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:52:41.668+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:52:41.667+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:52:41.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.327 seconds
[2024-11-08T20:53:12.104+0000] {processor.py:186} INFO - Started process (PID=738) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:53:12.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:53:12.109+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:53:12.108+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:53:12.264+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:53:12.291+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:53:12.291+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:53:12.329+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:53:12.329+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:53:12.357+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.264 seconds
[2024-11-08T20:53:43.389+0000] {processor.py:186} INFO - Started process (PID=805) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:53:43.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:53:43.394+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:53:43.394+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:53:43.581+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:53:43.619+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:53:43.619+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:53:43.671+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:53:43.670+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:53:43.711+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.333 seconds
[2024-11-08T20:54:13.894+0000] {processor.py:186} INFO - Started process (PID=872) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:54:13.896+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:54:13.899+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:54:13.898+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:54:14.029+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:54:14.060+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:54:14.060+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:54:14.097+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:54:14.096+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:54:14.128+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.241 seconds
[2024-11-08T20:54:44.543+0000] {processor.py:186} INFO - Started process (PID=939) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:54:44.545+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:54:44.552+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:54:44.551+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:54:44.752+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:54:44.783+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:54:44.783+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:54:44.829+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:54:44.829+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:54:44.861+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.328 seconds
[2024-11-08T20:55:15.027+0000] {processor.py:186} INFO - Started process (PID=1006) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:55:15.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:55:15.032+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:55:15.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:55:15.228+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:55:15.260+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:55:15.259+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:55:15.298+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:55:15.298+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:55:15.330+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.312 seconds
[2024-11-08T20:55:45.412+0000] {processor.py:186} INFO - Started process (PID=1073) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:55:45.414+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:55:45.418+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:55:45.417+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:55:45.617+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:55:45.699+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:55:45.699+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:55:45.812+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:55:45.811+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:55:45.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.449 seconds
[2024-11-08T20:56:16.380+0000] {processor.py:186} INFO - Started process (PID=1140) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:56:16.382+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:56:16.385+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:56:16.385+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:56:16.513+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:56:16.541+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:56:16.540+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:56:16.570+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:56:16.570+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:56:16.594+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.222 seconds
[2024-11-08T20:56:47.038+0000] {processor.py:186} INFO - Started process (PID=1207) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:56:47.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:56:47.044+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:56:47.043+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:56:47.164+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:56:47.192+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:56:47.192+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:56:47.222+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:56:47.222+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:56:47.250+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.220 seconds
[2024-11-08T20:57:17.699+0000] {processor.py:186} INFO - Started process (PID=1274) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:57:17.701+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:57:17.705+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:57:17.704+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:57:17.851+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:57:17.877+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:57:17.877+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:57:17.908+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:57:17.908+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:57:17.935+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.244 seconds
[2024-11-08T20:57:48.890+0000] {processor.py:186} INFO - Started process (PID=1342) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:57:48.891+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:57:48.895+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:57:48.894+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:57:49.027+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:57:49.053+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:57:49.052+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:57:49.095+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:57:49.094+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:57:49.124+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.243 seconds
[2024-11-08T20:58:19.762+0000] {processor.py:186} INFO - Started process (PID=1409) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:58:19.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:58:19.768+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:58:19.767+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:58:19.945+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:58:19.977+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:58:19.977+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:58:20.026+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:58:20.025+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:58:20.063+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.309 seconds
[2024-11-08T20:58:50.443+0000] {processor.py:186} INFO - Started process (PID=1476) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:58:50.445+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:58:50.448+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:58:50.448+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:58:50.581+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:58:50.610+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:58:50.610+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:58:50.643+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:58:50.642+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:58:50.671+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.237 seconds
[2024-11-08T20:59:22.367+0000] {processor.py:186} INFO - Started process (PID=1543) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:59:22.369+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:59:22.375+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:59:22.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:59:22.571+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:59:22.605+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:59:22.604+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:59:22.669+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:59:22.669+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:59:22.705+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.351 seconds
[2024-11-08T20:59:53.134+0000] {processor.py:186} INFO - Started process (PID=1610) to work on /opt/airflow/dags/etl.py
[2024-11-08T20:59:53.136+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T20:59:53.140+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:59:53.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T20:59:53.285+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T20:59:53.333+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:59:53.333+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T20:59:53.365+0000] {logging_mixin.py:190} INFO - [2024-11-08T20:59:53.365+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T20:59:53.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.268 seconds
[2024-11-08T21:00:24.190+0000] {processor.py:186} INFO - Started process (PID=1675) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:00:24.192+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:00:24.196+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:00:24.195+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:00:24.341+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:00:24.367+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:00:24.367+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:00:24.407+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:00:24.407+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:00:24.438+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.258 seconds
[2024-11-08T21:00:54.541+0000] {processor.py:186} INFO - Started process (PID=1732) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:00:54.542+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:00:54.545+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:00:54.544+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:00:54.731+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:00:54.755+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:00:54.754+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:00:54.786+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:00:54.786+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:00:54.815+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.282 seconds
[2024-11-08T21:04:11.917+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:04:11.918+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:04:11.922+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:04:11.921+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:04:12.041+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:04:12.073+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:04:12.073+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:04:12.102+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:04:12.102+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:04:12.133+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.224 seconds
[2024-11-08T21:04:42.827+0000] {processor.py:186} INFO - Started process (PID=140) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:04:42.828+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:04:42.831+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:04:42.831+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:04:42.974+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:04:42.999+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:04:42.999+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:04:43.032+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:04:43.031+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:04:43.056+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.238 seconds
[2024-11-08T21:05:13.368+0000] {processor.py:186} INFO - Started process (PID=207) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:05:13.369+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:05:13.371+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:05:13.371+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:05:13.501+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:05:13.542+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:05:13.542+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:05:13.581+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:05:13.581+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:05:13.616+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.256 seconds
[2024-11-08T21:05:44.533+0000] {processor.py:186} INFO - Started process (PID=274) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:05:44.534+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:05:44.537+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:05:44.536+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:05:44.779+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:05:44.819+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:05:44.819+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:05:44.871+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:05:44.871+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:05:44.906+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.383 seconds
[2024-11-08T21:06:15.346+0000] {processor.py:186} INFO - Started process (PID=341) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:06:15.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:06:15.352+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:06:15.351+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:06:15.803+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:06:15.868+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:06:15.867+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:06:15.963+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:06:15.963+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:06:16.035+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.713 seconds
[2024-11-08T21:06:46.327+0000] {processor.py:186} INFO - Started process (PID=409) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:06:46.329+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:06:46.331+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:06:46.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:06:46.490+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:06:46.523+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:06:46.522+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:06:46.561+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:06:46.561+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:06:46.593+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.275 seconds
[2024-11-08T21:07:17.526+0000] {processor.py:186} INFO - Started process (PID=476) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:07:17.528+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:07:17.530+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:07:17.530+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:07:17.695+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:07:17.721+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:07:17.720+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:07:17.754+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:07:17.754+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:07:17.785+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.269 seconds
[2024-11-08T21:11:29.366+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:11:29.368+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:11:29.375+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:11:29.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:11:29.525+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:11:29.561+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:11:29.561+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:11:29.598+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:11:29.598+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:11:29.629+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.278 seconds
[2024-11-08T21:12:00.064+0000] {processor.py:186} INFO - Started process (PID=140) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:12:00.066+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:12:00.074+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:12:00.073+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:12:00.287+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:12:00.330+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:12:00.330+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:12:00.391+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:12:00.390+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:12:00.442+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.394 seconds
[2024-11-08T21:12:31.142+0000] {processor.py:186} INFO - Started process (PID=207) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:12:31.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:12:31.154+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:12:31.153+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:12:31.457+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:12:31.513+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:12:31.513+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:12:31.556+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:12:31.555+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:12:31.588+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.466 seconds
[2024-11-08T21:13:01.980+0000] {processor.py:186} INFO - Started process (PID=274) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:13:01.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:13:01.985+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:13:01.985+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:13:02.117+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:13:02.145+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:13:02.144+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:13:02.176+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:13:02.176+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:13:02.215+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.243 seconds
[2024-11-08T21:13:32.677+0000] {processor.py:186} INFO - Started process (PID=341) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:13:32.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:13:32.685+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:13:32.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:13:32.851+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:13:32.883+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:13:32.883+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:13:32.950+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:13:32.949+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:13:32.988+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.326 seconds
[2024-11-08T21:14:03.509+0000] {processor.py:186} INFO - Started process (PID=408) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:14:03.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:14:03.516+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:14:03.516+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:14:03.702+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:14:03.728+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:14:03.728+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:14:03.766+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:14:03.766+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:14:03.797+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.302 seconds
[2024-11-08T21:14:34.118+0000] {processor.py:186} INFO - Started process (PID=475) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:14:34.120+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:14:34.133+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:14:34.123+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:14:34.306+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:14:34.341+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:14:34.341+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:14:34.389+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:14:34.389+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:14:34.426+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.317 seconds
[2024-11-08T21:18:04.644+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:18:04.646+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:18:04.649+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:18:04.648+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:18:04.797+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:18:04.979+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:18:04.978+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T21:18:04.994+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:18:04.993+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T21:18:05.004+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:18:05.004+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T21:18:05.016+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:18:05.015+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T21:18:05.025+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:18:05.025+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T21:18:05.051+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:18:05.051+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T21:18:05.061+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:18:05.061+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T21:18:05.062+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:18:05.062+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:18:05.084+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:18:05.084+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_etl_pipeline_with_separate_functions
[2024-11-08T21:18:05.097+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:18:05.097+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:18:05.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.481 seconds
[2024-11-08T21:18:35.366+0000] {processor.py:186} INFO - Started process (PID=141) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:18:35.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:18:35.388+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:18:35.387+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:18:35.794+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:18:35.872+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:18:35.872+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:18:35.960+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:18:35.959+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:18:36.033+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.691 seconds
[2024-11-08T21:19:06.275+0000] {processor.py:186} INFO - Started process (PID=208) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:19:06.276+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:19:06.281+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:19:06.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:19:06.514+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:19:06.564+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:19:06.563+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:19:06.655+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:19:06.654+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:19:06.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.438 seconds
[2024-11-08T21:19:36.846+0000] {processor.py:186} INFO - Started process (PID=276) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:19:36.848+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:19:36.852+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:19:36.851+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:19:37.013+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:19:37.040+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:19:37.039+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:19:37.076+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:19:37.075+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:19:37.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.268 seconds
[2024-11-08T21:20:07.487+0000] {processor.py:186} INFO - Started process (PID=342) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:20:07.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:20:07.494+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:20:07.493+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:20:07.637+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:20:07.669+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:20:07.669+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:20:07.703+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:20:07.703+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:20:07.737+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.259 seconds
[2024-11-08T21:20:37.927+0000] {processor.py:186} INFO - Started process (PID=410) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:20:37.928+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:20:37.932+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:20:37.932+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:20:38.054+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:20:38.078+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:20:38.078+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:20:38.108+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:20:38.108+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:20:38.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.229 seconds
[2024-11-08T21:21:08.873+0000] {processor.py:186} INFO - Started process (PID=477) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:21:08.876+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:21:08.882+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:21:08.881+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:21:09.056+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:21:09.094+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:21:09.093+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:21:09.146+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:21:09.145+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:21:09.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.324 seconds
[2024-11-08T21:21:39.478+0000] {processor.py:186} INFO - Started process (PID=544) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:21:39.480+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:21:39.495+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:21:39.494+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:21:39.682+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:21:39.709+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:21:39.709+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:21:39.742+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:21:39.742+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:21:39.775+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.323 seconds
[2024-11-08T21:22:09.995+0000] {processor.py:186} INFO - Started process (PID=611) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:22:09.997+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:22:10.001+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:22:10.000+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:22:10.132+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:22:10.161+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:22:10.160+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:22:10.198+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:22:10.198+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:22:10.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.242 seconds
[2024-11-08T21:22:40.646+0000] {processor.py:186} INFO - Started process (PID=678) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:22:40.648+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:22:40.653+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:22:40.652+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:22:40.845+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:22:40.882+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:22:40.882+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:22:40.928+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:22:40.927+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:22:40.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.324 seconds
[2024-11-08T21:23:11.298+0000] {processor.py:186} INFO - Started process (PID=745) to work on /opt/airflow/dags/etl.py
[2024-11-08T21:23:11.300+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T21:23:11.304+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:23:11.304+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T21:23:11.451+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T21:23:11.479+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:23:11.478+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T21:23:11.511+0000] {logging_mixin.py:190} INFO - [2024-11-08T21:23:11.511+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T21:23:11.541+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.255 seconds
[2024-11-08T22:00:19.650+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:00:19.651+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:00:19.655+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:00:19.655+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:00:19.792+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:00:19.951+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:00:19.950+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T22:00:19.966+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:00:19.965+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T22:00:19.997+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:00:19.997+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T22:00:20.052+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:00:20.052+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T22:00:20.107+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:00:20.107+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T22:00:20.148+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:00:20.148+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T22:00:20.200+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:00:20.199+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T22:00:20.201+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:00:20.200+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:00:20.218+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:00:20.218+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_etl_pipeline_with_separate_functions
[2024-11-08T22:00:20.234+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:00:20.234+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:00:20.310+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.668 seconds
[2024-11-08T22:00:51.173+0000] {processor.py:186} INFO - Started process (PID=141) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:00:51.176+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:00:51.182+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:00:51.181+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:00:51.442+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:00:51.480+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:00:51.479+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:00:51.533+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:00:51.533+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:00:51.571+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.414 seconds
[2024-11-08T22:01:21.750+0000] {processor.py:186} INFO - Started process (PID=209) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:01:21.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:01:21.758+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:01:21.757+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:01:22.044+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:01:22.136+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:01:22.136+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:01:22.233+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:01:22.233+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:01:22.312+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.575 seconds
[2024-11-08T22:01:52.628+0000] {processor.py:186} INFO - Started process (PID=277) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:01:52.631+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:01:52.638+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:01:52.638+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:01:52.901+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:01:52.952+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:01:52.951+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:01:53.009+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:01:53.009+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:01:53.057+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.445 seconds
[2024-11-08T22:02:23.210+0000] {processor.py:186} INFO - Started process (PID=342) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:02:23.212+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:02:23.218+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:02:23.217+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:02:23.425+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:02:23.464+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:02:23.464+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:02:23.513+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:02:23.513+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:02:23.554+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.362 seconds
[2024-11-08T22:02:53.931+0000] {processor.py:186} INFO - Started process (PID=410) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:02:53.934+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:02:53.942+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:02:53.941+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:02:54.178+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:02:54.212+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:02:54.211+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:02:54.258+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:02:54.257+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:02:54.296+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.383 seconds
[2024-11-08T22:03:24.841+0000] {processor.py:186} INFO - Started process (PID=476) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:03:24.848+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:03:24.866+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:03:24.864+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:03:25.206+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:03:25.256+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:03:25.256+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:03:25.324+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:03:25.323+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:03:25.373+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.576 seconds
[2024-11-08T22:03:55.602+0000] {processor.py:186} INFO - Started process (PID=543) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:03:55.604+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:03:55.609+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:03:55.608+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:03:55.801+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:03:55.838+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:03:55.838+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:03:55.888+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:03:55.888+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:03:55.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.336 seconds
[2024-11-08T22:04:26.392+0000] {processor.py:186} INFO - Started process (PID=611) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:04:26.394+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:04:26.401+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:04:26.400+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:04:26.622+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:04:26.669+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:04:26.669+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:04:26.726+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:04:26.725+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:04:26.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.398 seconds
[2024-11-08T22:04:56.901+0000] {processor.py:186} INFO - Started process (PID=678) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:04:56.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:04:56.909+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:04:56.909+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:04:57.148+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:04:57.207+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:04:57.207+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:04:57.335+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:04:57.334+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:04:57.400+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.513 seconds
[2024-11-08T22:05:28.042+0000] {processor.py:186} INFO - Started process (PID=744) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:05:28.044+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:05:28.049+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:05:28.049+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:05:28.324+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:05:28.360+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:05:28.359+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:05:28.405+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:05:28.404+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:05:28.441+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.413 seconds
[2024-11-08T22:05:59.319+0000] {processor.py:186} INFO - Started process (PID=811) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:05:59.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:05:59.327+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:05:59.326+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:05:59.528+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:05:59.570+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:05:59.569+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:05:59.670+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:05:59.669+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:05:59.792+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.490 seconds
[2024-11-08T22:06:31.013+0000] {processor.py:186} INFO - Started process (PID=878) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:06:31.017+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:06:31.026+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:06:31.025+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:06:31.243+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:06:31.280+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:06:31.280+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:06:31.322+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:06:31.322+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:06:31.358+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.375 seconds
[2024-11-08T22:07:02.267+0000] {processor.py:186} INFO - Started process (PID=945) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:07:02.270+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:07:02.275+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:07:02.274+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:07:02.475+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:07:02.523+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:07:02.523+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:07:02.584+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:07:02.584+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:07:02.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.380 seconds
[2024-11-08T22:07:33.925+0000] {processor.py:186} INFO - Started process (PID=1003) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:07:33.927+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:07:33.935+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:07:33.934+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:07:34.245+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:07:34.302+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:07:34.302+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:07:34.382+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:07:34.382+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:07:34.434+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.528 seconds
[2024-11-08T22:08:06.888+0000] {processor.py:186} INFO - Started process (PID=1070) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:08:06.894+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:08:06.908+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:08:06.907+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:08:07.228+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:08:07.280+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:08:07.279+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:08:07.465+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:08:07.464+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:08:07.552+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.701 seconds
[2024-11-08T22:08:39.860+0000] {processor.py:186} INFO - Started process (PID=1143) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:08:39.864+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:08:39.873+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:08:39.872+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:08:40.146+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:08:40.181+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:08:40.181+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:08:40.276+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:08:40.275+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:08:40.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.548 seconds
[2024-11-08T22:09:11.873+0000] {processor.py:186} INFO - Started process (PID=1210) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:09:11.880+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:09:11.895+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:09:11.892+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:09:12.285+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:09:12.394+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:09:12.393+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:09:12.532+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:09:12.531+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:09:12.614+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.776 seconds
[2024-11-08T22:09:43.377+0000] {processor.py:186} INFO - Started process (PID=1278) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:09:43.379+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:09:43.388+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:09:43.387+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:09:43.675+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:09:43.730+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:09:43.729+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:09:43.806+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:09:43.805+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:09:43.859+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.501 seconds
[2024-11-08T22:10:14.452+0000] {processor.py:186} INFO - Started process (PID=1341) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:10:14.454+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:10:14.458+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:10:14.457+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:10:14.635+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:10:14.678+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:10:14.678+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:10:14.725+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:10:14.725+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:10:14.762+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.321 seconds
[2024-11-08T22:10:45.322+0000] {processor.py:186} INFO - Started process (PID=1407) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:10:45.324+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:10:45.330+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:10:45.329+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:10:45.623+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:10:45.687+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:10:45.686+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:10:45.751+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:10:45.750+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:10:45.831+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.523 seconds
[2024-11-08T22:11:16.549+0000] {processor.py:186} INFO - Started process (PID=1474) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:11:16.551+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:11:16.555+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:11:16.555+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:11:16.771+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:11:16.805+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:11:16.805+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:11:16.850+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:11:16.850+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:11:16.889+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.351 seconds
[2024-11-08T22:11:47.090+0000] {processor.py:186} INFO - Started process (PID=1540) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:11:47.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:11:47.112+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:11:47.110+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:11:47.586+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:11:47.669+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:11:47.668+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:11:47.748+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:11:47.748+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:11:47.808+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.751 seconds
[2024-11-08T22:12:18.074+0000] {processor.py:186} INFO - Started process (PID=1607) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:12:18.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:12:18.087+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:12:18.085+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:12:18.332+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:12:18.388+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:12:18.388+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:12:18.445+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:12:18.444+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:12:18.492+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.439 seconds
[2024-11-08T22:12:48.623+0000] {processor.py:186} INFO - Started process (PID=1673) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:12:48.627+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:12:48.633+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:12:48.632+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:12:48.945+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:12:49.016+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:12:49.015+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:12:49.115+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:12:49.114+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:12:49.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.565 seconds
[2024-11-08T22:13:19.730+0000] {processor.py:186} INFO - Started process (PID=1740) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:13:19.732+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:13:19.751+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:13:19.750+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:13:20.108+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:13:20.156+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:13:20.156+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:13:20.204+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:13:20.203+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:13:20.242+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.534 seconds
[2024-11-08T22:13:50.611+0000] {processor.py:186} INFO - Started process (PID=1808) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:13:50.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:13:50.617+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:13:50.616+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:13:50.801+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:13:50.834+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:13:50.834+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:13:50.878+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:13:50.877+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:13:50.911+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.310 seconds
[2024-11-08T22:14:21.182+0000] {processor.py:186} INFO - Started process (PID=1874) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:14:21.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:14:21.206+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:14:21.204+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:14:21.530+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:14:21.582+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:14:21.582+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:14:21.647+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:14:21.646+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:14:21.998+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.863 seconds
[2024-11-08T22:14:52.112+0000] {processor.py:186} INFO - Started process (PID=1941) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:14:52.114+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:14:52.118+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:14:52.118+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:14:52.313+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:14:52.375+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:14:52.374+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:14:52.481+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:14:52.481+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:14:52.523+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.424 seconds
[2024-11-08T22:15:22.721+0000] {processor.py:186} INFO - Started process (PID=2008) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:15:22.723+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:15:22.727+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:15:22.727+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:15:23.019+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:15:23.121+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:15:23.120+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:15:23.213+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:15:23.213+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:15:23.276+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.566 seconds
[2024-11-08T22:15:53.502+0000] {processor.py:186} INFO - Started process (PID=2075) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:15:53.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:15:53.511+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:15:53.510+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:15:53.744+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:15:53.789+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:15:53.788+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:15:53.844+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:15:53.844+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:15:53.886+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.400 seconds
[2024-11-08T22:16:24.298+0000] {processor.py:186} INFO - Started process (PID=2143) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:16:24.308+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:16:24.319+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:16:24.317+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:16:24.569+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:16:24.620+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:16:24.619+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:16:25.054+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:16:25.053+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:16:25.108+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.842 seconds
[2024-11-08T22:16:55.580+0000] {processor.py:186} INFO - Started process (PID=2210) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:16:55.585+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:16:55.601+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:16:55.598+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:16:55.861+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:16:55.909+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:16:55.908+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:16:56.237+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:16:56.236+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:16:56.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.735 seconds
[2024-11-08T22:17:26.529+0000] {processor.py:186} INFO - Started process (PID=2278) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:17:26.534+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:17:26.545+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:17:26.544+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:17:26.935+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:17:26.968+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:17:26.968+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:17:27.007+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:17:27.007+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:17:27.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.841 seconds
[2024-11-08T22:17:57.598+0000] {processor.py:186} INFO - Started process (PID=2345) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:17:57.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:17:57.605+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:17:57.604+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:17:57.790+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:17:57.839+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:17:57.839+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:17:57.881+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:17:57.880+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:17:57.926+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.339 seconds
[2024-11-08T22:18:28.609+0000] {processor.py:186} INFO - Started process (PID=2412) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:18:28.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:18:28.629+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:18:28.627+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:18:28.937+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:18:29.470+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:18:29.469+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:18:29.527+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:18:29.527+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:18:29.572+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 1.015 seconds
[2024-11-08T22:18:59.701+0000] {processor.py:186} INFO - Started process (PID=2482) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:18:59.703+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:18:59.711+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:18:59.710+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:18:59.943+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:18:59.983+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:18:59.983+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:19:00.357+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:19:00.356+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:19:00.405+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.729 seconds
[2024-11-08T22:19:30.721+0000] {processor.py:186} INFO - Started process (PID=2549) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:19:30.723+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:19:30.726+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:19:30.725+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:19:30.842+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:19:30.865+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:19:30.864+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:19:30.896+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:19:30.895+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:19:31.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.395 seconds
[2024-11-08T22:20:01.163+0000] {processor.py:186} INFO - Started process (PID=2617) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:20:01.164+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:20:01.167+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:20:01.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:20:01.484+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:20:01.506+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:20:01.506+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:20:01.529+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:20:01.529+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:20:01.555+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.399 seconds
[2024-11-08T22:20:32.412+0000] {processor.py:186} INFO - Started process (PID=2684) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:20:32.415+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:20:32.420+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:20:32.419+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:20:32.729+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:20:32.752+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:20:32.752+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:20:32.775+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:20:32.775+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:20:32.805+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.404 seconds
[2024-11-08T22:21:02.960+0000] {processor.py:186} INFO - Started process (PID=2751) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:21:02.962+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:21:02.965+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:21:02.965+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:21:03.083+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:21:03.107+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:21:03.107+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:21:03.310+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:21:03.310+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:21:03.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.384 seconds
[2024-11-08T22:21:33.684+0000] {processor.py:186} INFO - Started process (PID=2818) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:21:33.685+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:21:33.690+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:21:33.689+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:21:34.151+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:21:34.176+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:21:34.176+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:21:34.214+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:21:34.213+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:21:34.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.576 seconds
[2024-11-08T22:22:04.379+0000] {processor.py:186} INFO - Started process (PID=2887) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:22:04.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:22:04.385+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:22:04.384+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:22:04.741+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:22:04.764+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:22:04.764+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:22:04.788+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:22:04.787+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:22:04.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.445 seconds
[2024-11-08T22:22:34.950+0000] {processor.py:186} INFO - Started process (PID=2954) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:22:34.951+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:22:34.955+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:22:34.955+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:22:35.335+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:22:35.357+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:22:35.357+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:22:35.391+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:22:35.391+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:22:35.416+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.475 seconds
[2024-11-08T22:23:06.297+0000] {processor.py:186} INFO - Started process (PID=3021) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:23:06.299+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:23:06.301+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:23:06.301+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:23:06.640+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:23:06.659+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:23:06.659+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:23:06.682+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:23:06.681+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:23:06.723+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.432 seconds
[2024-11-08T22:23:36.950+0000] {processor.py:186} INFO - Started process (PID=3088) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:23:36.952+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:23:36.954+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:23:36.954+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:23:37.249+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:23:37.271+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:23:37.271+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:23:37.300+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:23:37.300+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:23:37.325+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.381 seconds
[2024-11-08T22:24:07.574+0000] {processor.py:186} INFO - Started process (PID=3155) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:24:07.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:24:07.578+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:24:07.577+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:24:07.918+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:24:07.936+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:24:07.935+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:24:07.960+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:24:07.959+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:24:07.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.417 seconds
[2024-11-08T22:24:38.763+0000] {processor.py:186} INFO - Started process (PID=3222) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:24:38.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:24:38.767+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:24:38.767+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:24:39.117+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:24:39.143+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:24:39.142+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:24:39.179+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:24:39.179+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:24:39.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.456 seconds
[2024-11-08T22:25:09.556+0000] {processor.py:186} INFO - Started process (PID=3289) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:25:09.558+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:25:09.563+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:25:09.563+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:25:09.964+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:25:10.020+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:25:10.020+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:25:10.061+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:25:10.059+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:25:10.097+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.552 seconds
[2024-11-08T22:25:40.858+0000] {processor.py:186} INFO - Started process (PID=3356) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:25:40.861+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:25:40.865+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:25:40.865+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:25:41.026+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:25:41.048+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:25:41.048+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:25:41.079+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:25:41.078+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:25:41.101+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.255 seconds
[2024-11-08T22:26:11.505+0000] {processor.py:186} INFO - Started process (PID=3429) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:26:11.507+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:26:11.510+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:26:11.509+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:26:11.613+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:26:11.635+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:26:11.635+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:26:11.660+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:26:11.660+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:26:11.683+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.185 seconds
[2024-11-08T22:26:42.314+0000] {processor.py:186} INFO - Started process (PID=3496) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:26:42.316+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:26:42.319+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:26:42.318+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:26:42.419+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:26:42.441+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:26:42.441+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:26:42.467+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:26:42.467+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:26:42.487+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.180 seconds
[2024-11-08T22:27:13.238+0000] {processor.py:186} INFO - Started process (PID=3563) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:27:13.239+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:27:13.243+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:27:13.243+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:27:13.358+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:27:13.379+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:27:13.379+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:27:13.415+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:27:13.415+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:27:13.436+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.208 seconds
[2024-11-08T22:27:45.645+0000] {processor.py:186} INFO - Started process (PID=3630) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:27:45.647+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:27:45.652+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:27:45.652+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:27:45.908+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:27:45.942+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:27:45.941+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:27:45.983+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:27:45.983+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:27:46.020+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.391 seconds
[2024-11-08T22:28:16.800+0000] {processor.py:186} INFO - Started process (PID=3697) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:28:16.801+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:28:16.805+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:28:16.805+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:28:16.912+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:28:16.932+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:28:16.932+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:28:16.958+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:28:16.958+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:28:16.980+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.192 seconds
[2024-11-08T22:28:47.319+0000] {processor.py:186} INFO - Started process (PID=3764) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:28:47.320+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:28:47.324+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:28:47.323+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:28:47.445+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:28:47.469+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:28:47.469+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:28:47.494+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:28:47.494+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:28:47.516+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.204 seconds
[2024-11-08T22:29:17.845+0000] {processor.py:186} INFO - Started process (PID=3830) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:29:17.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:29:17.850+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:29:17.849+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:29:17.973+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:29:18.006+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:29:18.006+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:29:18.037+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:29:18.037+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:29:18.058+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.219 seconds
[2024-11-08T22:32:38.347+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:32:38.349+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:32:38.352+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:32:38.352+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:32:38.550+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:32:38.701+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:32:38.700+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T22:32:38.718+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:32:38.718+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T22:32:38.728+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:32:38.728+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_etl_pipeline_with_separate_functions
[2024-11-08T22:32:38.740+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:32:38.739+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T22:32:38.749+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:32:38.749+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T22:32:38.758+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:32:38.758+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T22:32:38.767+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:32:38.767+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_etl_pipeline_with_separate_functions
[2024-11-08T22:32:38.768+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:32:38.768+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:32:38.784+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:32:38.784+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_etl_pipeline_with_separate_functions
[2024-11-08T22:32:38.797+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:32:38.797+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:32:38.822+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.484 seconds
[2024-11-08T22:33:09.796+0000] {processor.py:186} INFO - Started process (PID=141) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:33:09.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:33:09.802+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:33:09.801+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:33:09.980+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:33:10.012+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:33:10.012+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:33:10.052+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:33:10.052+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:33:10.082+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.297 seconds
[2024-11-08T22:33:40.209+0000] {processor.py:186} INFO - Started process (PID=209) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:33:40.211+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:33:40.216+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:33:40.215+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:33:40.417+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:33:40.440+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:33:40.440+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:33:40.474+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:33:40.473+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:33:40.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.305 seconds
[2024-11-08T22:34:10.578+0000] {processor.py:186} INFO - Started process (PID=276) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:34:10.579+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:34:10.582+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:34:10.581+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:34:10.694+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:34:10.720+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:34:10.720+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:34:10.748+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:34:10.748+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:34:10.768+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.198 seconds
[2024-11-08T22:34:41.243+0000] {processor.py:186} INFO - Started process (PID=342) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:34:41.244+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:34:41.247+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:34:41.247+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:34:41.378+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:34:41.404+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:34:41.403+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:34:41.432+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:34:41.432+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:34:41.464+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.228 seconds
[2024-11-08T22:35:11.583+0000] {processor.py:186} INFO - Started process (PID=409) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:35:11.585+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:35:11.588+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:35:11.587+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:35:11.741+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:35:11.768+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:35:11.767+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:35:11.801+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:35:11.800+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:35:11.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.259 seconds
[2024-11-08T22:35:42.282+0000] {processor.py:186} INFO - Started process (PID=476) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:35:42.284+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:35:42.287+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:35:42.287+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:35:42.408+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:35:42.436+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:35:42.435+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:35:42.501+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:35:42.501+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:35:42.535+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.265 seconds
[2024-11-08T22:36:12.721+0000] {processor.py:186} INFO - Started process (PID=544) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:36:12.723+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:36:12.725+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:36:12.725+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:36:12.844+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:36:12.869+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:36:12.869+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:36:12.904+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:36:12.904+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:36:12.936+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.222 seconds
[2024-11-08T22:36:43.519+0000] {processor.py:186} INFO - Started process (PID=610) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:36:43.520+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:36:43.523+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:36:43.522+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:36:43.629+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:36:43.651+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:36:43.650+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:36:43.679+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:36:43.679+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:36:43.706+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.193 seconds
[2024-11-08T22:37:14.430+0000] {processor.py:186} INFO - Started process (PID=677) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:37:14.431+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:37:14.434+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:37:14.433+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:37:14.546+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:37:14.567+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:37:14.567+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:37:14.591+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:37:14.591+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:37:14.618+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.195 seconds
[2024-11-08T22:37:44.761+0000] {processor.py:186} INFO - Started process (PID=745) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:37:44.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:37:44.765+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:37:44.765+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:37:44.889+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:37:44.914+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:37:44.914+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:37:44.940+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:37:44.940+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:37:44.962+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.208 seconds
[2024-11-08T22:38:15.071+0000] {processor.py:186} INFO - Started process (PID=811) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:38:15.072+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:38:15.075+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:38:15.075+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:38:15.179+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:38:15.204+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:38:15.203+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:38:15.232+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:38:15.231+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:38:15.259+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.194 seconds
[2024-11-08T22:38:45.443+0000] {processor.py:186} INFO - Started process (PID=879) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:38:45.445+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:38:45.448+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:38:45.448+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:38:45.556+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:38:45.577+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:38:45.577+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:38:45.602+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:38:45.602+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:38:45.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.191 seconds
[2024-11-08T22:39:16.218+0000] {processor.py:186} INFO - Started process (PID=945) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:39:16.219+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:39:16.222+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:39:16.222+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:39:16.341+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:39:16.367+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:39:16.367+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:39:16.395+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:39:16.395+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:39:16.424+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.213 seconds
[2024-11-08T22:39:47.113+0000] {processor.py:186} INFO - Started process (PID=1013) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:39:47.114+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:39:47.118+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:39:47.117+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:39:47.231+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:39:47.253+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:39:47.252+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:39:47.283+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:39:47.282+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:39:47.315+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.209 seconds
[2024-11-08T22:40:17.865+0000] {processor.py:186} INFO - Started process (PID=1080) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:40:17.867+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:40:17.869+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:40:17.869+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:40:17.975+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:40:17.995+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:40:17.995+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:40:18.019+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:40:18.019+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:40:18.043+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.184 seconds
[2024-11-08T22:40:48.958+0000] {processor.py:186} INFO - Started process (PID=1147) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:40:48.959+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:40:48.962+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:40:48.962+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:40:49.066+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:40:49.086+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:40:49.086+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:40:49.110+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:40:49.110+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:40:49.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.195 seconds
[2024-11-08T22:41:19.856+0000] {processor.py:186} INFO - Started process (PID=1220) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:41:19.858+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:41:19.866+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:41:19.865+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:41:20.055+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:41:20.086+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:41:20.086+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:41:20.129+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:41:20.128+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:41:20.159+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.322 seconds
[2024-11-08T22:41:50.599+0000] {processor.py:186} INFO - Started process (PID=1287) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:41:50.601+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:41:50.604+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:41:50.604+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:41:50.784+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:41:50.821+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:41:50.821+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:41:50.852+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:41:50.851+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:41:50.875+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.286 seconds
[2024-11-08T22:42:21.503+0000] {processor.py:186} INFO - Started process (PID=1354) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:42:21.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:42:21.507+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:42:21.507+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:42:21.629+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:42:21.653+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:42:21.653+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:42:21.690+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:42:21.689+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:42:21.711+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.215 seconds
[2024-11-08T22:42:51.909+0000] {processor.py:186} INFO - Started process (PID=1421) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:42:51.910+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:42:51.913+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:42:51.913+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:42:52.017+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:42:52.039+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:42:52.039+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:42:52.065+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:42:52.065+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:42:52.090+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.188 seconds
[2024-11-08T22:43:22.451+0000] {processor.py:186} INFO - Started process (PID=1488) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:43:22.452+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:43:22.455+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:43:22.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:43:22.559+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:43:22.580+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:43:22.580+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:43:22.605+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:43:22.605+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:43:22.630+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.186 seconds
[2024-11-08T22:43:53.439+0000] {processor.py:186} INFO - Started process (PID=1555) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:43:53.441+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:43:53.445+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:43:53.444+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:43:53.576+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:43:53.628+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:43:53.627+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:43:53.666+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:43:53.665+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:43:53.691+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.262 seconds
[2024-11-08T22:44:24.337+0000] {processor.py:186} INFO - Started process (PID=1622) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:44:24.338+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:44:24.341+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:44:24.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:44:24.444+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:44:24.466+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:44:24.465+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:44:24.490+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:44:24.489+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:44:24.515+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.185 seconds
[2024-11-08T22:44:55.444+0000] {processor.py:186} INFO - Started process (PID=1689) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:44:55.445+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:44:55.448+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:44:55.448+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:44:55.556+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:44:55.578+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:44:55.578+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:44:55.604+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:44:55.604+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:44:55.626+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.189 seconds
[2024-11-08T22:45:26.458+0000] {processor.py:186} INFO - Started process (PID=1756) to work on /opt/airflow/dags/etl.py
[2024-11-08T22:45:26.459+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-11-08T22:45:26.462+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:45:26.462+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-11-08T22:45:26.573+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline_with_separate_functions' retrieved from /opt/airflow/dags/etl.py
[2024-11-08T22:45:26.595+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:45:26.595+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-08T22:45:26.622+0000] {logging_mixin.py:190} INFO - [2024-11-08T22:45:26.622+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_etl_pipeline_with_separate_functions to 2024-01-20 00:00:00+00:00, run_after=2024-01-21 00:00:00+00:00
[2024-11-08T22:45:26.651+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl.py took 0.199 seconds
